{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22643b33",
   "metadata": {},
   "source": [
    "# LangChain: Memory\n",
    "\n",
    "## Outline\n",
    "- ConversationBufferMemory\n",
    "- ConversationBufferWindowMemory\n",
    "- ConversationTokenBufferMemory\n",
    "- ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67ccbb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade tiktoken\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d8948c",
   "metadata": {},
   "source": [
    "## ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64224484",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0be64d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bcf8cdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.0)\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    verbose=True,\n",
    "    memory = memory\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91b903be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi, my name is Andrew\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello Andrew! It's nice to meet you. How can I assist you today?\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi, my name is Andrew\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9963721e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Andrew\n",
      "AI: Hello Andrew! It's nice to meet you. How can I assist you today?\n",
      "Human: What is 1+1?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1+1 is equal to 2.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is 1+1?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64128bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi, my name is Andrew\n",
      "AI: Hello Andrew! It's nice to meet you. How can I assist you today?\n",
      "Human: What is 1+1?\n",
      "AI: 1+1 is equal to 2.\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Andrew.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b786189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: 嗨，我的名字是Andrew\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'嗨，Andrew！很高兴认识你。我是一个AI助手，我可以回答你的问题和提供帮助。有什么我可以帮你的吗？'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"嗨，我的名字是Andrew\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ecfc77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: 嗨，我的名字是Andrew\n",
      "AI: 嗨，Andrew！很高兴认识你。我是一个AI助手，我可以回答你的问题和提供帮助。有什么我可以帮你的吗？\n",
      "Human: 1+1等於多少？\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1+1等于2。'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"1+1等於多少？\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e77d0adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: 嗨，我的名字是Andrew\n",
      "AI: 嗨，Andrew！很高兴认识你。我是一个AI助手，我可以回答你的问题和提供帮助。有什么我可以帮你的吗？\n",
      "Human: 1+1等於多少？\n",
      "AI: 1+1等于2。\n",
      "Human: 我的名字是什麼？\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'你的名字是Andrew。'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"我的名字是什麼？\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c2bf9f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: 嗨，我的名字是Andrew\\nAI: 嗨，Andrew！很高兴认识你。我是一个AI助手，我可以回答你的问题和提供帮助。有什么我可以帮你的吗？\\nHuman: 1+1等於多少？\\nAI: 1+1等于2。\\nHuman: 我的名字是什麼？\\nAI: 你的名字是Andrew。'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b19fb0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e8b7dc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Hi\"},\n",
    "                    {\"output\": \"What's up\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "702c1650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi\n",
      "AI: What's up\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5f8b0511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi\\nAI: What's up\"}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b1aff1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f8105b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi\\nAI: What's up\\nHuman: Not much, just hanging\\nAI: Cool\"}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce68374c",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4c6056fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"嗨\"}, \n",
    "                    {\"output\": \"最近怎樣？\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "513e13a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 嗨\n",
      "AI: 最近怎樣？\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e97fab09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: 嗨\\nAI: 最近怎樣？'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9d4b10ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"沒什麼，只是閒著\"}, \n",
    "                    {\"output\": \"酷\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a539e0cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: 嗨\\nAI: 最近怎樣？\\nHuman: 沒什麼，只是閒著\\nAI: 酷'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638c5862",
   "metadata": {},
   "source": [
    "## Memory\n",
    "Large Language Models are 'stateless'\n",
    "- Each transaction is independent \n",
    "\n",
    "Chatbots appear to have memory by providing the full conversation as 'context'\n",
    "\n",
    "LangChain provides several kinds of 'memory' to store and accumulate the conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d366cf",
   "metadata": {},
   "source": [
    "## ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7f210ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "acc95800",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(k=1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "53f867a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Hi\"},\n",
    "                    {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a9605b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Not much, just hanging\\nAI: Cool'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5d27350e",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(k=1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eb9a9d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"嗨\"}, \n",
    "                    {\"output\": \"最近怎樣？\"})\n",
    "memory.save_context({\"input\": \"沒什麼，只是閒著\"}, \n",
    "                    {\"output\": \"酷\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0a0b5093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: 沒什麼，只是閒著\\nAI: 酷'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4b3130e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.0)\n",
    "memory = ConversationBufferWindowMemory(k=1) # just remember 1 conversational exchange\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9756e140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Andrew! It's nice to meet you. How can I assist you today?\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi, my name is Andrew\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6110490d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1+1 is equal to 2.'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is 1+1?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "53292aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I don't have access to personal information about individuals unless it has been shared with me in the course of our conversation.\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What is my name?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a1e5eb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.0)\n",
    "memory = ConversationBufferWindowMemory(k=1) # just remember 1 conversational exchange\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "37a2aaa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'嗨，Andrew！很高兴认识你。我是一个AI助手，我可以回答你的问题和提供帮助。有什么我可以帮你的吗？'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"嗨，我的名字是Andrew\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e5be94c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1+1等于2。'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"1+1等於多少？\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "72b2a597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'很抱歉，我無法知道您的名字，因為我只是一個AI，無法直接存取您的個人資訊。'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"我的名字是什麼？\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7acfed",
   "metadata": {},
   "source": [
    "## ConversationTokenBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d365a523",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4dad29d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "from langchain.llms import OpenAI\n",
    "llm = ChatOpenAI(temperature=0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "65ad1561",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=30)\n",
    "memory.save_context({\"input\": \"AI is what?!\"},\n",
    "                    {\"output\": \"Amazing!\"})\n",
    "memory.save_context({\"input\": \"Backpropagation is what?\"},\n",
    "                    {\"output\": \"Beautiful!\"})\n",
    "memory.save_context({\"input\": \"Chatbots are what?\"}, \n",
    "                    {\"output\": \"Charming!\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6a4ef354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'AI: Beautiful!\\nHuman: Chatbots are what?\\nAI: Charming!'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8be4d8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "from langchain.llms import OpenAI\n",
    "llm = ChatOpenAI(temperature=0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b0b1a4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=30)\n",
    "memory.save_context({\"input\": \"AI是什麼？!\"},\n",
    "                    {\"output\": \"驚人！\"})\n",
    "memory.save_context({\"input\": \"反向傳播是什麼？\"},\n",
    "                    {\"output\": \"美麗！\"})\n",
    "memory.save_context({\"input\": \"聊天機器人是什麼？\"}, \n",
    "                    {\"output\": \"迷人！\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "785c83c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'AI: 迷人！'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f7c539",
   "metadata": {},
   "source": [
    "## ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8faf8b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "86f7ff84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a long string\n",
    "schedule = \"There is a meeting at 8am with your product team. \\\n",
    "You will need your powerpoint presentation prepared. \\\n",
    "9am-12pm have time to work on your LangChain \\\n",
    "project which will go quickly because Langchain is such a powerful tool. \\\n",
    "At Noon, lunch at the italian resturant with a customer who is driving \\\n",
    "from over an hour away to meet you to understand the latest in AI. \\\n",
    "Be sure to bring your laptop to show the latest LLM demo.\"\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n",
    "memory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n",
    "memory.save_context({\"input\": \"What is on the schedule today?\"}, \n",
    "                    {\"output\": f\"{schedule}\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "68a6bf1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'System: The human and AI exchange greetings. The human asks about the schedule for the day. The AI provides a detailed schedule, including a meeting with the product team, work on the LangChain project, and a lunch meeting with a customer interested in AI. The AI emphasizes the importance of bringing a laptop to showcase the latest LLM demo during the lunch meeting.'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d085b3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "17384ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human and AI exchange greetings. The human asks about the schedule for the day. The AI provides a detailed schedule, including a meeting with the product team, work on the LangChain project, and a lunch meeting with a customer interested in AI. The AI emphasizes the importance of bringing a laptop to showcase the latest LLM demo during the lunch meeting.\n",
      "Human: What would be a good demo to show?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A good demo to show during the lunch meeting with the customer interested in AI would be the latest LLM (Language Model) demo. The LLM is a cutting-edge AI model that can generate human-like text based on a given prompt. It has been trained on a vast amount of data and can generate coherent and contextually relevant responses. By showcasing the LLM demo, you can demonstrate the capabilities of our AI technology and how it can be applied to various industries and use cases.'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What would be a good demo to show?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4eabfb36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'System: The human and AI exchange greetings and discuss the schedule for the day. The AI provides a detailed schedule, including a meeting with the product team, work on the LangChain project, and a lunch meeting with a customer interested in AI. The AI suggests bringing a laptop to showcase the latest Language Learning Model (LLM) demo during the lunch meeting. The LLM is a cutting-edge AI model that can understand and generate human-like text in multiple languages, performing tasks such as language translation, text summarization, and creative writing. By showcasing the LLM demo, the AI believes they can demonstrate the power and potential of LangChain to the customer, highlighting its ability to revolutionize language-related tasks and improve efficiency in various industries.'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "88217d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a long string\n",
    "schedule = \"早上8點與您的產品團隊有個會議。您將需要準備您的PowerPoint演示文稿。\\\n",
    "上午9點到12點有時間致力於您的LangChain項目，由於LangChain是如此強大的工具，進展將會非常迅速。\\\n",
    "中午，在意大利餐廳和一位開車從一個多小時以外的地方趕來與您見面，了解AI最新情況的客戶共進午餐。\\\n",
    "請務必帶上您的筆記本電腦，以展示最新的LLM演示。\"\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n",
    "memory.save_context({\"input\": \"你好\"}, {\"output\": \"最近怎樣？\"})\n",
    "memory.save_context({\"input\": \"沒什麼，只是閒著\"},\n",
    "                    {\"output\": \"酷\"})\n",
    "memory.save_context({\"input\": \"今天的行程是什麼？\"}, \n",
    "                    {\"output\": f\"{schedule}\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "184c9bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'System: The human greets the AI in Chinese and asks how it\\'s been. The AI responds by asking what the human has been up to. The human says they\\'ve been idle. The AI responds with \"cool.\" The human then asks about their schedule for the day. The AI explains that they have a meeting with the product team at 8 am and need to prepare a PowerPoint presentation. From 9 am to 12 pm, they will be working on their LangChain project, which is progressing rapidly due to its powerful nature. At noon, they have a lunch meeting with a client who will be driving from over an hour away to discuss the latest developments in AI. The AI advises the human to bring their laptop to showcase the latest LLM demo.\\n\\nNew summary:\\nThe human greets the AI in Chinese and asks how it\\'s been. The AI responds by asking what the human has been up to. The human says they\\'ve been idle. The AI responds with \"cool.\" The human then asks about their schedule for the day. The AI explains that they have a meeting with the product team at 8 am and need to prepare a PowerPoint presentation. From 9 am to 12 pm, they will be working on their LangChain project, which is progressing rapidly due to its powerful nature. At noon, they have a lunch meeting with a client who will be driving from over an hour away to discuss the latest developments in AI. The AI advises the human to bring their laptop to showcase the latest LLM demo.'}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3fbef000",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ca036155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human greets the AI in Chinese and asks how it's been. The AI responds by asking what the human has been up to. The human says they've been idle. The AI responds with \"cool.\" The human then asks about their schedule for the day. The AI explains that they have a meeting with the product team at 8 am and need to prepare a PowerPoint presentation. From 9 am to 12 pm, they will be working on their LangChain project, which is progressing rapidly due to its powerful nature. At noon, they have a lunch meeting with a client who will be driving from over an hour away to discuss the latest developments in AI. The AI advises the human to bring their laptop to showcase the latest LLM demo.\n",
      "\n",
      "New summary:\n",
      "The human greets the AI in Chinese and asks how it's been. The AI responds by asking what the human has been up to. The human says they've been idle. The AI responds with \"cool.\" The human then asks about their schedule for the day. The AI explains that they have a meeting with the product team at 8 am and need to prepare a PowerPoint presentation. From 9 am to 12 pm, they will be working on their LangChain project, which is progressing rapidly due to its powerful nature. At noon, they have a lunch meeting with a client who will be driving from over an hour away to discuss the latest developments in AI. The AI advises the human to bring their laptop to showcase the latest LLM demo.\n",
      "Human: 展示哪個示範會比較好？\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'你可以展示最新的LLM演示。'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"展示哪個示範會比較好？\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "613bbf8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'System: The human greets the AI in Chinese and asks how it\\'s been. The AI responds by asking what the human has been up to. The human says they\\'ve been idle. The AI responds with \"cool.\" The human then asks about their schedule for the day. The AI explains that they have a meeting with the product team at 8 am and need to prepare a PowerPoint presentation. From 9 am to 12 pm, they will be working on their LangChain project, which is progressing rapidly due to its powerful nature. At noon, they have a lunch meeting with a client who will be driving from over an hour away to discuss the latest developments in AI. The AI advises the human to bring their laptop to showcase the latest LLM demo.\\n\\nNew summary:\\nThe human greets the AI in Chinese and asks how it\\'s been. The AI responds by asking what the human has been up to. The human says they\\'ve been idle. The AI responds with \"cool.\" The human then asks about their schedule for the day. The AI explains that they have a meeting with the product team at 8 am and need to prepare a PowerPoint presentation. From 9 am to 12 pm, they will be working on their LangChain project, which is progressing rapidly due to its powerful nature. At noon, they have a lunch meeting with a client who will be driving from over an hour away to discuss the latest developments in AI. The AI advises the human to bring their laptop to showcase the latest LLM demo.\\nHuman: 展示哪個示範會比較好？\\nAI: 你可以展示最新的LLM演示。'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc242147",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
