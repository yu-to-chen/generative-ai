{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "301bb46e",
   "metadata": {},
   "source": [
    "# Lesson 4: Using Pydantic Models for Structured LLM Output\n",
    "\n",
    "In the previous lesson, you implemented retry mechanisms to handle validation errors, which mimics what some structured output frameworks are doing behind the scenes when they handle validation for you.\n",
    "\n",
    "In this lesson, you'll experiment with passing you Pydantic model directly in your API call using different frameworks and LLM providers.\n",
    "\n",
    "By the end of this lesson, you'll be able to:\n",
    "- Use Pydantic models directly in your API calls to LLMs\n",
    "- Reliably receive a properly structured response using a variety of different frameworks and LLM providers.\n",
    "\n",
    "---\n",
    "\n",
    "### Import all required libraries and set up your environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b11c5e5",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from pydantic import BaseModel, Field, EmailStr\n",
    "from typing import List, Literal, Optional\n",
    "from openai import OpenAI\n",
    "import instructor\n",
    "import anthropic\n",
    "from dotenv import load_dotenv\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3eab72",
   "metadata": {},
   "source": [
    "### Define your Pydantic models for user input and LLM output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c21e83",
   "metadata": {
    "height": 438
   },
   "outputs": [],
   "source": [
    "# Define the UserInput model for customer support queries\n",
    "class UserInput(BaseModel):\n",
    "    name: str\n",
    "    email: EmailStr\n",
    "    query: str\n",
    "    order_id: Optional[int] = Field(\n",
    "        None,\n",
    "        description=\"5-digit order number (cannot start with 0)\",\n",
    "        ge=10000,\n",
    "        le=99999\n",
    "    )\n",
    "    purchase_date: Optional[date] = None\n",
    "\n",
    "# Define the CustomerQuery model that inherits from UserInput\n",
    "class CustomerQuery(UserInput):\n",
    "    priority: str = Field(\n",
    "        ..., description=\"Priority level: low, medium, high\"\n",
    "    )\n",
    "    category: Literal[\n",
    "        'refund_request', 'information_request', 'other'\n",
    "    ] = Field(..., description=\"Query category\")\n",
    "    is_complaint: bool = Field(\n",
    "        ..., description=\"Whether this is a complaint\"\n",
    "    )\n",
    "    tags: List[str] = Field(..., description=\"Relevant keyword tags\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd4d86b",
   "metadata": {},
   "source": [
    "### Provide sample input and validate it using your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ded7c6",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "# Define your input data as a JSON string\n",
    "user_input_json = '''{\n",
    "    \"name\": \"Joe User\",\n",
    "    \"email\": \"joe.user@example.com\",\n",
    "    \"query\": \"I ordered a new computer monitor and it arrived with the screen cracked. This is the second time this has happened. I need a replacement ASAP.\",\n",
    "    \"order_number\": 12345,\n",
    "    \"purchase_date\": \"2025-12-31\"\n",
    "}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de1bc95",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "# Validate the user_input_json by creating a UserInput instance\n",
    "user_input = UserInput.model_validate_json(user_input_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b48355",
   "metadata": {},
   "source": [
    "### Build a prompt and call the Anthropic API with the instructor package for structured output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7505cb71",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "prompt = (\n",
    "    f\"Analyze the following customer query {user_input} \"\n",
    "    f\"and provide a structured response.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1363746c",
   "metadata": {
    "height": 319
   },
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "# Use Anthropic with Instructor to get structured output\n",
    "anthropic_client = instructor.from_anthropic(\n",
    "    anthropic.Anthropic()\n",
    ")\n",
    "\n",
    "response = anthropic_client.messages.create(\n",
    "    model=\"claude-3-7-sonnet-latest\",  \n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ],\n",
    "    response_model=CustomerQuery  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ea2ec7",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "# Inspect the returned structured data\n",
    "print(type(response))\n",
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a39682",
   "metadata": {},
   "source": [
    "### Use OpenAI's structured output API with your Pydantic schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d342f4a",
   "metadata": {
    "height": 183
   },
   "outputs": [],
   "source": [
    "# Initialize OpenAI client and call passing CustomerQuery in your API call\n",
    "openai_client = OpenAI()\n",
    "response = openai_client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    response_format=CustomerQuery\n",
    ")\n",
    "response_content = response.choices[0].message.content\n",
    "print(type(response_content))\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257c716e",
   "metadata": {},
   "source": [
    "### Additional advanced usage and inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0facf3a",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "# Validate the repsonse you got from the LLM\n",
    "valid_data = CustomerQuery.model_validate_json(\n",
    "    response_content\n",
    ")\n",
    "print(type(valid_data))\n",
    "print(valid_data.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf6a29f",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "# Try the responses API from OpenAI\n",
    "response = openai_client.responses.parse(\n",
    "    model=\"gpt-4o\",\n",
    "    input=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    text_format=CustomerQuery\n",
    ")\n",
    "\n",
    "print(type(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38913864",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "# Investigate class inheritance structure of the OpenAI response\n",
    "def print_class_inheritence(llm_response):\n",
    "    for cls in type(llm_response).mro():\n",
    "        print(f\"{cls.__module__}.{cls.__name__}\")\n",
    "\n",
    "print_class_inheritence(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92138d5",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "# Print the response type and content \n",
    "print(type(response.output_parsed))\n",
    "print(response.output_parsed.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb392c18",
   "metadata": {
    "height": 200
   },
   "outputs": [],
   "source": [
    "# Try out the Pydantic AI package for defining an agent and getting a structured response\n",
    "from pydantic_ai import Agent\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "agent = Agent(\n",
    "    model=\"google-gla:gemini-2.0-flash\",\n",
    "    output_type=CustomerQuery,\n",
    ")\n",
    "\n",
    "response = agent.run_sync(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54073bc3",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "# Print out the repsonse type and content\n",
    "print(type(response.output))\n",
    "print(response.output.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c4a537",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "In this lesson, you learned how to use Pydantic models to extract structured, validated output directly from LLMs using both OpenAI and Anthropic APIs. By defining your expected output schema with Pydantic and passing it directly to the API, you can eliminate manual parsing and validation code and receive reliable, well-formed responses in a single API call. This approach lets you focus on designing clear data models and prompts, making your code more maintainable and robust."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
