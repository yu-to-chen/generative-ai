{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9bff53e",
   "metadata": {},
   "source": [
    "# Lesson 1: Advanced RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "feb98470-c136-471d-a63e-d50d8eb09c57",
   "metadata": {
    "height": 98,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ytchen/Documents/experimental/AdvancedRAG/.venv/lib/python3.11/site-packages/munch/__init__.py:24: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "âœ… In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "âœ… In Context Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "âœ… In Context Relevance, input response will be set to __record__.calls[-1].rets.source_nodes[:].node.text .\n",
      "âœ… In Groundedness, input source will be set to __record__.calls[-1].rets.source_nodes[:].node.text .\n",
      "âœ… In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "import os\n",
    "import openai\n",
    "openai.api_key = utils.get_openai_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31e2859b-596e-40b3-867b-f4d6e91f74bc",
   "metadata": {
    "height": 98,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from llama_index import SimpleDirectoryReader\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[\"./eBook-How-to-Build-a-Career-in-AI.pdf\"]\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d7d0857-b9d1-4feb-8243-bfd2f4953acd",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> \n",
      "\n",
      "41 \n",
      "\n",
      "<class 'llama_index.core.schema.Document'>\n",
      "Doc ID: d3ee076f-bc22-4752-a2f9-b66b976deb83\n",
      "Text: PAGE 1 Founder, DeepLearning.AI Collected Insights from Andrew\n",
      "Ng How to  Build Your Career in AI A Simple Guide\n"
     ]
    }
   ],
   "source": [
    "print(type(documents), \"\\n\")\n",
    "print(len(documents), \"\\n\")\n",
    "print(type(documents[0]))\n",
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3123d3d",
   "metadata": {},
   "source": [
    "## Basic RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4abc806-64f5-46bb-8c9f-6469ecb18d20",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from llama_index import Document\n",
    "from llama_index.core import Document\n",
    "\n",
    "\n",
    "document = Document(text=\"\\n\\n\".join([doc.text for doc in documents]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afc2baff-5e8b-4733-9899-16f248777b23",
   "metadata": {
    "height": 183,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom llama_index import VectorStoreIndex\\nfrom llama_index import ServiceContext\\nfrom llama_index.llms import OpenAI\\n\\n\\nllm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\\nservice_context = ServiceContext.from_defaults(\\n    llm=llm, embed_model=\"local:BAAI/bge-small-en-v1.5\"\\n)\\nindex = VectorStoreIndex.from_documents([document],\\n                                        service_context=service_context)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from llama_index import VectorStoreIndex\n",
    "from llama_index import ServiceContext\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=llm, embed_model=\"local:BAAI/bge-small-en-v1.5\"\n",
    ")\n",
    "index = VectorStoreIndex.from_documents([document],\n",
    "                                        service_context=service_context)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0bd588c-af8c-405d-95e5-b673c404ece1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-27 16:32:46,793 - INFO - Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5\n",
      "2025-08-27 16:32:49,212 - INFO - 1 prompt is loaded, with the key: query\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "# Define LLM and embedding\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "\n",
    "# Apply globally (so all indices/query_engines use these defaults)\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "\n",
    "# Now you can build the index without passing service_context\n",
    "index = VectorStoreIndex.from_documents([document])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae52a26c-7d0c-44df-8043-4c7f19f794b9",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b0d5b6e-cc2e-4648-b28c-5fa25a97d175",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-27 16:32:54,022 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Develop a side hustle, ensure the project helps you grow technically, collaborate with good teammates, and consider if the project can serve as a stepping stone to larger projects.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"What are steps to take when finding projects to build your experience?\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50a1ac5",
   "metadata": {},
   "source": [
    "## Evaluation setup using TruLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ead7dc1-71b2-4001-918f-bf8d610fd3fd",
   "metadata": {
    "height": 132,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the keys to building a career in AI?\n",
      "How can teamwork contribute to success in AI?\n",
      "What is the importance of networking in AI?\n",
      "What are some good habits to develop for a successful career?\n",
      "How can altruism be beneficial in building a career?\n",
      "What is imposter syndrome and how does it relate to AI?\n",
      "Who are some accomplished individuals who have experienced imposter syndrome?\n",
      "What is the first step to becoming good at AI?\n",
      "What are some common challenges in AI?\n",
      "Is it normal to find parts of AI challenging?\n"
     ]
    }
   ],
   "source": [
    "eval_questions = []\n",
    "with open('eval_questions.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        # Remove newline character and convert to integer\n",
    "        item = line.strip()\n",
    "        print(item)\n",
    "        eval_questions.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87a278f8",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "# You can try your own question:\n",
    "new_question = \"What is the right AI job for me?\"\n",
    "eval_questions.append(new_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d5204e8",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What are the keys to building a career in AI?', 'How can teamwork contribute to success in AI?', 'What is the importance of networking in AI?', 'What are some good habits to develop for a successful career?', 'How can altruism be beneficial in building a career?', 'What is imposter syndrome and how does it relate to AI?', 'Who are some accomplished individuals who have experienced imposter syndrome?', 'What is the first step to becoming good at AI?', 'What are some common challenges in AI?', 'Is it normal to find parts of AI challenging?', 'What is the right AI job for me?']\n"
     ]
    }
   ],
   "source": [
    "print(eval_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c063c9c7-bf1e-4b24-9a22-d4281c0f954e",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-27 16:33:06,178 - WARNING - Package trulens-providers-google not present in requirements.\n",
      "/var/folders/7t/drc_5mxn3c96k2_3zc1n57yh0000gn/T/ipykernel_79109/2801267818.py:1: DeprecationWarning: The `trulens_eval` module is deprecated. See https://www.trulens.org/component_guides/other/trulens_eval_migration/ for instructions on migrating to `trulens.*` modules.\n",
      "  from trulens_eval import Tru\n",
      "2025-08-27 16:33:06,386 - INFO - Context impl SQLiteImpl.\n",
      "2025-08-27 16:33:06,387 - INFO - Will assume non-transactional DDL.\n",
      "2025-08-27 16:33:06,393 - INFO - Context impl SQLiteImpl.\n",
      "2025-08-27 16:33:06,393 - INFO - Will assume non-transactional DDL.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦‘ Initialized with db url sqlite:///default.sqlite .\n",
      "ðŸ›‘ Secret keys may be written to the database. See the `database_redact_keys` option of `TruSession` to prevent this.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating app_name and app_version in apps table: 0it [00:00, ?it/s]\n",
      "Updating app_id in records table: 0it [00:00, ?it/s]\n",
      "Updating app_json in apps table: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from trulens_eval import Tru\n",
    "tru = Tru()\n",
    "\n",
    "tru.reset_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03802825-6ce4-4563-aeec-d8d57e095ad1",
   "metadata": {},
   "source": [
    "For the classroom, we've written some of the code in helper functions inside a utils.py file.  \n",
    "- You can view the utils.py file in the file directory by clicking on the \"Jupyter\" logo at the top of the notebook.\n",
    "- In later lessons, you'll get to work directly with the code that's currently wrapped inside these helper functions, to give you more options to customize your RAG pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f754bed-d16f-4c8d-a1a1-b36096272570",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.core.embeddings.multi_modal_base.MultiModalEmbedding'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.core.base.embeddings.base.BaseEmbedding'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.core.schema.TransformComponent'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index_instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.callbacks.base.CallbackManager'> for base <class 'llama_index.core.callbacks.base_handler.BaseCallbackHandler'>\n",
      "instrumenting <class 'llama_index.core.callbacks.base.CallbackManager'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.callbacks.base.CallbackManager'> for base <class 'object'>\n",
      "instrumenting <class 'tuple'> for base <class 'tuple'>\n",
      "instrumenting <class 'tuple'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'llama_index.core.vector_stores.types.BasePydanticVectorStore'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStoreData'> for base <class 'dataclasses_json.api.DataClassJsonMixin'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStoreData'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStoreData'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'llama_index.core.indices.base.BaseIndex'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'typing.Generic'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> for base <class 'llama_index.core.graph_stores.types.GraphStore'>\n",
      "instrumenting <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> for base <class 'typing.Protocol'>\n",
      "instrumenting <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> for base <class 'typing.Generic'>\n",
      "instrumenting <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.node_parser.interface.MetadataAwareTextSplitter'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.node_parser.interface.TextSplitter'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.node_parser.interface.NodeParser'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.schema.TransformComponent'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index_instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> for base <class 'llama_index.core.storage.docstore.keyval_docstore.KVDocumentStore'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> for base <class 'llama_index.core.storage.docstore.types.BaseDocumentStore'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.data_structs.data_structs.IndexDict'> for base <class 'llama_index.core.data_structs.data_structs.IndexStruct'>\n",
      "instrumenting <class 'llama_index.core.data_structs.data_structs.IndexDict'> for base <class 'dataclasses_json.api.DataClassJsonMixin'>\n",
      "instrumenting <class 'llama_index.core.data_structs.data_structs.IndexDict'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.data_structs.data_structs.IndexDict'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.types.RefDocInfo'> for base <class 'llama_index.core.storage.docstore.types.RefDocInfo'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.types.RefDocInfo'> for base <class 'dataclasses_json.api.DataClassJsonMixin'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.types.RefDocInfo'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.types.RefDocInfo'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.storage.storage_context.StorageContext'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'>\n",
      "\tinstrumenting retrieve\n",
      "\tinstrumenting _retrieve\n",
      "\tinstrumenting _aretrieve\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.base.base_retriever.BaseRetriever'>\n",
      "\tinstrumenting retrieve\n",
      "\tinstrumenting _retrieve\n",
      "\tinstrumenting _aretrieve\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.prompts.mixin.PromptMixin'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index_instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.llms.openai.base.OpenAI'>\n",
      "\tinstrumenting chat\n",
      "\tinstrumenting complete\n",
      "\tinstrumenting stream_chat\n",
      "\tinstrumenting stream_complete\n",
      "\tinstrumenting achat\n",
      "\tinstrumenting acomplete\n",
      "\tinstrumenting astream_chat\n",
      "\tinstrumenting astream_complete\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.core.llms.function_calling.FunctionCallingLLM'>\n",
      "\tinstrumenting chat\n",
      "\tinstrumenting complete\n",
      "\tinstrumenting stream_chat\n",
      "\tinstrumenting stream_complete\n",
      "\tinstrumenting achat\n",
      "\tinstrumenting acomplete\n",
      "\tinstrumenting astream_chat\n",
      "\tinstrumenting astream_complete\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.core.llms.llm.LLM'>\n",
      "\tinstrumenting chat\n",
      "\tinstrumenting complete\n",
      "\tinstrumenting stream_chat\n",
      "\tinstrumenting stream_complete\n",
      "\tinstrumenting achat\n",
      "\tinstrumenting acomplete\n",
      "\tinstrumenting astream_chat\n",
      "\tinstrumenting astream_complete\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.core.base.llms.base.BaseLLM'>\n",
      "\tinstrumenting chat\n",
      "\tinstrumenting complete\n",
      "\tinstrumenting stream_chat\n",
      "\tinstrumenting stream_complete\n",
      "\tinstrumenting achat\n",
      "\tinstrumenting acomplete\n",
      "\tinstrumenting astream_chat\n",
      "\tinstrumenting astream_complete\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index_instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.base.llms.types.LLMMetadata'> for base <class 'llama_index.core.base.llms.types.LLMMetadata'>\n",
      "instrumenting <class 'llama_index.core.base.llms.types.LLMMetadata'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.base.llms.types.LLMMetadata'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.indices.prompt_helper.PromptHelper'> for base <class 'llama_index.core.indices.prompt_helper.PromptHelper'>\n",
      "instrumenting <class 'llama_index.core.indices.prompt_helper.PromptHelper'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.core.indices.prompt_helper.PromptHelper'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.indices.prompt_helper.PromptHelper'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'>\n",
      "\tinstrumenting get_response\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.response_synthesizers.refine.Refine'>\n",
      "\tinstrumenting get_response\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.response_synthesizers.base.BaseSynthesizer'>\n",
      "\tinstrumenting get_response\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.prompts.mixin.PromptMixin'>\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index_instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'llama_index.core.prompts.base.BasePromptTemplate'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'llama_index.core.prompts.base.BasePromptTemplate'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'>\n",
      "\tinstrumenting query\n",
      "\tinstrumenting aquery\n",
      "\tinstrumenting synthesize\n",
      "\tinstrumenting asynthesize\n",
      "\tinstrumenting retrieve\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.base.base_query_engine.BaseQueryEngine'>\n",
      "\tinstrumenting query\n",
      "\tinstrumenting aquery\n",
      "\tinstrumenting synthesize\n",
      "\tinstrumenting asynthesize\n",
      "\tinstrumenting retrieve\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.prompts.mixin.PromptMixin'>\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index_instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'object'>\n"
     ]
    }
   ],
   "source": [
    "from utils import get_prebuilt_trulens_recorder\n",
    "\n",
    "tru_recorder = get_prebuilt_trulens_recorder(query_engine,\n",
    "                                             app_id=\"Direct Query Engine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4dbdfbcc-aac7-4805-9894-4fc016c66bf6",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tru_recorder as recording:\n",
    "    for question in eval_questions:\n",
    "        response = query_engine.query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e14f512b-601c-42d0-bfac-bf41d9c577e7",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [],
   "source": [
    "records, feedback = tru.get_records_and_feedback(app_ids=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2da4a602-0d56-4bf8-9fa6-03ef0b7e254b",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_name</th>\n",
       "      <th>app_version</th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_json</th>\n",
       "      <th>type</th>\n",
       "      <th>record_id</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>tags</th>\n",
       "      <th>record_json</th>\n",
       "      <th>...</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Context Relevance_calls</th>\n",
       "      <th>Context Relevance feedback cost in USD</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>Groundedness_calls</th>\n",
       "      <th>Groundedness feedback cost in USD</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>total_cost</th>\n",
       "      <th>cost_currency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Direct Query Engine</td>\n",
       "      <td>base</td>\n",
       "      <td>app_hash_6e8221fde876d15698298cea8c0d1bd6</td>\n",
       "      <td>{'tru_class_info': {'name': 'TruLlama', 'modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
       "      <td>record_hash_50d04792bf32f7be0d9b48701c034bc0</td>\n",
       "      <td>What is the right AI job for me?</td>\n",
       "      <td>The right AI job for you would be one that ali...</td>\n",
       "      <td>-</td>\n",
       "      <td>{'record_id': 'record_hash_50d04792bf32f7be0d9...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.793852</td>\n",
       "      <td>2182</td>\n",
       "      <td>0.003307</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Direct Query Engine</td>\n",
       "      <td>base</td>\n",
       "      <td>app_hash_6e8221fde876d15698298cea8c0d1bd6</td>\n",
       "      <td>{'tru_class_info': {'name': 'TruLlama', 'modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
       "      <td>record_hash_b17e6fb2869a9309eaed4a7ff4ff7055</td>\n",
       "      <td>Is it normal to find parts of AI challenging?</td>\n",
       "      <td>It is normal to find parts of AI challenging.</td>\n",
       "      <td>-</td>\n",
       "      <td>{'record_id': 'record_hash_b17e6fb2869a9309eae...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.511552</td>\n",
       "      <td>2129</td>\n",
       "      <td>0.003199</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Direct Query Engine</td>\n",
       "      <td>base</td>\n",
       "      <td>app_hash_6e8221fde876d15698298cea8c0d1bd6</td>\n",
       "      <td>{'tru_class_info': {'name': 'TruLlama', 'modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
       "      <td>record_hash_ce1a7b27a23a487bbdc789b9622fe115</td>\n",
       "      <td>What are some common challenges in AI?</td>\n",
       "      <td>Common challenges in AI include understanding ...</td>\n",
       "      <td>-</td>\n",
       "      <td>{'record_id': 'record_hash_ce1a7b27a23a487bbdc...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.769732</td>\n",
       "      <td>2123</td>\n",
       "      <td>0.003198</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Direct Query Engine</td>\n",
       "      <td>base</td>\n",
       "      <td>app_hash_6e8221fde876d15698298cea8c0d1bd6</td>\n",
       "      <td>{'tru_class_info': {'name': 'TruLlama', 'modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
       "      <td>record_hash_6e595aecd248617542d11e29f2fcfcd4</td>\n",
       "      <td>What is the first step to becoming good at AI?</td>\n",
       "      <td>Learning foundational technical skills.</td>\n",
       "      <td>-</td>\n",
       "      <td>{'record_id': 'record_hash_6e595aecd248617542d...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.649987</td>\n",
       "      <td>1727</td>\n",
       "      <td>0.002593</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Direct Query Engine</td>\n",
       "      <td>base</td>\n",
       "      <td>app_hash_6e8221fde876d15698298cea8c0d1bd6</td>\n",
       "      <td>{'tru_class_info': {'name': 'TruLlama', 'modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.core.query_en...</td>\n",
       "      <td>record_hash_bd0ebe790090d258b67a9427d854ff3a</td>\n",
       "      <td>Who are some accomplished individuals who have...</td>\n",
       "      <td>Former Facebook COO Sheryl Sandberg, U.S. firs...</td>\n",
       "      <td>-</td>\n",
       "      <td>{'record_id': 'record_hash_bd0ebe790090d258b67...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.714716</td>\n",
       "      <td>2143</td>\n",
       "      <td>0.003237</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              app_name app_version                                     app_id  \\\n",
       "0  Direct Query Engine        base  app_hash_6e8221fde876d15698298cea8c0d1bd6   \n",
       "1  Direct Query Engine        base  app_hash_6e8221fde876d15698298cea8c0d1bd6   \n",
       "2  Direct Query Engine        base  app_hash_6e8221fde876d15698298cea8c0d1bd6   \n",
       "3  Direct Query Engine        base  app_hash_6e8221fde876d15698298cea8c0d1bd6   \n",
       "4  Direct Query Engine        base  app_hash_6e8221fde876d15698298cea8c0d1bd6   \n",
       "\n",
       "                                            app_json  \\\n",
       "0  {'tru_class_info': {'name': 'TruLlama', 'modul...   \n",
       "1  {'tru_class_info': {'name': 'TruLlama', 'modul...   \n",
       "2  {'tru_class_info': {'name': 'TruLlama', 'modul...   \n",
       "3  {'tru_class_info': {'name': 'TruLlama', 'modul...   \n",
       "4  {'tru_class_info': {'name': 'TruLlama', 'modul...   \n",
       "\n",
       "                                                type  \\\n",
       "0  RetrieverQueryEngine(llama_index.core.query_en...   \n",
       "1  RetrieverQueryEngine(llama_index.core.query_en...   \n",
       "2  RetrieverQueryEngine(llama_index.core.query_en...   \n",
       "3  RetrieverQueryEngine(llama_index.core.query_en...   \n",
       "4  RetrieverQueryEngine(llama_index.core.query_en...   \n",
       "\n",
       "                                      record_id  \\\n",
       "0  record_hash_50d04792bf32f7be0d9b48701c034bc0   \n",
       "1  record_hash_b17e6fb2869a9309eaed4a7ff4ff7055   \n",
       "2  record_hash_ce1a7b27a23a487bbdc789b9622fe115   \n",
       "3  record_hash_6e595aecd248617542d11e29f2fcfcd4   \n",
       "4  record_hash_bd0ebe790090d258b67a9427d854ff3a   \n",
       "\n",
       "                                               input  \\\n",
       "0                   What is the right AI job for me?   \n",
       "1      Is it normal to find parts of AI challenging?   \n",
       "2             What are some common challenges in AI?   \n",
       "3     What is the first step to becoming good at AI?   \n",
       "4  Who are some accomplished individuals who have...   \n",
       "\n",
       "                                              output tags  \\\n",
       "0  The right AI job for you would be one that ali...    -   \n",
       "1      It is normal to find parts of AI challenging.    -   \n",
       "2  Common challenges in AI include understanding ...    -   \n",
       "3            Learning foundational technical skills.    -   \n",
       "4  Former Facebook COO Sheryl Sandberg, U.S. firs...    -   \n",
       "\n",
       "                                         record_json  ... Context Relevance  \\\n",
       "0  {'record_id': 'record_hash_50d04792bf32f7be0d9...  ...               NaN   \n",
       "1  {'record_id': 'record_hash_b17e6fb2869a9309eae...  ...               NaN   \n",
       "2  {'record_id': 'record_hash_ce1a7b27a23a487bbdc...  ...               NaN   \n",
       "3  {'record_id': 'record_hash_6e595aecd248617542d...  ...               NaN   \n",
       "4  {'record_id': 'record_hash_bd0ebe790090d258b67...  ...               NaN   \n",
       "\n",
       "  Context Relevance_calls Context Relevance feedback cost in USD  \\\n",
       "0                     NaN                                    NaN   \n",
       "1                     NaN                                    NaN   \n",
       "2                     NaN                                    NaN   \n",
       "3                     NaN                                    NaN   \n",
       "4                     NaN                                    NaN   \n",
       "\n",
       "   Groundedness Groundedness_calls  Groundedness feedback cost in USD  \\\n",
       "0           NaN                NaN                                NaN   \n",
       "1           NaN                NaN                                NaN   \n",
       "2           NaN                NaN                                NaN   \n",
       "3           NaN                NaN                                NaN   \n",
       "4           NaN                NaN                                NaN   \n",
       "\n",
       "    latency total_tokens  total_cost  cost_currency  \n",
       "0  0.793852         2182    0.003307            USD  \n",
       "1  0.511552         2129    0.003199            USD  \n",
       "2  0.769732         2123    0.003198            USD  \n",
       "3  0.649987         1727    0.002593            USD  \n",
       "4  0.714716         2143    0.003237            USD  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64310897-179b-4081-aab8-f08a3392a078",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7t/drc_5mxn3c96k2_3zc1n57yh0000gn/T/ipykernel_79109/1997498841.py:2: DeprecationWarning: Method `run_dashboard` has been renamed or moved to `trulens.dashboard.run.run_dashboard`.\n",
      "\n",
      "  tru.run_dashboard()\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f63e8a45ad0c47e6822246f6c53545e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(VBox(children=(VBox(children=(Label(value='STDOUT'), Output())), VBox(children=(Label(valuâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard started at http://localhost:57915 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# launches on http://localhost:8501/\n",
    "tru.run_dashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4eedcef",
   "metadata": {},
   "source": [
    "## Advanced RAG pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a17ea2b",
   "metadata": {},
   "source": [
    "### 1. Sentence Window retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dae4a668-3699-4750-82f7-e53ae1bca3a7",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from llama_index.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a0de73-638d-4e53-acd7-7b0d1b4c1996",
   "metadata": {},
   "source": [
    "## Replace build_sentence_window_index() & build_automerging_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e83f013-011f-4c14-948e-722cdd9f36f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add at top of file (imports)\n",
    "from llama_index.core import VectorStoreIndex, StorageContext, load_index_from_storage\n",
    "from llama_index.core.node_parser import SentenceWindowNodeParser\n",
    "from llama_index.core.postprocessor import MetadataReplacementPostProcessor, SentenceTransformerRerank\n",
    "#from llama_index.embeddings.huggingface_openai import HuggingFaceEmbedding\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "import os\n",
    "\n",
    "\n",
    "from llama_index.core.node_parser import HierarchicalNodeParser, get_leaf_nodes\n",
    "\n",
    "def _ensure_embed_model(embed_model):\n",
    "    # allow passing either a ready embedding object or a \"local:MODEL_NAME\" string (your current style)\n",
    "    if hasattr(embed_model, \"get_text_embedding\"):\n",
    "        return embed_model\n",
    "    if isinstance(embed_model, str):\n",
    "        if embed_model.startswith(\"local:\"):\n",
    "            return HuggingFaceEmbedding(model_name=embed_model.split(\"local:\", 1)[1])\n",
    "        else:\n",
    "            # treat as HF model name\n",
    "            return HuggingFaceEmbedding(model_name=embed_model)\n",
    "    raise ValueError(\"embed_model must be an embedding object or a model name string.\")\n",
    "\n",
    "def build_sentence_window_index(\n",
    "    document,\n",
    "    llm,\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
    "    save_dir=\"sentence_index\",\n",
    "):\n",
    "    # 1) node parsing\n",
    "    node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "        window_size=3,\n",
    "        window_metadata_key=\"window\",\n",
    "        original_text_metadata_key=\"original_text\",\n",
    "    )\n",
    "    nodes = node_parser.get_nodes_from_documents([document])\n",
    "\n",
    "    # 2) ensure embedding object\n",
    "    embed = _ensure_embed_model(embed_model)\n",
    "\n",
    "    # 3) build or load index (pass llm/embed directly; no ServiceContext)\n",
    "    if not os.path.exists(save_dir):\n",
    "        index = VectorStoreIndex(nodes, llm=llm, embed_model=embed)\n",
    "        index.storage_context.persist(persist_dir=save_dir)\n",
    "    else:\n",
    "        storage = StorageContext.from_defaults(persist_dir=save_dir)\n",
    "        index = load_index_from_storage(storage, llm=llm, embed_model=embed)\n",
    "\n",
    "    return index\n",
    "\n",
    "\n",
    "def build_automerging_index(\n",
    "    documents,\n",
    "    llm,\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
    "    save_dir=\"merging_index\",\n",
    "    chunk_sizes=None,\n",
    "):\n",
    "    chunk_sizes = chunk_sizes or [2048, 512, 128]\n",
    "\n",
    "    # 1) parse hierarchy â†’ leaf nodes\n",
    "    node_parser = HierarchicalNodeParser.from_defaults(chunk_sizes=chunk_sizes)\n",
    "    nodes = node_parser.get_nodes_from_documents(documents)\n",
    "    leaf_nodes = get_leaf_nodes(nodes)\n",
    "\n",
    "    # 2) ensure embedding object\n",
    "    embed = _ensure_embed_model(embed_model)\n",
    "\n",
    "    # 3) build or load index (no ServiceContext)\n",
    "    storage_context = StorageContext.from_defaults()\n",
    "    storage_context.docstore.add_documents(nodes)\n",
    "\n",
    "    if not os.path.exists(save_dir):\n",
    "        index = VectorStoreIndex(\n",
    "            leaf_nodes,\n",
    "            storage_context=storage_context,\n",
    "            llm=llm,\n",
    "            embed_model=embed,\n",
    "        )\n",
    "        index.storage_context.persist(persist_dir=save_dir)\n",
    "    else:\n",
    "        storage = StorageContext.from_defaults(persist_dir=save_dir)\n",
    "        index = load_index_from_storage(storage, llm=llm, embed_model=embed)\n",
    "\n",
    "    return index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78f7678f-358d-448d-b153-11ac8e96a7fc",
   "metadata": {
    "height": 149,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading llama_index.core.storage.kvstore.simple_kvstore from sentence_index/docstore.json.\n",
      "Loading llama_index.core.storage.kvstore.simple_kvstore from sentence_index/index_store.json.\n"
     ]
    }
   ],
   "source": [
    "#from utils import build_sentence_window_index\n",
    "\n",
    "sentence_index = build_sentence_window_index(\n",
    "    document,\n",
    "    llm,\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
    "    save_dir=\"sentence_index\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72f904c3-9845-4df5-9d2e-e5115160f987",
   "metadata": {
    "height": 64,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae0d7f34bef942199303fdfeb2420e69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/799 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54c948a963ca412aa5ae33347e39a2f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64e2cac9324c42c08d80d35abb206cae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/443 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dbec32403b94cd995388d3dc598b63b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bb6bdc2fc9645118a261bebbdc12c3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b12ace0056e049378f5b6e0d353dcd2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/279 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa913b51aad14bb5bbb350a4fd8dbd65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import get_sentence_window_query_engine\n",
    "\n",
    "sentence_window_engine = get_sentence_window_query_engine(sentence_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f59e2314-7cac-42f4-a552-9a8e4db641eb",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To get started on a personal project in AI, you can begin by identifying a project that aligns with your career goals and interests. It's important to choose a project that is responsible, ethical, and beneficial to people. Once you have selected a project, you can follow the steps outlined in the chapters provided, such as scoping the project, executing it with an eye toward career development, and building a portfolio that demonstrates skill progression. By following these guidelines, you can embark on a personal AI project that not only enhances your skills but also makes a positive impact in the field.\n"
     ]
    }
   ],
   "source": [
    "window_response = sentence_window_engine.query(\n",
    "    \"how do I get started on a personal project in AI?\"\n",
    ")\n",
    "print(str(window_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5c10917-8846-4e73-838d-6232c906a7db",
   "metadata": {
    "height": 115,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating app_name and app_version in apps table: 0it [00:00, ?it/s]\n",
      "Updating app_id in records table: 0it [00:00, ?it/s]\n",
      "Updating app_json in apps table: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.core.embeddings.multi_modal_base.MultiModalEmbedding'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.core.base.embeddings.base.BaseEmbedding'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.core.schema.TransformComponent'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index_instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.callbacks.base.CallbackManager'> for base <class 'llama_index.core.callbacks.base_handler.BaseCallbackHandler'>\n",
      "instrumenting <class 'llama_index.core.callbacks.base.CallbackManager'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.callbacks.base.CallbackManager'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'llama_index.core.vector_stores.types.BasePydanticVectorStore'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStoreData'> for base <class 'dataclasses_json.api.DataClassJsonMixin'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStoreData'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStoreData'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'llama_index.core.indices.base.BaseIndex'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'typing.Generic'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> for base <class 'llama_index.core.graph_stores.types.GraphStore'>\n",
      "instrumenting <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> for base <class 'typing.Protocol'>\n",
      "instrumenting <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> for base <class 'typing.Generic'>\n",
      "instrumenting <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.node_parser.interface.MetadataAwareTextSplitter'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.node_parser.interface.TextSplitter'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.node_parser.interface.NodeParser'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.schema.TransformComponent'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index_instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> for base <class 'llama_index.core.storage.docstore.keyval_docstore.KVDocumentStore'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> for base <class 'llama_index.core.storage.docstore.types.BaseDocumentStore'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.data_structs.data_structs.IndexDict'> for base <class 'llama_index.core.data_structs.data_structs.IndexStruct'>\n",
      "instrumenting <class 'llama_index.core.data_structs.data_structs.IndexDict'> for base <class 'dataclasses_json.api.DataClassJsonMixin'>\n",
      "instrumenting <class 'llama_index.core.data_structs.data_structs.IndexDict'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.data_structs.data_structs.IndexDict'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.storage.storage_context.StorageContext'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'>\n",
      "\tinstrumenting retrieve\n",
      "\tinstrumenting _retrieve\n",
      "\tinstrumenting _aretrieve\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.base.base_retriever.BaseRetriever'>\n",
      "\tinstrumenting retrieve\n",
      "\tinstrumenting _retrieve\n",
      "\tinstrumenting _aretrieve\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.prompts.mixin.PromptMixin'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index_instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.llms.openai.base.OpenAI'>\n",
      "\tinstrumenting chat\n",
      "\tinstrumenting complete\n",
      "\tinstrumenting stream_chat\n",
      "\tinstrumenting stream_complete\n",
      "\tinstrumenting achat\n",
      "\tinstrumenting acomplete\n",
      "\tinstrumenting astream_chat\n",
      "\tinstrumenting astream_complete\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.core.llms.function_calling.FunctionCallingLLM'>\n",
      "\tinstrumenting chat\n",
      "\tinstrumenting complete\n",
      "\tinstrumenting stream_chat\n",
      "\tinstrumenting stream_complete\n",
      "\tinstrumenting achat\n",
      "\tinstrumenting acomplete\n",
      "\tinstrumenting astream_chat\n",
      "\tinstrumenting astream_complete\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.core.llms.llm.LLM'>\n",
      "\tinstrumenting chat\n",
      "\tinstrumenting complete\n",
      "\tinstrumenting stream_chat\n",
      "\tinstrumenting stream_complete\n",
      "\tinstrumenting achat\n",
      "\tinstrumenting acomplete\n",
      "\tinstrumenting astream_chat\n",
      "\tinstrumenting astream_complete\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.core.base.llms.base.BaseLLM'>\n",
      "\tinstrumenting chat\n",
      "\tinstrumenting complete\n",
      "\tinstrumenting stream_chat\n",
      "\tinstrumenting stream_complete\n",
      "\tinstrumenting achat\n",
      "\tinstrumenting acomplete\n",
      "\tinstrumenting astream_chat\n",
      "\tinstrumenting astream_complete\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index_instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.base.llms.types.LLMMetadata'> for base <class 'llama_index.core.base.llms.types.LLMMetadata'>\n",
      "instrumenting <class 'llama_index.core.base.llms.types.LLMMetadata'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.base.llms.types.LLMMetadata'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.indices.prompt_helper.PromptHelper'> for base <class 'llama_index.core.indices.prompt_helper.PromptHelper'>\n",
      "instrumenting <class 'llama_index.core.indices.prompt_helper.PromptHelper'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.core.indices.prompt_helper.PromptHelper'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.indices.prompt_helper.PromptHelper'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'>\n",
      "\tinstrumenting get_response\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.response_synthesizers.refine.Refine'>\n",
      "\tinstrumenting get_response\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.response_synthesizers.base.BaseSynthesizer'>\n",
      "\tinstrumenting get_response\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.prompts.mixin.PromptMixin'>\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index_instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'llama_index.core.prompts.base.BasePromptTemplate'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'llama_index.core.prompts.base.BasePromptTemplate'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'>\n",
      "\tinstrumenting query\n",
      "\tinstrumenting aquery\n",
      "\tinstrumenting synthesize\n",
      "\tinstrumenting asynthesize\n",
      "\tinstrumenting retrieve\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.base.base_query_engine.BaseQueryEngine'>\n",
      "\tinstrumenting query\n",
      "\tinstrumenting aquery\n",
      "\tinstrumenting synthesize\n",
      "\tinstrumenting asynthesize\n",
      "\tinstrumenting retrieve\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.prompts.mixin.PromptMixin'>\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index_instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'> for base <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'>\n",
      "\tinstrumenting _postprocess_nodes\n",
      "instrumenting <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'> for base <class 'llama_index.core.postprocessor.types.BaseNodePostprocessor'>\n",
      "\tinstrumenting _postprocess_nodes\n",
      "instrumenting <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'> for base <class 'llama_index_instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.metadata_replacement.MetadataReplacementPostProcessor'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'> for base <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'>\n",
      "\tinstrumenting _postprocess_nodes\n",
      "instrumenting <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'> for base <class 'llama_index.core.postprocessor.types.BaseNodePostprocessor'>\n",
      "\tinstrumenting _postprocess_nodes\n",
      "instrumenting <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'> for base <class 'llama_index_instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'> for base <class 'object'>\n"
     ]
    }
   ],
   "source": [
    "tru.reset_database()\n",
    "\n",
    "tru_recorder_sentence_window = get_prebuilt_trulens_recorder(\n",
    "    sentence_window_engine,\n",
    "    app_id = \"Sentence Window Query Engine\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "11710e67-aba8-479e-8585-c4c611e2c1d2",
   "metadata": {
    "height": 98,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the keys to building a career in AI?\n",
      "Keys to building a career in AI include developing a portfolio of projects that demonstrate skill progression, using informational interviews to find the right job, and overcoming imposter syndrome.\n",
      "How can teamwork contribute to success in AI?\n",
      "Teamwork can contribute to success in AI by allowing individuals to leverage the diverse skills and perspectives of their colleagues. This collaboration can lead to more innovative solutions, better problem-solving, and overall project improvement. Additionally, working in a team can create a supportive environment that fosters continuous learning and growth, ultimately enhancing the quality of the AI projects being developed.\n",
      "What is the importance of networking in AI?\n",
      "Networking in AI is crucial as it can provide valuable insights, guidance, and opportunities for individuals looking to advance in the field. By connecting with professionals who have experience in AI, individuals can gain knowledge about the industry, potential career paths, and current trends. Networking also allows individuals to build relationships with others in the field, which can lead to mentorship, collaboration on projects, and even job opportunities. Additionally, networking can help individuals stay informed about the evolving nature of AI and the varied job roles within the industry.\n",
      "What are some good habits to develop for a successful career?\n",
      "Developing good habits in eating, exercise, sleep, personal relationships, work, learning, and self-care can help individuals move forward in their careers while staying healthy. Additionally, aiming to lift others during every step of one's own journey can lead to better outcomes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ytchen/Documents/experimental/AdvancedRAG/.venv/lib/python3.11/site-packages/trulens/feedback/llm_provider.py:1966: UserWarning: Failed to process and remove trivial statements. Proceeding with all statements.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can altruism be beneficial in building a career?\n",
      "Helping others along the way can actually benefit one's career development.\n",
      "What is imposter syndrome and how does it relate to AI?\n",
      "Imposter syndrome is a phenomenon where individuals doubt their accomplishments and have a persistent fear of being exposed as a fraud. In the context of AI, newcomers to the field may experience imposter syndrome, feeling like they do not truly belong in the AI community despite their success. This can be a common experience for many people in various fields, including AI, and it is important to address and overcome these feelings to continue growing and contributing effectively in the field.\n",
      "Who are some accomplished individuals who have experienced imposter syndrome?\n",
      "Former Facebook COO Sheryl Sandberg, U.S. first lady Michelle Obama, actor Tom Hanks, and Atlassian co-CEO Mike Cannon-Brookes.\n",
      "What is the first step to becoming good at AI?\n",
      "The first step to becoming good at AI is learning foundational technical skills.\n",
      "What are some common challenges in AI?\n",
      "Common challenges in AI include the evolving nature of technologies, the need to stay updated with rapidly changing technology, the difficulty in estimating project timelines and returns on investment, the iterative nature of AI projects leading to uncertainties in project management, the necessity to collaborate with stakeholders lacking AI expertise, and the challenge of finding suitable AI skills for hiring in companies.\n",
      "Is it normal to find parts of AI challenging?\n",
      "It is normal to find parts of AI challenging.\n",
      "What is the right AI job for me?\n",
      "The right AI job for you can be found by following the steps outlined in Chapter 9: Finding the Right AI Job for You.\n"
     ]
    }
   ],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder_sentence_window as recording:\n",
    "        response = sentence_window_engine.query(question)\n",
    "        print(question)\n",
    "        print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "869d1e55-729b-45f2-a0f9-773c49d4616f",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_name</th>\n",
       "      <th>app_version</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sentence Window Query Engine</th>\n",
       "      <th>base</th>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>1.29267</td>\n",
       "      <td>0.000785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Answer Relevance  Context Relevance  \\\n",
       "app_name                     app_version                                        \n",
       "Sentence Window Query Engine base                 0.916667           0.388889   \n",
       "\n",
       "                                          Groundedness  latency  total_cost  \n",
       "app_name                     app_version                                     \n",
       "Sentence Window Query Engine base               0.5625  1.29267    0.000785  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b92d0f2-2e80-48d5-92af-b3655eb03ea2",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n",
      "Dashboard already running at path:   Local URL: http://localhost:57915\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# launches on http://localhost:8501/\n",
    "tru.run_dashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92e2c55",
   "metadata": {},
   "source": [
    "### 2. Auto-merging retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "558c639b-31eb-4c34-b6c4-fe6ae5717733",
   "metadata": {
    "height": 149,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading llama_index.core.storage.kvstore.simple_kvstore from merging_index/docstore.json.\n",
      "Loading llama_index.core.storage.kvstore.simple_kvstore from merging_index/index_store.json.\n"
     ]
    }
   ],
   "source": [
    "#from utils import build_automerging_index\n",
    "\n",
    "automerging_index = build_automerging_index(\n",
    "    documents,\n",
    "    llm,\n",
    "    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n",
    "    save_dir=\"merging_index\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b32265f2-0247-42df-9abe-97d52f69edcf",
   "metadata": {
    "height": 98,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import get_automerging_query_engine\n",
    "\n",
    "automerging_query_engine = get_automerging_query_engine(\n",
    "    automerging_index,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "918ed568-220e-4c7c-aa60-cfa58ef1fcbd",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: 31c89103-15e0-4fd8-a7b5-8763062be6af.\n",
      "> Parent node text: PAGE 21Building a Portfolio of \n",
      "Projects that Shows \n",
      "Skill Progression CHAPTER 6\n",
      "PROJECTS\n",
      "\n",
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: f78aa493-30e2-4d7e-8045-6ee68573344f.\n",
      "> Parent node text: PAGE 21Building a Portfolio of \n",
      "Projects that Shows \n",
      "Skill Progression CHAPTER 6\n",
      "PROJECTS\n",
      "\n",
      "Building a portfolio of AI projects involves showcasing a progression from simple to complex undertakings over time. It is important to be able to communicate your thinking effectively to demonstrate the value of your work and gain trust from others. Identifying ideas that are worth working on is a crucial skill for an AI architect, and working on projects across various industries can help in gaining experience and diversifying your portfolio.\n"
     ]
    }
   ],
   "source": [
    "auto_merging_response = automerging_query_engine.query(\n",
    "    \"How do I build a portfolio of AI projects?\"\n",
    ")\n",
    "print(str(auto_merging_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "db4f18a9-7b8a-4ae2-ab11-3a6a941a5afc",
   "metadata": {
    "height": 81,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating app_name and app_version in apps table: 0it [00:00, ?it/s]\n",
      "Updating app_id in records table: 0it [00:00, ?it/s]\n",
      "Updating app_json in apps table: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.core.embeddings.multi_modal_base.MultiModalEmbedding'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.core.base.embeddings.base.BaseEmbedding'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.core.schema.TransformComponent'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'llama_index_instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.embeddings.huggingface.base.HuggingFaceEmbedding'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.callbacks.base.CallbackManager'> for base <class 'llama_index.core.callbacks.base_handler.BaseCallbackHandler'>\n",
      "instrumenting <class 'llama_index.core.callbacks.base.CallbackManager'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.callbacks.base.CallbackManager'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'llama_index.core.vector_stores.types.BasePydanticVectorStore'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStore'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStoreData'> for base <class 'dataclasses_json.api.DataClassJsonMixin'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStoreData'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.vector_stores.simple.SimpleVectorStoreData'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'llama_index.core.indices.base.BaseIndex'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'typing.Generic'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> for base <class 'llama_index.core.graph_stores.types.GraphStore'>\n",
      "instrumenting <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> for base <class 'typing.Protocol'>\n",
      "instrumenting <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> for base <class 'typing.Generic'>\n",
      "instrumenting <class 'llama_index.core.graph_stores.simple.SimpleGraphStore'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.node_parser.interface.MetadataAwareTextSplitter'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.node_parser.interface.TextSplitter'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.node_parser.interface.NodeParser'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.schema.TransformComponent'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'llama_index_instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.node_parser.text.sentence.SentenceSplitter'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> for base <class 'llama_index.core.storage.docstore.keyval_docstore.KVDocumentStore'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> for base <class 'llama_index.core.storage.docstore.types.BaseDocumentStore'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.data_structs.data_structs.IndexDict'> for base <class 'llama_index.core.data_structs.data_structs.IndexStruct'>\n",
      "instrumenting <class 'llama_index.core.data_structs.data_structs.IndexDict'> for base <class 'dataclasses_json.api.DataClassJsonMixin'>\n",
      "instrumenting <class 'llama_index.core.data_structs.data_structs.IndexDict'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.data_structs.data_structs.IndexDict'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.storage.storage_context.StorageContext'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'>\n",
      "\tinstrumenting retrieve\n",
      "\tinstrumenting _retrieve\n",
      "\tinstrumenting _aretrieve\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.base.base_retriever.BaseRetriever'>\n",
      "\tinstrumenting retrieve\n",
      "\tinstrumenting _retrieve\n",
      "\tinstrumenting _aretrieve\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index.core.prompts.mixin.PromptMixin'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'llama_index_instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.indices.vector_store.retrievers.retriever.VectorIndexRetriever'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.retrievers.auto_merging_retriever.AutoMergingRetriever'> for base <class 'llama_index.core.retrievers.auto_merging_retriever.AutoMergingRetriever'>\n",
      "\tinstrumenting retrieve\n",
      "\tinstrumenting _retrieve\n",
      "\tinstrumenting _aretrieve\n",
      "instrumenting <class 'llama_index.core.retrievers.auto_merging_retriever.AutoMergingRetriever'> for base <class 'llama_index.core.base.base_retriever.BaseRetriever'>\n",
      "\tinstrumenting retrieve\n",
      "\tinstrumenting _retrieve\n",
      "\tinstrumenting _aretrieve\n",
      "instrumenting <class 'llama_index.core.retrievers.auto_merging_retriever.AutoMergingRetriever'> for base <class 'llama_index.core.prompts.mixin.PromptMixin'>\n",
      "instrumenting <class 'llama_index.core.retrievers.auto_merging_retriever.AutoMergingRetriever'> for base <class 'llama_index_instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.retrievers.auto_merging_retriever.AutoMergingRetriever'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.retrievers.auto_merging_retriever.AutoMergingRetriever'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.callbacks.base.CallbackManager'> for base <class 'llama_index.core.callbacks.base_handler.BaseCallbackHandler'>\n",
      "instrumenting <class 'llama_index.core.callbacks.base.CallbackManager'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.callbacks.base.CallbackManager'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.llms.openai.base.OpenAI'>\n",
      "\tinstrumenting chat\n",
      "\tinstrumenting complete\n",
      "\tinstrumenting stream_chat\n",
      "\tinstrumenting stream_complete\n",
      "\tinstrumenting achat\n",
      "\tinstrumenting acomplete\n",
      "\tinstrumenting astream_chat\n",
      "\tinstrumenting astream_complete\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.core.llms.function_calling.FunctionCallingLLM'>\n",
      "\tinstrumenting chat\n",
      "\tinstrumenting complete\n",
      "\tinstrumenting stream_chat\n",
      "\tinstrumenting stream_complete\n",
      "\tinstrumenting achat\n",
      "\tinstrumenting acomplete\n",
      "\tinstrumenting astream_chat\n",
      "\tinstrumenting astream_complete\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.core.llms.llm.LLM'>\n",
      "\tinstrumenting chat\n",
      "\tinstrumenting complete\n",
      "\tinstrumenting stream_chat\n",
      "\tinstrumenting stream_complete\n",
      "\tinstrumenting achat\n",
      "\tinstrumenting acomplete\n",
      "\tinstrumenting astream_chat\n",
      "\tinstrumenting astream_complete\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.core.base.llms.base.BaseLLM'>\n",
      "\tinstrumenting chat\n",
      "\tinstrumenting complete\n",
      "\tinstrumenting stream_chat\n",
      "\tinstrumenting stream_complete\n",
      "\tinstrumenting achat\n",
      "\tinstrumenting acomplete\n",
      "\tinstrumenting astream_chat\n",
      "\tinstrumenting astream_complete\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'llama_index_instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.llms.openai.base.OpenAI'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.base.llms.types.LLMMetadata'> for base <class 'llama_index.core.base.llms.types.LLMMetadata'>\n",
      "instrumenting <class 'llama_index.core.base.llms.types.LLMMetadata'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.base.llms.types.LLMMetadata'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.indices.prompt_helper.PromptHelper'> for base <class 'llama_index.core.indices.prompt_helper.PromptHelper'>\n",
      "instrumenting <class 'llama_index.core.indices.prompt_helper.PromptHelper'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.core.indices.prompt_helper.PromptHelper'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.indices.prompt_helper.PromptHelper'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'>\n",
      "\tinstrumenting get_response\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.response_synthesizers.refine.Refine'>\n",
      "\tinstrumenting get_response\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.response_synthesizers.base.BaseSynthesizer'>\n",
      "\tinstrumenting get_response\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index.core.prompts.mixin.PromptMixin'>\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'llama_index_instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.response_synthesizers.compact_and_refine.CompactAndRefine'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'llama_index.core.prompts.base.BasePromptTemplate'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'llama_index.core.prompts.base.BasePromptTemplate'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.prompts.base.SelectorPromptTemplate'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'>\n",
      "\tinstrumenting query\n",
      "\tinstrumenting aquery\n",
      "\tinstrumenting synthesize\n",
      "\tinstrumenting asynthesize\n",
      "\tinstrumenting retrieve\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.base.base_query_engine.BaseQueryEngine'>\n",
      "\tinstrumenting query\n",
      "\tinstrumenting aquery\n",
      "\tinstrumenting synthesize\n",
      "\tinstrumenting asynthesize\n",
      "\tinstrumenting retrieve\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index.core.prompts.mixin.PromptMixin'>\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'llama_index_instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.query_engine.retriever_query_engine.RetrieverQueryEngine'> for base <class 'object'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'> for base <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'>\n",
      "\tinstrumenting _postprocess_nodes\n",
      "instrumenting <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'> for base <class 'llama_index.core.postprocessor.types.BaseNodePostprocessor'>\n",
      "\tinstrumenting _postprocess_nodes\n",
      "instrumenting <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'> for base <class 'llama_index.core.schema.BaseComponent'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'> for base <class 'pydantic.main.BaseModel'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'> for base <class 'llama_index_instrumentation.DispatcherSpanMixin'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'> for base <class 'abc.ABC'>\n",
      "instrumenting <class 'llama_index.core.postprocessor.sbert_rerank.SentenceTransformerRerank'> for base <class 'object'>\n"
     ]
    }
   ],
   "source": [
    "tru.reset_database()\n",
    "\n",
    "tru_recorder_automerging = get_prebuilt_trulens_recorder(automerging_query_engine,\n",
    "                                                         app_id=\"Automerging Query Engine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "99cc2cfe-7096-4fa0-aa72-094bebac35a3",
   "metadata": {
    "height": 98,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Merging 2 nodes into parent node.\n",
      "> Parent node id: b46bba4d-5db4-4ae7-b67e-bcedd7e2e1e2.\n",
      "> Parent node text: PAGE 3Table of \n",
      "ContentsIntroduction: Coding AI is the New Literacy.\n",
      "Chapter 1: Three Steps to Ca...\n",
      "\n",
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: 6f8b3671-b30a-4e55-8524-bc025db7f587.\n",
      "> Parent node text: PAGE 3Table of \n",
      "ContentsIntroduction: Coding AI is the New Literacy.\n",
      "Chapter 1: Three Steps to Ca...\n",
      "\n",
      "What are the keys to building a career in AI?\n",
      "The keys to building a career in AI include learning foundational technical skills, working on projects, finding a job, being part of a community, prioritizing topic selection when learning, and collaborating effectively with others in team settings.\n",
      "How can teamwork contribute to success in AI?\n",
      "Teamwork can contribute to success in AI by enhancing the ability to collaborate effectively with others, influence team members, and be influenced by them. This collaboration allows for a more comprehensive approach to tackling large projects, which can lead to better outcomes than working individually.\n",
      "> Merging 3 nodes into parent node.\n",
      "> Parent node id: 70681275-23cd-457c-af3d-0e3c9c3390dc.\n",
      "> Parent node text: PAGE 35Keys to Building a Career in AI CHAPTER 10\n",
      "The path to career success in AI is more comple...\n",
      "\n",
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: 2288b31d-ea8c-4955-949d-61b3ec8dc16c.\n",
      "> Parent node text: PAGE 35Keys to Building a Career in AI CHAPTER 10\n",
      "The path to career success in AI is more comple...\n",
      "\n",
      "What is the importance of networking in AI?\n",
      "Networking in AI is crucial as it helps in building a strong professional network within the industry. This network can provide support, guidance, and opportunities for career advancement. By connecting with others in the field, individuals can gain valuable insights, stay updated on industry trends, and potentially find mentors who can help them navigate their career paths effectively.\n",
      "> Merging 2 nodes into parent node.\n",
      "> Parent node id: ec084901-f597-4899-bb3e-6b892f4558e2.\n",
      "> Parent node text: PAGE 36Keys to Building a Career in AI CHAPTER 10\n",
      "Of all the steps in building a career, this \n",
      "on...\n",
      "\n",
      "> Merging 2 nodes into parent node.\n",
      "> Parent node id: ebc3e306-61e1-4770-b7b4-ab46353c6b8f.\n",
      "> Parent node text: PAGE 11\n",
      "The Best Way to Build \n",
      "a New Habit\n",
      "One of my favorite books is BJ Foggâ€™s, Tiny Habits: Th...\n",
      "\n",
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: 35ff94c4-042d-441c-b813-c5fea9dbc7de.\n",
      "> Parent node text: PAGE 36Keys to Building a Career in AI CHAPTER 10\n",
      "Of all the steps in building a career, this \n",
      "on...\n",
      "\n",
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: 3ac0313f-5f7b-4626-b590-a0f317732e8f.\n",
      "> Parent node text: PAGE 11\n",
      "The Best Way to Build \n",
      "a New Habit\n",
      "One of my favorite books is BJ Foggâ€™s, Tiny Habits: Th...\n",
      "\n",
      "What are some good habits to develop for a successful career?\n",
      "Good habits to develop for a successful career include habits related to eating well, exercising regularly, getting enough sleep, maintaining positive personal relationships, consistently working towards learning and self-improvement, and practicing self-care. These habits can help individuals progress in their careers while also ensuring their overall well-being.\n",
      "> Merging 2 nodes into parent node.\n",
      "> Parent node id: acd58c6e-2fd9-4a34-b54b-a338a24d8599.\n",
      "> Parent node text: PAGE 30Finding someone to interview isnâ€™t always easy, but many people who are in senior position...\n",
      "\n",
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: 0baea2e2-63a9-4ef7-aed6-31df81bd4b32.\n",
      "> Parent node text: PAGE 30Finding someone to interview isnâ€™t always easy, but many people who are in senior position...\n",
      "\n",
      "How can altruism be beneficial in building a career?\n",
      "Altruism can be beneficial in building a career by creating opportunities for networking and mentorship. By helping others and lifting them up during their journey, individuals can establish strong relationships within their industry. This can lead to receiving support and guidance from more experienced professionals, opening doors to new opportunities and potential collaborations. Additionally, practicing altruism can enhance one's reputation and credibility, making them more attractive to potential employers or collaborators.\n",
      "> Merging 5 nodes into parent node.\n",
      "> Parent node id: 96eba374-d01a-48fc-b0b3-74f6f6508f7c.\n",
      "> Parent node text: PAGE 38Before we dive into the final chapter of this book, Iâ€™d like to address the serious matter...\n",
      "\n",
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: 70a5705c-983b-4f04-bbc7-4336206d4564.\n",
      "> Parent node text: PAGE 37Overcoming Imposter \n",
      "SyndromeCHAPTER 11\n",
      "\n",
      "> Merging 3 nodes into parent node.\n",
      "> Parent node id: c6f2a6d3-f45f-4730-9e96-ba55e3f77f70.\n",
      "> Parent node text: PAGE 39My three-year-old daughter (who can barely count to 12) regularly tries to teach things to...\n",
      "\n",
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: 4a2ef1cf-5f04-4a9f-9475-2810bf04fa7e.\n",
      "> Parent node text: PAGE 38Before we dive into the final chapter of this book, Iâ€™d like to address the serious matter...\n",
      "\n",
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: b50ac343-bf5a-4fee-b804-ba6f281683df.\n",
      "> Parent node text: PAGE 37Overcoming Imposter \n",
      "SyndromeCHAPTER 11\n",
      "\n",
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: 1f0671ae-49a8-4710-81fd-3daab344d92a.\n",
      "> Parent node text: PAGE 39My three-year-old daughter (who can barely count to 12) regularly tries to teach things to...\n",
      "\n",
      "What is imposter syndrome and how does it relate to AI?\n",
      "Imposter syndrome is when individuals doubt their accomplishments and have a persistent fear of being exposed as a fraud, despite evidence of their competence. In the context of AI, newcomers to the field may experience imposter syndrome due to the technical complexity and the presence of highly capable individuals. It is highlighted that imposter syndrome is common even among accomplished people in the AI community, and the message is to not let it discourage anyone from pursuing growth in AI.\n",
      "> Merging 3 nodes into parent node.\n",
      "> Parent node id: 96eba374-d01a-48fc-b0b3-74f6f6508f7c.\n",
      "> Parent node text: PAGE 38Before we dive into the final chapter of this book, Iâ€™d like to address the serious matter...\n",
      "\n",
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: 70a5705c-983b-4f04-bbc7-4336206d4564.\n",
      "> Parent node text: PAGE 37Overcoming Imposter \n",
      "SyndromeCHAPTER 11\n",
      "\n",
      "> Merging 3 nodes into parent node.\n",
      "> Parent node id: c6f2a6d3-f45f-4730-9e96-ba55e3f77f70.\n",
      "> Parent node text: PAGE 39My three-year-old daughter (who can barely count to 12) regularly tries to teach things to...\n",
      "\n",
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: 4a2ef1cf-5f04-4a9f-9475-2810bf04fa7e.\n",
      "> Parent node text: PAGE 38Before we dive into the final chapter of this book, Iâ€™d like to address the serious matter...\n",
      "\n",
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: b50ac343-bf5a-4fee-b804-ba6f281683df.\n",
      "> Parent node text: PAGE 37Overcoming Imposter \n",
      "SyndromeCHAPTER 11\n",
      "\n",
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: 1f0671ae-49a8-4710-81fd-3daab344d92a.\n",
      "> Parent node text: PAGE 39My three-year-old daughter (who can barely count to 12) regularly tries to teach things to...\n",
      "\n",
      "Who are some accomplished individuals who have experienced imposter syndrome?\n",
      "Sheryl Sandberg, Michelle Obama, Tom Hanks, and Mike Cannon-Brookes are some accomplished individuals who have experienced imposter syndrome.\n",
      "What is the first step to becoming good at AI?\n",
      "The first step to becoming good at AI is to suck at it.\n",
      "What are some common challenges in AI?\n",
      "Some common challenges in AI include the highly iterative nature of AI projects, which can make it difficult to plan accurately for building a system, and technical challenges that many individuals face when working on AI projects.\n",
      "> Merging 3 nodes into parent node.\n",
      "> Parent node id: 96eba374-d01a-48fc-b0b3-74f6f6508f7c.\n",
      "> Parent node text: PAGE 38Before we dive into the final chapter of this book, Iâ€™d like to address the serious matter...\n",
      "\n",
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: 4a2ef1cf-5f04-4a9f-9475-2810bf04fa7e.\n",
      "> Parent node text: PAGE 38Before we dive into the final chapter of this book, Iâ€™d like to address the serious matter...\n",
      "\n",
      "Is it normal to find parts of AI challenging?\n",
      "It is normal to find parts of AI challenging.\n",
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: 9b767b57-3f54-480e-a22d-88544e272d88.\n",
      "> Parent node text: PAGE 31Finding the Right \n",
      "AI Job for YouCHAPTER 9\n",
      "JOBS\n",
      "\n",
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: 3dea01ae-acb4-4191-aaf4-6bda30071cad.\n",
      "> Parent node text: If youâ€™re leaving \n",
      "a job, exit gracefully. Give your employer ample notice, give your full effort...\n",
      "\n",
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: d062e0ce-9515-4133-bb23-d9063fb78bf1.\n",
      "> Parent node text: PAGE 28Using Informational \n",
      "Interviews to Find \n",
      "the Right JobCHAPTER 8\n",
      "JOBS\n",
      "\n",
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: c6e3a541-8520-45f6-b78a-412f0f82bc20.\n",
      "> Parent node text: PAGE 31Finding the Right \n",
      "AI Job for YouCHAPTER 9\n",
      "JOBS\n",
      "\n",
      "> Merging 1 nodes into parent node.\n",
      "> Parent node id: 7362375c-617d-4f5d-b8a1-cd44fb904509.\n",
      "> Parent node text: PAGE 28Using Informational \n",
      "Interviews to Find \n",
      "the Right JobCHAPTER 8\n",
      "JOBS\n",
      "\n",
      "What is the right AI job for me?\n",
      "The right AI job for you would likely involve transitioning into a role or industry that aligns with your current expertise or experience. It may be easier to switch either roles or industries first before attempting to switch both simultaneously when looking for your first job in AI.\n"
     ]
    }
   ],
   "source": [
    "for question in eval_questions:\n",
    "    with tru_recorder_automerging as recording:\n",
    "        response = automerging_query_engine.query(question)\n",
    "        print(question)\n",
    "        print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5404dec1-60ca-42fa-ac13-793a5423aa64",
   "metadata": {
    "height": 30,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Groundedness</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>app_name</th>\n",
       "      <th>app_version</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Automerging Query Engine</th>\n",
       "      <th>base</th>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>1.213081</td>\n",
       "      <td>0.000862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Answer Relevance  Context Relevance  \\\n",
       "app_name                 app_version                                        \n",
       "Automerging Query Engine base                 0.888889           0.555556   \n",
       "\n",
       "                                      Groundedness   latency  total_cost  \n",
       "app_name                 app_version                                      \n",
       "Automerging Query Engine base             0.645833  1.213081    0.000862  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tru.get_leaderboard(app_ids=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0f545d41-0d98-446f-8214-8b59bef08d6c",
   "metadata": {
    "height": 47,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n",
      "Dashboard already running at path:   Local URL: http://localhost:57915\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# launches on http://localhost:8501/\n",
    "tru.run_dashboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c06330-20b9-41a8-ae7a-f3aa61ebc786",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (RAG)",
   "language": "python",
   "name": "beeai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
