{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa43f487-7649-486c-8818-13134a36cc1f",
   "metadata": {},
   "source": [
    "# L5: Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a880d1-48c3-4099-ac29-7db9cd6dc3dc",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff6e4; padding:15px; border-width:3px; border-color:#f5ecda; border-style:solid; border-radius:6px\"> ‚è≥ <b>Note <code>(Kernel Starting)</code>:</b> This notebook takes about 30 seconds to be ready to use. You may start and watch the video while you wait.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af9bd43a-fe0d-4199-b20f-3ca0c85d2875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#!{sys.executable} -m pip install tiktoken\n",
    "#!{sys.executable} -m pip install torch\n",
    "#!{sys.executable} -m pip install blobfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "516d8dc0-88c8-4f5b-976a-953239876e1d",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56ba58f-d67b-47ee-8597-5bee85e987ce",
   "metadata": {},
   "source": [
    "## Initialize tiktoken tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10adcf23-3f2b-4df7-85cb-6808cb9ed394",
   "metadata": {
    "height": 676
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import tiktoken\n",
    "from tiktoken.load import load_tiktoken_bpe\n",
    "import torch\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tokenizer_path = \"./content/tokenizer.model\"\n",
    "num_reserved_special_tokens = 256\n",
    "\n",
    "mergeable_ranks = load_tiktoken_bpe(tokenizer_path)\n",
    "\n",
    "num_base_tokens = len(mergeable_ranks)\n",
    "special_tokens = [\n",
    "    \"<|begin_of_text|>\",\n",
    "    \"<|end_of_text|>\",\n",
    "    \"<|reserved_special_token_0|>\",\n",
    "    \"<|reserved_special_token_1|>\",\n",
    "    \"<|finetune_right_pad_id|>\",\n",
    "    \"<|step_id|>\",\n",
    "    \"<|start_header_id|>\",\n",
    "    \"<|end_header_id|>\",\n",
    "    \"<|eom_id|>\",\n",
    "    \"<|eot_id|>\",\n",
    "    \"<|python_tag|>\",\n",
    "]\n",
    "reserved_tokens = [\n",
    "    f\"<|reserved_special_token_{2 + i}|>\"\n",
    "    for i in range(num_reserved_special_tokens - len(special_tokens))\n",
    "]\n",
    "special_tokens = special_tokens + reserved_tokens\n",
    "\n",
    "# source: https://github.com/meta-llama/llama-models/blob/main/models/llama3/api/tokenizer.py#L53\n",
    "tokenizer = tiktoken.Encoding(\n",
    "    name=Path(tokenizer_path).name,\n",
    "    pat_str=r\"(?i:'s|'t|'re|'ve|'m|'ll|'d)|[^\\r\\n\\p{L}\\p{N}]?\\p{L}+|\\p{N}{1,3}| ?[^\\s\\p{L}\\p{N}]+[\\r\\n]*|\\s*[\\r\\n]+|\\s+(?!\\S)|\\s+\",\n",
    "    mergeable_ranks=mergeable_ranks,\n",
    "    special_tokens={token: len(mergeable_ranks) + i for i, token in enumerate(special_tokens)},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "190fa04b-af53-401d-a0eb-1fd9f03a2dad",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15339]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9f8cb2a-a18b-4daa-9dd1-5f287ad55ffe",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([15339])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9e19f39-0a11-4ad6-921d-69711dffad36",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15339, 13929]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"hello Andrew\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9f1186e-9aaf-473a-8e2d-86e55b15d70f",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15339, 323, 4361]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"hello andrew\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce38afd6-2130-4c86-82de-c046ca6be9d2",
   "metadata": {},
   "source": [
    "### Tokens.ipynb\n",
    "If you would like to view a UTF-8 view of the Tokens.model file, uncomment the following line and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2033e2f3-3b81-4ac3-890d-c523c6436f22",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "#!cat Tokens.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3e7371-a9c2-4092-aaf2-db1b2fb5be2f",
   "metadata": {},
   "source": [
    "You can also go to file->open to find Tokens.ipynb file. Please note that the file is large and opening it might take some time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b4f561-2e7b-465e-8da0-e0148c631beb",
   "metadata": {
    "id": "InJMbvnb5F1a"
   },
   "source": [
    "## Getting the length of tokens of an input text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5438a5c5-9602-49d0-b327-6514dd334817",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 47,
    "id": "XTqQQEgq3_12",
    "outputId": "6b8d7489-4877-4c59-8888-518ca95ac2b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = \"hello world\"\n",
    "len(tokenizer.encode(input_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab8efbb4-6370-40e4-9615-f1eb597d980c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 149,
    "id": "k85mOcbv4TvL",
    "outputId": "a080269c-0d1f-4c86-da49-d81aaae51bea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Who wrote the book Charlotte's Web?\"\n",
    "prompt = f\"\"\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "{question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "\n",
    "encoded_tokens = tokenizer.encode(prompt, allowed_special=\"all\")\n",
    "len(encoded_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4c57fc0-f538-43de-9e82-858ec11b22a4",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128000 <|begin_of_text|>\n",
      "128006 <|start_header_id|>\n",
      "882 user\n",
      "128007 <|end_header_id|>\n",
      "271 \n",
      "\n",
      "\n",
      "15546 Who\n",
      "6267  wrote\n",
      "279  the\n",
      "2363  book\n",
      "29473  Charlotte\n",
      "596 's\n",
      "5000  Web\n",
      "30 ?\n",
      "128009 <|eot_id|>\n",
      "128006 <|start_header_id|>\n",
      "78191 assistant\n",
      "128007 <|end_header_id|>\n",
      "198 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "decoded_tokens = [tokenizer.decode([token]) for token in encoded_tokens]\n",
    "for e, d in zip(encoded_tokens, decoded_tokens):\n",
    "    print(e, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24b60cc2-6167-4eb2-84e2-fb850ae49454",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "from utils import html_tokens, llama31"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5920552b-70f5-4c5f-ac95-fbf2acc61b33",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff6ff; padding:15px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\"> üíª &nbsp; <b>Access <code>requirements.txt</code> and <code>utils.py</code> files:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em>. For more help, please see the <em>\"Appendix - Tips and Help\"</em> Lesson.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "235d5f1b-e8b9-4507-8785-03a1211cc9be",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "height": 30,
    "id": "89FPMUAsBfwG",
    "outputId": "57b2a29c-21f7-401b-e543-298ff34d1219"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"color: black; background-color: #ADE0FC; padding: 2px;\"><|begin_of_text|></span><span style=\"color: black; background-color: #FCE278; padding: 2px;\"><|start_header_id|></span><span style=\"color: black; background-color: #B2D1FE; padding: 2px;\">user</span><span style=\"color: black; background-color: #AFF7C6; padding: 2px;\"><|end_header_id|></span><span style=\"color: black; background-color: #FDCE9B; padding: 2px;\">\\n\\n</span><span style=\"color: black; background-color: #97F1FB; padding: 2px;\">Who</span><span style=\"color: black; background-color: #DEE1E7; padding: 2px;\"> wrote</span><span style=\"color: black; background-color: #E3C9FF; padding: 2px;\"> the</span><span style=\"color: black; background-color: #BBC6FD; padding: 2px;\"> book</span><span style=\"color: black; background-color: #D1FB8C; padding: 2px;\"> Charlotte</span><span style=\"color: black; background-color: #ADE0FC; padding: 2px;\">'s</span><span style=\"color: black; background-color: #FCE278; padding: 2px;\"> Web</span><span style=\"color: black; background-color: #B2D1FE; padding: 2px;\">?</span><span style=\"color: black; background-color: #AFF7C6; padding: 2px;\"><|eot_id|></span><span style=\"color: black; background-color: #FDCE9B; padding: 2px;\"><|start_header_id|></span><span style=\"color: black; background-color: #97F1FB; padding: 2px;\">assistant</span><span style=\"color: black; background-color: #DEE1E7; padding: 2px;\"><|end_header_id|></span><span style=\"color: black; background-color: #E3C9FF; padding: 2px;\">\\n</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(html_tokens(decoded_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e1a205b-c47a-4e24-a75d-2bf7a02a94db",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"color: black; background-color: #ADE0FC; padding: 2px;\">Sup</span><span style=\"color: black; background-color: #FCE278; padding: 2px;\">erc</span><span style=\"color: black; background-color: #B2D1FE; padding: 2px;\">al</span><span style=\"color: black; background-color: #AFF7C6; padding: 2px;\">if</span><span style=\"color: black; background-color: #FDCE9B; padding: 2px;\">rag</span><span style=\"color: black; background-color: #97F1FB; padding: 2px;\">il</span><span style=\"color: black; background-color: #DEE1E7; padding: 2px;\">istic</span><span style=\"color: black; background-color: #E3C9FF; padding: 2px;\">exp</span><span style=\"color: black; background-color: #BBC6FD; padding: 2px;\">ial</span><span style=\"color: black; background-color: #D1FB8C; padding: 2px;\">id</span><span style=\"color: black; background-color: #ADE0FC; padding: 2px;\">ocious</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Try one of you own:\n",
    "prompt = \"Supercalifragilisticexpialidocious\"\n",
    "encoded_tokens = tokenizer.encode(prompt, allowed_special=\"all\")\n",
    "decoded_tokens = [tokenizer.decode([token]) for token in encoded_tokens]\n",
    "display(HTML(html_tokens(decoded_tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d6cbeb-bae2-4c6d-9cae-e1f97db7808b",
   "metadata": {
    "id": "DygZtn-HBPUu"
   },
   "source": [
    "# LLM reasoning vs tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06d3ee99-3691-431f-91bf-1820475eef7e",
   "metadata": {
    "height": 149
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 r's in the word \"strawberry\".\n"
     ]
    }
   ],
   "source": [
    "question = \"How many r's in the word strawberry?\"\n",
    "prompt = f\"\"\"\n",
    "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "{question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "response = llama31(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88e93a64-0665-4f36-8194-5d7add849c5b",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"color: black; background-color: #ADE0FC; padding: 2px;\">\\n</span><span style=\"color: black; background-color: #FCE278; padding: 2px;\"><|begin_of_text|></span><span style=\"color: black; background-color: #B2D1FE; padding: 2px;\"><|start_header_id|></span><span style=\"color: black; background-color: #AFF7C6; padding: 2px;\">user</span><span style=\"color: black; background-color: #FDCE9B; padding: 2px;\"><|end_header_id|></span><span style=\"color: black; background-color: #97F1FB; padding: 2px;\">\\n\\n</span><span style=\"color: black; background-color: #DEE1E7; padding: 2px;\">How</span><span style=\"color: black; background-color: #E3C9FF; padding: 2px;\"> many</span><span style=\"color: black; background-color: #BBC6FD; padding: 2px;\"> r</span><span style=\"color: black; background-color: #D1FB8C; padding: 2px;\">'s</span><span style=\"color: black; background-color: #ADE0FC; padding: 2px;\"> in</span><span style=\"color: black; background-color: #FCE278; padding: 2px;\"> the</span><span style=\"color: black; background-color: #B2D1FE; padding: 2px;\"> word</span><span style=\"color: black; background-color: #AFF7C6; padding: 2px;\"> strawberry</span><span style=\"color: black; background-color: #FDCE9B; padding: 2px;\">?</span><span style=\"color: black; background-color: #97F1FB; padding: 2px;\"><|eot_id|></span><span style=\"color: black; background-color: #DEE1E7; padding: 2px;\"><|start_header_id|></span><span style=\"color: black; background-color: #E3C9FF; padding: 2px;\">assistant</span><span style=\"color: black; background-color: #BBC6FD; padding: 2px;\"><|end_header_id|></span><span style=\"color: black; background-color: #D1FB8C; padding: 2px;\">\\n</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_tokens = tokenizer.encode(prompt, allowed_special=\"all\")\n",
    "decoded_tokens = [tokenizer.decode([token]) for token in encoded_tokens]\n",
    "display(HTML(html_tokens(decoded_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e7bdc82-7570-48ee-8819-1673a93b3795",
   "metadata": {
    "height": 149
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 r's in the word \"strawberry\".\n"
     ]
    }
   ],
   "source": [
    "question = \"How many r's in the word s t r a w b e r r y? \"\n",
    "prompt = f\"\"\"\n",
    "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "{question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "response = llama31(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "173f5788-bf5a-4b45-8aad-a98e2c8f4a6f",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"color: black; background-color: #ADE0FC; padding: 2px;\">\\n</span><span style=\"color: black; background-color: #FCE278; padding: 2px;\"><|begin_of_text|></span><span style=\"color: black; background-color: #B2D1FE; padding: 2px;\"><|start_header_id|></span><span style=\"color: black; background-color: #AFF7C6; padding: 2px;\">user</span><span style=\"color: black; background-color: #FDCE9B; padding: 2px;\"><|end_header_id|></span><span style=\"color: black; background-color: #97F1FB; padding: 2px;\">\\n\\n</span><span style=\"color: black; background-color: #DEE1E7; padding: 2px;\">How</span><span style=\"color: black; background-color: #E3C9FF; padding: 2px;\"> many</span><span style=\"color: black; background-color: #BBC6FD; padding: 2px;\"> r</span><span style=\"color: black; background-color: #D1FB8C; padding: 2px;\">'s</span><span style=\"color: black; background-color: #ADE0FC; padding: 2px;\"> in</span><span style=\"color: black; background-color: #FCE278; padding: 2px;\"> the</span><span style=\"color: black; background-color: #B2D1FE; padding: 2px;\"> word</span><span style=\"color: black; background-color: #AFF7C6; padding: 2px;\"> s</span><span style=\"color: black; background-color: #FDCE9B; padding: 2px;\"> t</span><span style=\"color: black; background-color: #97F1FB; padding: 2px;\"> r</span><span style=\"color: black; background-color: #DEE1E7; padding: 2px;\"> a</span><span style=\"color: black; background-color: #E3C9FF; padding: 2px;\"> w</span><span style=\"color: black; background-color: #BBC6FD; padding: 2px;\"> b</span><span style=\"color: black; background-color: #D1FB8C; padding: 2px;\"> e</span><span style=\"color: black; background-color: #ADE0FC; padding: 2px;\"> r</span><span style=\"color: black; background-color: #FCE278; padding: 2px;\"> r</span><span style=\"color: black; background-color: #B2D1FE; padding: 2px;\"> y</span><span style=\"color: black; background-color: #AFF7C6; padding: 2px;\">?</span><span style=\"color: black; background-color: #FDCE9B; padding: 2px;\"> </span><span style=\"color: black; background-color: #97F1FB; padding: 2px;\"><|eot_id|></span><span style=\"color: black; background-color: #DEE1E7; padding: 2px;\"><|start_header_id|></span><span style=\"color: black; background-color: #E3C9FF; padding: 2px;\">assistant</span><span style=\"color: black; background-color: #BBC6FD; padding: 2px;\"><|end_header_id|></span><span style=\"color: black; background-color: #D1FB8C; padding: 2px;\">\\n</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_tokens = tokenizer.encode(prompt, allowed_special=\"all\")\n",
    "decoded_tokens = [tokenizer.decode([token]) for token in encoded_tokens]\n",
    "display(HTML(html_tokens(decoded_tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f996d88-5748-4fe4-ade4-47b8169db08c",
   "metadata": {},
   "source": [
    "# Extra examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c72f29-dd4d-41a4-83d4-5205a108283d",
   "metadata": {
    "id": "k-QJtnHBAekO"
   },
   "source": [
    "## Llama 3.1 tokenization model file demystification\n",
    "\n",
    "The Llama 3.1 tokenization model, named as tokenizer.model, can be downloaded along with the Llama 3.1 model weights or from the Llama models repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9269bc84-ba31-418d-92de-53d2ba5770bc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 47,
    "id": "nvKQX-E8JgB0",
    "outputId": "77a157ab-1bfb-40f5-e4d9-13eea7cb4465"
   },
   "outputs": [],
   "source": [
    "# download the Llama 3.1 tokenizer model\n",
    "#!wget https://raw.githubusercontent.com/meta-llama/llama-models/main/models/llama3/api/tokenizer.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6df0569-a8bc-4820-a61a-b16d24da5597",
   "metadata": {
    "id": "fvKOWlWpmE7F"
   },
   "source": [
    "If you take a quick look at the model file, you'll see it has 128,000 lines and each line has two values separated by a space: a mysterious string and a number that starts with 0 and ends with 127,999."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8c39d7a-adfc-4394-a919-053b5251809a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 30,
    "id": "V2w9tshTmt7z",
    "outputId": "6c8def0c-6d49-4de1-d286-33ac2f1754de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IQ== 0\n",
      "Ig== 1\n",
      "Iw== 2\n",
      "JA== 3\n",
      "JQ== 4\n",
      "Jg== 5\n",
      "Jw== 6\n",
      "KA== 7\n",
      "KQ== 8\n",
      "Kg== 9\n"
     ]
    }
   ],
   "source": [
    "!head -10 ./content/tokenizer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4142dfd3-d368-4c9c-9f0e-3d6e25872140",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 30,
    "id": "5V2V0-7Pmt-O",
    "outputId": "fa9a0a55-08a3-4838-af93-fb069a497be5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4LmM4LiB4Lij 127990\n",
      "zrbOsQ== 127991\n",
      "IOuNlOyasQ== 127992\n",
      "2YjZhNin2Ko= 127993\n",
      "0LLQsNGC0LjRgdGP 127994\n",
      "IGvDtms= 127995\n",
      "2YbYqA== 127996\n",
      "INCy0YvRgdC+0LrQvtC5 127997\n",
      "44O844O8 127998\n",
      "6ZSm 127999\n"
     ]
    }
   ],
   "source": [
    "!tail -10 ./content/tokenizer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e1815ba-d5fe-4cca-abe6-cc307c7c5598",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 30,
    "id": "SdqWumbTmuA5",
    "outputId": "6c11fa7a-c7fc-4370-b11c-f06ad4791634"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  128000 ./content/tokenizer.model\n"
     ]
    }
   ],
   "source": [
    "!wc -l ./content/tokenizer.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0e814c-bf8a-41da-82eb-42c9429de2a7",
   "metadata": {
    "id": "6fHCjwHvm24l"
   },
   "source": [
    "Each line indeed describes one token out of 128K total tokens and its associated integer ID, and the string on each line is base64 encoded. Use the code snippet below to decode those 128K encoded strings, and then convert the decoded bytes to more readable UTF-8 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7681feee-b4d0-4fae-a81c-405bd23d2de3",
   "metadata": {
    "height": 217,
    "id": "x89Mdqinb_Cv"
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "encoded_tokens = []\n",
    "decoded_byte_tokens = []\n",
    "decoded_utf8_tokens = []\n",
    "\n",
    "with open(\"./content/tokenizer.model\", 'r') as file:\n",
    "  for i, line in enumerate(file):\n",
    "    k, v = line.strip().split(' ')\n",
    "    encoded_tokens.append({k: v})\n",
    "    decoded_byte_tokens.append({base64.b64decode(k): v})\n",
    "    decoded_utf8_tokens.append({base64.b64decode(k).decode('utf-8', errors=\"replace\") : v})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ae39d9-9ee7-45c8-8d71-005b266619c0",
   "metadata": {
    "id": "JfuUILBIoNgc"
   },
   "source": [
    "Let's check the first ten encoded tokens (what's stored in the tokenizer.model), and their decoded byte and UTF-8 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80577ae9-f648-494c-9496-d3c1055c77dd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 30,
    "id": "Q6BrA-5JMfrH",
    "outputId": "34f88ab4-1976-4a32-aded-c83a4248848f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'IQ==': '0'},\n",
       " {'Ig==': '1'},\n",
       " {'Iw==': '2'},\n",
       " {'JA==': '3'},\n",
       " {'JQ==': '4'},\n",
       " {'Jg==': '5'},\n",
       " {'Jw==': '6'},\n",
       " {'KA==': '7'},\n",
       " {'KQ==': '8'},\n",
       " {'Kg==': '9'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(encoded_tokens)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "541c0a61-9bad-4c08-96c9-0cff710227ab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 30,
    "id": "n_FQjyZcMft-",
    "outputId": "637327fa-0733-4562-bf3d-6cff32c389da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{b'!': '0'},\n",
       " {b'\"': '1'},\n",
       " {b'#': '2'},\n",
       " {b'$': '3'},\n",
       " {b'%': '4'},\n",
       " {b'&': '5'},\n",
       " {b\"'\": '6'},\n",
       " {b'(': '7'},\n",
       " {b')': '8'},\n",
       " {b'*': '9'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(decoded_byte_tokens)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9df6456-fbcb-40d0-9468-277eddcf91b9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 30,
    "id": "rqr0ZSPuMfw1",
    "outputId": "616752a5-bbe6-488f-a10a-9fbfa17329b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'!': '0'},\n",
       " {'\"': '1'},\n",
       " {'#': '2'},\n",
       " {'$': '3'},\n",
       " {'%': '4'},\n",
       " {'&': '5'},\n",
       " {\"'\": '6'},\n",
       " {'(': '7'},\n",
       " {')': '8'},\n",
       " {'*': '9'}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(decoded_utf8_tokens)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd884a62-13db-420f-8c3f-5d33fa7b51cc",
   "metadata": {
    "id": "clepcO48paeN"
   },
   "source": [
    "Let's confirm the tokenizer.model file stores the base64 encoded strings for tokens, e.g. the token \"hello\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37d9c876-d428-45a8-9ec4-e953ec004d92",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'aA=='"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base64.b64encode('h'.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c304e01e-20e9-4ec6-9acc-1cf19a8be0f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 30,
    "id": "rcCuoBg_GYOF",
    "outputId": "e8acb422-f239-4bf6-8ce5-79ab776653ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'aGVsbG8='"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base64.b64encode('hello'.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dce9b9ae-3b40-43ee-ba61-24a66cee7d88",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 30,
    "id": "9M0iDw1jGYQt",
    "outputId": "7cef033f-f345-4eab-dd22-8825a9400c5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aGVsbG8= 15339\n"
     ]
    }
   ],
   "source": [
    "!grep \"aGVsbG8=\" ./content/tokenizer.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012c07c0-70f5-4480-9825-c31637306475",
   "metadata": {
    "id": "DygZtn-HBPUu"
   },
   "source": [
    "# More LLM reasoning vs tokenization\n",
    "\n",
    "Let's try out Llama 3.1 on some recent tokenization related LLM problems, and see if we can improve its reasoning by some prompt engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90548f45-c312-40ac-bc86-db8a719979fa",
   "metadata": {
    "id": "QGw3xRYytwG5"
   },
   "source": [
    "## Simple math problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "45171fef-8dc5-4636-b36e-c600a35ef8e4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 149,
    "id": "p38aw09tQ-Z5",
    "outputId": "aaaf706b-d1ea-4c01-9cc2-2942b51946cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.11 is bigger than 9.9.\n"
     ]
    }
   ],
   "source": [
    "question = \"Which number is bigger, 9.11 or 9.9? \"\n",
    "prompt = f\"\"\"\n",
    "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "{question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "response = llama31(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0ad3466d-9f02-41da-bc39-490bd4bcf628",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 47,
    "id": "gsjH4XSntLwO",
    "outputId": "f705ac59-a0a8-4412-8b10-93c6b03e08d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.9 is bigger than 9.11.\n"
     ]
    }
   ],
   "source": [
    "response = llama31(prompt, 70)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c902284b-af14-427f-8bba-e8ed13da2e75",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 47,
    "id": "wLt3-k05tLzR",
    "outputId": "29e2107e-2f24-4c37-d504-e7fe5826d443"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.11 is bigger than 9.9.\n",
      "\n",
      "To compare these numbers, I looked at the decimal parts. Since 0.11 is greater than 0.09 (or 0.9), 9.11 is greater than 9.9.\n",
      "\n",
      "Think of it like money: $9.11 is more than $9.90 (or $9.90 is 9 dollars and 90 cents, while $9.11 is 9 dollars and 11 cents, but since 11 cents is more than the difference between 90 cents and a dollar, it's actually more).\n"
     ]
    }
   ],
   "source": [
    "response = llama31(prompt, 405)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b4c5e9-aeb2-48d7-bbae-2a36bbaba9c8",
   "metadata": {
    "id": "Eow6Kj9ruue_"
   },
   "source": [
    "Somehow the largest Llama 3.1 405b model returns the incorrect result. From the visualization of the tokens in the prompt, you can see the number 9.11 is split into 3 tokens: \"9\", \".\", and \".11\", while 9.9 into 2 tokens: \"9\", \".\", \"9\". If the two numbers are encoded as the two numbers themselves, correct model response will be more likely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fff40b66-4c91-47c4-a575-fa4663ef1928",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 64,
    "id": "vUq9EC0-a8lv",
    "outputId": "b9bae0c5-cd84-43c7-8ca1-c99979d3afdb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(198, '\\n'),\n",
       " (128000, '<|begin_of_text|>'),\n",
       " (128006, '<|start_header_id|>'),\n",
       " (882, 'user'),\n",
       " (128007, '<|end_header_id|>'),\n",
       " (271, '\\n\\n'),\n",
       " (23956, 'Which'),\n",
       " (1396, ' number'),\n",
       " (374, ' is'),\n",
       " (11493, ' bigger'),\n",
       " (11, ','),\n",
       " (220, ' '),\n",
       " (24, '9'),\n",
       " (13, '.'),\n",
       " (806, '11'),\n",
       " (477, ' or'),\n",
       " (220, ' '),\n",
       " (24, '9'),\n",
       " (13, '.'),\n",
       " (24, '9'),\n",
       " (30, '?'),\n",
       " (220, ' '),\n",
       " (128009, '<|eot_id|>'),\n",
       " (128006, '<|start_header_id|>'),\n",
       " (78191, 'assistant'),\n",
       " (128007, '<|end_header_id|>'),\n",
       " (198, '\\n')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_tokens = tokenizer.encode(prompt, allowed_special=\"all\")\n",
    "decoded_tokens = [tokenizer.decode([token]) for token in encoded_tokens]\n",
    "[x for x in zip(encoded_tokens, decoded_tokens)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a7dfc789-327f-425d-9470-3cbe4b758d82",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "height": 30,
    "id": "Vk4FfGqme3Wx",
    "outputId": "1f7fc2f8-4921-4581-bbd8-909f7be142e4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"color: black; background-color: #ADE0FC; padding: 2px;\">\\n</span><span style=\"color: black; background-color: #FCE278; padding: 2px;\"><|begin_of_text|></span><span style=\"color: black; background-color: #B2D1FE; padding: 2px;\"><|start_header_id|></span><span style=\"color: black; background-color: #AFF7C6; padding: 2px;\">user</span><span style=\"color: black; background-color: #FDCE9B; padding: 2px;\"><|end_header_id|></span><span style=\"color: black; background-color: #97F1FB; padding: 2px;\">\\n\\n</span><span style=\"color: black; background-color: #DEE1E7; padding: 2px;\">Which</span><span style=\"color: black; background-color: #E3C9FF; padding: 2px;\"> number</span><span style=\"color: black; background-color: #BBC6FD; padding: 2px;\"> is</span><span style=\"color: black; background-color: #D1FB8C; padding: 2px;\"> bigger</span><span style=\"color: black; background-color: #ADE0FC; padding: 2px;\">,</span><span style=\"color: black; background-color: #FCE278; padding: 2px;\"> </span><span style=\"color: black; background-color: #B2D1FE; padding: 2px;\">9</span><span style=\"color: black; background-color: #AFF7C6; padding: 2px;\">.</span><span style=\"color: black; background-color: #FDCE9B; padding: 2px;\">11</span><span style=\"color: black; background-color: #97F1FB; padding: 2px;\"> or</span><span style=\"color: black; background-color: #DEE1E7; padding: 2px;\"> </span><span style=\"color: black; background-color: #E3C9FF; padding: 2px;\">9</span><span style=\"color: black; background-color: #BBC6FD; padding: 2px;\">.</span><span style=\"color: black; background-color: #D1FB8C; padding: 2px;\">9</span><span style=\"color: black; background-color: #ADE0FC; padding: 2px;\">?</span><span style=\"color: black; background-color: #FCE278; padding: 2px;\"> </span><span style=\"color: black; background-color: #B2D1FE; padding: 2px;\"><|eot_id|></span><span style=\"color: black; background-color: #AFF7C6; padding: 2px;\"><|start_header_id|></span><span style=\"color: black; background-color: #FDCE9B; padding: 2px;\">assistant</span><span style=\"color: black; background-color: #97F1FB; padding: 2px;\"><|end_header_id|></span><span style=\"color: black; background-color: #DEE1E7; padding: 2px;\">\\n</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(html_tokens(decoded_tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da659067-b8dd-41bb-b0c2-28700e489c9e",
   "metadata": {
    "id": "8zF6KRbCssQ4"
   },
   "source": [
    "## String reversing\n",
    "\n",
    "First, for a common word \"amazing\", all 3 Llama 3.1 chat models reverse the string correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "514f8d3d-0135-4914-8c5b-b0cfb9fb0420",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 149,
    "id": "z0NfW2ioylY2",
    "outputId": "d567cf95-d70c-4bbe-be5d-94e257b923b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reverse of 'amazing' is 'gnizama'.\n"
     ]
    }
   ],
   "source": [
    "input = \"Reverse the string 'amazing'\"\n",
    "prompt = f\"\"\"\n",
    "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "{input}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "response = llama31(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f4ded4d6-4b8e-4a68-bed6-6e1dc4da831c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 47,
    "id": "h2TbIPdnylby",
    "outputId": "1a113ee7-789b-460e-e7d4-120e6e764cdc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reverse of 'amazing' is 'gnizama'.\n"
     ]
    }
   ],
   "source": [
    "response = llama31(prompt, 70)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7dced3e5-3812-49a4-a363-a977ca6653f3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 47,
    "id": "05S3HqU7ylec",
    "outputId": "a46745bd-1e8c-402e-bb36-ba0bc810a8e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reverse of 'amazing' is 'gnizama'.\n"
     ]
    }
   ],
   "source": [
    "response = llama31(prompt, 405)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0e4f888c-58b4-4da9-87d9-94eb6b45ce1c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "height": 64,
    "id": "3JbyuLJG0erH",
    "outputId": "7d659c8e-2075-4b4b-f0bf-7289ade782b0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"color: black; background-color: #ADE0FC; padding: 2px;\">\\n</span><span style=\"color: black; background-color: #FCE278; padding: 2px;\"><|begin_of_text|></span><span style=\"color: black; background-color: #B2D1FE; padding: 2px;\"><|start_header_id|></span><span style=\"color: black; background-color: #AFF7C6; padding: 2px;\">user</span><span style=\"color: black; background-color: #FDCE9B; padding: 2px;\"><|end_header_id|></span><span style=\"color: black; background-color: #97F1FB; padding: 2px;\">\\n\\n</span><span style=\"color: black; background-color: #DEE1E7; padding: 2px;\">Reverse</span><span style=\"color: black; background-color: #E3C9FF; padding: 2px;\"> the</span><span style=\"color: black; background-color: #BBC6FD; padding: 2px;\"> string</span><span style=\"color: black; background-color: #D1FB8C; padding: 2px;\"> '</span><span style=\"color: black; background-color: #ADE0FC; padding: 2px;\">am</span><span style=\"color: black; background-color: #FCE278; padding: 2px;\">azing</span><span style=\"color: black; background-color: #B2D1FE; padding: 2px;\">'</span><span style=\"color: black; background-color: #AFF7C6; padding: 2px;\"><|eot_id|></span><span style=\"color: black; background-color: #FDCE9B; padding: 2px;\"><|start_header_id|></span><span style=\"color: black; background-color: #97F1FB; padding: 2px;\">assistant</span><span style=\"color: black; background-color: #DEE1E7; padding: 2px;\"><|end_header_id|></span><span style=\"color: black; background-color: #E3C9FF; padding: 2px;\">\\n</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_tokens = tokenizer.encode(prompt, allowed_special=\"all\")\n",
    "decoded_tokens = [tokenizer.decode([token]) for token in encoded_tokens]\n",
    "display(HTML(html_tokens(decoded_tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c640cc4-ac98-4bf4-85ea-0fd4acbd2561",
   "metadata": {
    "id": "d73S4v0DzZzR"
   },
   "source": [
    "For a less common word \"language\", Llama 3.1 8B doesn't return the correct result, but 70B and 405B do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d69630cd-e495-4e07-bcab-3c899402dfb2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 149,
    "id": "o6zCMvEcx81n",
    "outputId": "0b9ef5da-89b6-4cf4-d86d-aaa3b5425551"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reverse of 'language' is 'egnualn'.\n"
     ]
    }
   ],
   "source": [
    "input = \"Reverse the string 'language'\"\n",
    "prompt = f\"\"\"\n",
    "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "{input}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "response = llama31(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1f643e37-800d-4a58-9d29-1e2180ebce11",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 47,
    "id": "6wTtu2Dax84g",
    "outputId": "2ea3000f-78e9-424b-cb68-c9b6e0ad17cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "egaugnal\n"
     ]
    }
   ],
   "source": [
    "response = llama31(prompt, 70)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b543a78e-2eb0-4ae3-ad78-df2626622855",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 47,
    "id": "xxNAXOWJx87s",
    "outputId": "e47fb971-1f3a-4fda-b49c-b00f1758b873"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reverse of 'language' is 'egaugnal'.\n"
     ]
    }
   ],
   "source": [
    "response = llama31(prompt, 405)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5af398b5-dc0b-41c1-8c84-eecfdd8130ef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "height": 64,
    "id": "YjwtVk840xQZ",
    "outputId": "bd301af7-c0c5-4d90-fbe1-46ce44c53158"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"color: black; background-color: #ADE0FC; padding: 2px;\">\\n</span><span style=\"color: black; background-color: #FCE278; padding: 2px;\"><|begin_of_text|></span><span style=\"color: black; background-color: #B2D1FE; padding: 2px;\"><|start_header_id|></span><span style=\"color: black; background-color: #AFF7C6; padding: 2px;\">user</span><span style=\"color: black; background-color: #FDCE9B; padding: 2px;\"><|end_header_id|></span><span style=\"color: black; background-color: #97F1FB; padding: 2px;\">\\n\\n</span><span style=\"color: black; background-color: #DEE1E7; padding: 2px;\">Reverse</span><span style=\"color: black; background-color: #E3C9FF; padding: 2px;\"> the</span><span style=\"color: black; background-color: #BBC6FD; padding: 2px;\"> string</span><span style=\"color: black; background-color: #D1FB8C; padding: 2px;\"> '</span><span style=\"color: black; background-color: #ADE0FC; padding: 2px;\">language</span><span style=\"color: black; background-color: #FCE278; padding: 2px;\">'</span><span style=\"color: black; background-color: #B2D1FE; padding: 2px;\"><|eot_id|></span><span style=\"color: black; background-color: #AFF7C6; padding: 2px;\"><|start_header_id|></span><span style=\"color: black; background-color: #FDCE9B; padding: 2px;\">assistant</span><span style=\"color: black; background-color: #97F1FB; padding: 2px;\"><|end_header_id|></span><span style=\"color: black; background-color: #DEE1E7; padding: 2px;\">\\n</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_tokens = tokenizer.encode(prompt, allowed_special=\"all\")\n",
    "decoded_tokens = [tokenizer.decode([token]) for token in encoded_tokens]\n",
    "display(HTML(html_tokens(decoded_tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f364dd4-a909-4f35-b813-a8e388e231d4",
   "metadata": {
    "id": "pQxwR6Dzz5kf"
   },
   "source": [
    "For the string \"XMLElement\", none of the 3 models is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "495880ee-9a77-4456-9f10-51b491604825",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 149,
    "id": "6gsPDJ8-s2nH",
    "outputId": "13436dc8-21a6-43eb-dc67-72d369cbc8ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reverse of 'XMLElement' is 'deMltxE'.\n"
     ]
    }
   ],
   "source": [
    "input = \"Reverse the string 'XMLElement'\"\n",
    "prompt = f\"\"\"\n",
    "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "{input}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "response = llama31(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "11a30042-c245-4cb1-ac09-543b481384f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 47,
    "id": "HcvoNHTYtB5j",
    "outputId": "33783fa9-b0d2-4674-a92f-ae18591a48c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'temnelMXE'\n"
     ]
    }
   ],
   "source": [
    "response = llama31(prompt, 70)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bf4a74a4-373e-4334-b9f6-51ba67724b69",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "height": 64,
    "id": "rlwyKqSItB-G",
    "outputId": "26c856ca-eb85-4a00-9485-926fcd7db3f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reverse of the string 'XMLElement' is 'TNEMELMX'.\n"
     ]
    }
   ],
   "source": [
    "response = llama31(prompt, 405)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "499a0e33-9072-4bc0-b478-0e84dc773744",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "height": 64,
    "id": "K8EXFGUt05Dw",
    "outputId": "cf8c3a9e-0eef-4de5-85c4-05bb86f5c7d8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"color: black; background-color: #ADE0FC; padding: 2px;\">\\n</span><span style=\"color: black; background-color: #FCE278; padding: 2px;\"><|begin_of_text|></span><span style=\"color: black; background-color: #B2D1FE; padding: 2px;\"><|start_header_id|></span><span style=\"color: black; background-color: #AFF7C6; padding: 2px;\">user</span><span style=\"color: black; background-color: #FDCE9B; padding: 2px;\"><|end_header_id|></span><span style=\"color: black; background-color: #97F1FB; padding: 2px;\">\\n\\n</span><span style=\"color: black; background-color: #DEE1E7; padding: 2px;\">Reverse</span><span style=\"color: black; background-color: #E3C9FF; padding: 2px;\"> the</span><span style=\"color: black; background-color: #BBC6FD; padding: 2px;\"> string</span><span style=\"color: black; background-color: #D1FB8C; padding: 2px;\"> '</span><span style=\"color: black; background-color: #ADE0FC; padding: 2px;\">XMLElement</span><span style=\"color: black; background-color: #FCE278; padding: 2px;\">'</span><span style=\"color: black; background-color: #B2D1FE; padding: 2px;\"><|eot_id|></span><span style=\"color: black; background-color: #AFF7C6; padding: 2px;\"><|start_header_id|></span><span style=\"color: black; background-color: #FDCE9B; padding: 2px;\">assistant</span><span style=\"color: black; background-color: #97F1FB; padding: 2px;\"><|end_header_id|></span><span style=\"color: black; background-color: #DEE1E7; padding: 2px;\">\\n</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_tokens = tokenizer.encode(prompt, allowed_special=\"all\")\n",
    "decoded_tokens = [tokenizer.decode([token]) for token in encoded_tokens]\n",
    "display(HTML(html_tokens(decoded_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138197b5-cc37-4a85-8316-6814a52a88d0",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
