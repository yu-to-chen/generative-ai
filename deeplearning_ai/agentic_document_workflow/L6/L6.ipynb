{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cde6753-c327-4c1d-9ea8-63a1f851ddff",
   "metadata": {},
   "source": [
    "# Lesson 6: Use your voice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7121aec5-1316-4186-aad5-914aecb6c6cf",
   "metadata": {},
   "source": [
    "**Lesson objective**: Get voice feedback \n",
    "\n",
    "So far we've set up a moderately complex workflow with a human feedback loop. Let's run it through the visualizer to see what it looks like."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9456a5ef",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff1d7; padding:15px;\"> <b> Note</b>: Make sure to run the notebook cell by cell. Please try to avoid running all cells at once.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "497254a3-476d-401f-9d40-76e9a364756c",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "180fcb51-4d47-4877-a5b3-f773c64f1f72",
   "metadata": {
    "height": 557
   },
   "outputs": [],
   "source": [
    "import os, json\n",
    "from llama_parse import LlamaParse\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    "    load_index_from_storage\n",
    ")\n",
    "from llama_index.core.workflow import (\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    Workflow,\n",
    "    step,\n",
    "    Event,\n",
    "    Context,\n",
    "    InputRequiredEvent,\n",
    "    HumanResponseEvent\n",
    ")\n",
    "from llama_index.utils.workflow import draw_all_possible_flows\n",
    "from llama_index.readers.whisper import WhisperReader\n",
    "import gradio as gr\n",
    "import asyncio\n",
    "from queue import Queue\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from helper import get_openai_api_key, get_llama_cloud_api_key\n",
    "\n",
    "llama_cloud_api_key = get_llama_cloud_api_key()\n",
    "openai_api_key = get_openai_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc3a2f78-d56f-4bbb-9664-3da5f90cf102",
   "metadata": {
    "height": 2903
   },
   "outputs": [],
   "source": [
    "class ParseFormEvent(Event):\n",
    "    application_form: str\n",
    "\n",
    "class QueryEvent(Event):\n",
    "    query: str\n",
    "\n",
    "class ResponseEvent(Event):\n",
    "    response: str\n",
    "\n",
    "class FeedbackEvent(Event):\n",
    "    feedback: str\n",
    "\n",
    "class GenerateQuestionsEvent(Event):\n",
    "    pass\n",
    "\n",
    "class RAGWorkflow(Workflow):\n",
    "    storage_dir = \"./storage\"\n",
    "    llm: OpenAI\n",
    "    query_engine: VectorStoreIndex\n",
    "\n",
    "    @step\n",
    "    async def set_up(self, ctx: Context, ev: StartEvent) -> ParseFormEvent:\n",
    "\n",
    "        if not ev.resume_file:\n",
    "            raise ValueError(\"No resume file provided\")\n",
    "\n",
    "        if not ev.application_form:\n",
    "            raise ValueError(\"No application form provided\")\n",
    "\n",
    "        # give ourselves an LLM to work with\n",
    "        self.llm = OpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "        # ingest our data and set up the query engine\n",
    "        if os.path.exists(self.storage_dir):\n",
    "            # we've already ingested our documents\n",
    "            storage_context = StorageContext.from_defaults(persist_dir=self.storage_dir)\n",
    "            index = load_index_from_storage(storage_context)\n",
    "        else:\n",
    "            # we need to parse and load our documents\n",
    "            documents = LlamaParse(\n",
    "                api_key=llama_cloud_api_key,\n",
    "                base_url=os.getenv(\"LLAMA_CLOUD_BASE_URL\"),\n",
    "                result_type=\"markdown\",\n",
    "                content_guideline_instruction=\"This is a resume, gather related facts together and format it as bullet points with headers\"\n",
    "            ).load_data(ev.resume_file)\n",
    "            # embed and index the documents\n",
    "            index = VectorStoreIndex.from_documents(\n",
    "                documents,\n",
    "                embed_model=OpenAIEmbedding(model_name=\"text-embedding-3-small\")\n",
    "            )\n",
    "            index.storage_context.persist(persist_dir=self.storage_dir)\n",
    "\n",
    "        # either way, create a query engine\n",
    "        self.query_engine = index.as_query_engine(llm=self.llm, similarity_top_k=5)\n",
    "\n",
    "        # let's pass our application form to a new step where we parse it\n",
    "        return ParseFormEvent(application_form=ev.application_form)\n",
    "\n",
    "    # we've separated the form parsing from the question generation\n",
    "    @step\n",
    "    async def parse_form(self, ctx: Context, ev: ParseFormEvent) -> GenerateQuestionsEvent:\n",
    "        parser = LlamaParse(\n",
    "            api_key=llama_cloud_api_key,\n",
    "            base_url=os.getenv(\"LLAMA_CLOUD_BASE_URL\"),\n",
    "            result_type=\"markdown\",\n",
    "            content_guideline_instruction=\"This is a job application form. Create a list of all the fields that need to be filled in.\",\n",
    "            formatting_instruction=\"Return a bulleted list of the fields ONLY.\"\n",
    "        )\n",
    "\n",
    "        # get the LLM to convert the parsed form into JSON\n",
    "        result = parser.load_data(ev.application_form)[0]\n",
    "        raw_json = self.llm.complete(\n",
    "            f\"This is a parsed form. Convert it into a JSON object containing only the list of fields to be filled in, in the form {{ fields: [...] }}. <form>{result.text}</form>. Return JSON ONLY, no markdown.\")\n",
    "        fields = json.loads(raw_json.text)[\"fields\"]\n",
    "\n",
    "        await ctx.set(\"fields_to_fill\", fields)\n",
    "\n",
    "        return GenerateQuestionsEvent()\n",
    "\n",
    "    # this step can get triggered either by GenerateQuestionsEvent or a FeedbackEvent\n",
    "    @step\n",
    "    async def generate_questions(self, ctx: Context, ev: GenerateQuestionsEvent | FeedbackEvent) -> QueryEvent:\n",
    "\n",
    "        # get the list of fields to fill in\n",
    "        fields = await ctx.get(\"fields_to_fill\")\n",
    "\n",
    "        # generate one query for each of the fields, and fire them off\n",
    "        for field in fields:\n",
    "            question = f\"How would you answer this question about the candidate? <field>{field}</field>\"\n",
    "\n",
    "            if hasattr(ev,\"feedback\"):\n",
    "                question += f\"\"\"\n",
    "                    \\nWe previously got feedback about how we answered the questions.\n",
    "                    It might not be relevant to this particular field, but here it is:\n",
    "                    <feedback>{ev.feedback}</feedback>\n",
    "                \"\"\"\n",
    "\n",
    "            ctx.send_event(QueryEvent(\n",
    "                field=field,\n",
    "                query=question\n",
    "            ))\n",
    "\n",
    "        # store the number of fields so we know how many to wait for later\n",
    "        await ctx.set(\"total_fields\", len(fields))\n",
    "        return\n",
    "\n",
    "    @step\n",
    "    async def ask_question(self, ctx: Context, ev: QueryEvent) -> ResponseEvent:\n",
    "        print(f\"Asking question: {ev.query}\")\n",
    "\n",
    "        response = self.query_engine.query(f\"This is a question about the specific resume we have in our database: {ev.query}\")\n",
    "\n",
    "        print(f\"Answer was: {str(response)}\")\n",
    "\n",
    "        return ResponseEvent(field=ev.field, response=response.response)\n",
    "\n",
    "    # we now emit an InputRequiredEvent\n",
    "    @step\n",
    "    async def fill_in_application(self, ctx: Context, ev: ResponseEvent) -> InputRequiredEvent:\n",
    "        # get the total number of fields to wait for\n",
    "        total_fields = await ctx.get(\"total_fields\")\n",
    "\n",
    "        responses = ctx.collect_events(ev, [ResponseEvent] * total_fields)\n",
    "        if responses is None:\n",
    "            return None # do nothing if there's nothing to do yet\n",
    "\n",
    "        # we've got all the responses!\n",
    "        responseList = \"\\n\".join(\"Field: \" + r.field + \"\\n\" + \"Response: \" + r.response for r in responses)\n",
    "\n",
    "        result = self.llm.complete(f\"\"\"\n",
    "            You are given a list of fields in an application form and responses to\n",
    "            questions about those fields from a resume. Combine the two into a list of\n",
    "            fields and succinct, factual answers to fill in those fields.\n",
    "\n",
    "            <responses>\n",
    "            {responseList}\n",
    "            </responses>\n",
    "        \"\"\")\n",
    "\n",
    "        # save the result for later\n",
    "        await ctx.set(\"filled_form\", str(result))\n",
    "\n",
    "        # Let's get a human in the loop\n",
    "        return InputRequiredEvent(\n",
    "            prefix=\"How does this look? Give me any feedback you have on any of the answers.\",\n",
    "            result=result\n",
    "        )\n",
    "\n",
    "    # Accept the feedback.\n",
    "    @step\n",
    "    async def get_feedback(self, ctx: Context, ev: HumanResponseEvent) -> FeedbackEvent | StopEvent:\n",
    "\n",
    "        result = self.llm.complete(f\"\"\"\n",
    "            You have received some human feedback on the form-filling task you've done.\n",
    "            Does everything look good, or is there more work to be done?\n",
    "            <feedback>\n",
    "            {ev.response}\n",
    "            </feedback>\n",
    "            If everything is fine, respond with just the word 'OKAY'.\n",
    "            If there's any other feedback, respond with just the word 'FEEDBACK'.\n",
    "        \"\"\")\n",
    "\n",
    "        verdict = result.text.strip()\n",
    "\n",
    "        print(f\"LLM says the verdict was {verdict}\")\n",
    "        if (verdict == \"OKAY\"):\n",
    "            return StopEvent(result=await ctx.get(\"filled_form\"))\n",
    "        else:\n",
    "            return FeedbackEvent(feedback=ev.response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0039610-c02e-4e7e-9c9f-1dc56450543d",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workflows/lesson_6.html\n"
     ]
    }
   ],
   "source": [
    "WORKFLOW_FILE = \"workflows/lesson_6.html\"\n",
    "draw_all_possible_flows(RAGWorkflow, filename=WORKFLOW_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "777454c5-31d0-4b23-ac03-f74207fbaf83",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       " <div style=\"width: 100%; height: 800px; overflow: hidden;\"> <html>\n",
       "    <head>\n",
       "        <meta charset=\"utf-8\">\n",
       "        \n",
       "            <script src=\"lib/bindings/utils.js\"></script>\n",
       "            <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/dist/vis-network.min.css\" integrity=\"sha512-WgxfT5LWjfszlPHXRmBWHkV2eceiWTOBvrKCNbdgDYTHrT2AeLCGbF4sZlZw3UMN3WtL0tGUoIAKsu8mllg/XA==\" crossorigin=\"anonymous\" referrerpolicy=\"no-referrer\" />\n",
       "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/vis-network.min.js\" integrity=\"sha512-LnvoEWDFrqGHlHmDD2101OrLcbsfkrzoSpvtSQtxK3RMnRV0eOkhhBN2dXHKRrUU8p2DGRTk35n4O8nWSVe1mQ==\" crossorigin=\"anonymous\" referrerpolicy=\"no-referrer\"></script>\n",
       "            \n",
       "        \n",
       "<center>\n",
       "<h1></h1>\n",
       "</center>\n",
       "\n",
       "<!-- <link rel=\"stylesheet\" href=\"../node_modules/vis/dist/vis.min.css\" type=\"text/css\" />\n",
       "<script type=\"text/javascript\" src=\"../node_modules/vis/dist/vis.js\"> </script>-->\n",
       "        <link\n",
       "          href=\"https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/css/bootstrap.min.css\"\n",
       "          rel=\"stylesheet\"\n",
       "          integrity=\"sha384-eOJMYsd53ii+scO/bJGFsiCZc+5NDVN2yr8+0RDqr0Ql0h+rP48ckxlpbzKgwra6\"\n",
       "          crossorigin=\"anonymous\"\n",
       "        />\n",
       "        <script\n",
       "          src=\"https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/js/bootstrap.bundle.min.js\"\n",
       "          integrity=\"sha384-JEW9xMcG8R+pH31jmWH6WWP0WintQrMb4s7ZOdauHnUtxwoG2vI5DkLtS3qm9Ekf\"\n",
       "          crossorigin=\"anonymous\"\n",
       "        ></script>\n",
       "\n",
       "\n",
       "        <center>\n",
       "          <h1></h1>\n",
       "        </center>\n",
       "        <style type=\"text/css\">\n",
       "\n",
       "             #mynetwork {\n",
       "                 width: 100%;\n",
       "                 height: 750px;\n",
       "                 background-color: #ffffff;\n",
       "                 border: 1px solid lightgray;\n",
       "                 position: relative;\n",
       "                 float: left;\n",
       "             }\n",
       "\n",
       "             \n",
       "\n",
       "             \n",
       "\n",
       "             \n",
       "        </style>\n",
       "    </head>\n",
       "\n",
       "\n",
       "    <body>\n",
       "        <div class=\"card\" style=\"width: 100%\">\n",
       "            \n",
       "            \n",
       "            <div id=\"mynetwork\" class=\"card-body\"></div>\n",
       "        </div>\n",
       "\n",
       "        \n",
       "        \n",
       "\n",
       "        <script type=\"text/javascript\">\n",
       "\n",
       "              // initialize global variables.\n",
       "              var edges;\n",
       "              var nodes;\n",
       "              var allNodes;\n",
       "              var allEdges;\n",
       "              var nodeColors;\n",
       "              var originalNodes;\n",
       "              var network;\n",
       "              var container;\n",
       "              var options, data;\n",
       "              var filter = {\n",
       "                  item : '',\n",
       "                  property : '',\n",
       "                  value : []\n",
       "              };\n",
       "\n",
       "              \n",
       "\n",
       "              \n",
       "\n",
       "              // This method is responsible for drawing the graph, returns the drawn network\n",
       "              function drawGraph() {\n",
       "                  var container = document.getElementById('mynetwork');\n",
       "\n",
       "                  \n",
       "\n",
       "                  // parsing and collecting nodes and edges from the python\n",
       "                  nodes = new vis.DataSet([{\"color\": \"#ADD8E6\", \"id\": \"_done\", \"label\": \"_done\", \"shape\": \"box\", \"title\": null}, {\"color\": \"#FFA07A\", \"id\": \"StopEvent\", \"label\": \"StopEvent\", \"shape\": \"ellipse\", \"title\": null}, {\"color\": \"#ADD8E6\", \"id\": \"ask_question\", \"label\": \"ask_question\", \"shape\": \"box\", \"title\": null}, {\"color\": \"#90EE90\", \"id\": \"QueryEvent\", \"label\": \"QueryEvent\", \"shape\": \"ellipse\", \"title\": null}, {\"color\": \"#90EE90\", \"id\": \"ResponseEvent\", \"label\": \"ResponseEvent\", \"shape\": \"ellipse\", \"title\": null}, {\"color\": \"#ADD8E6\", \"id\": \"fill_in_application\", \"label\": \"fill_in_application\", \"shape\": \"box\", \"title\": null}, {\"color\": \"#90EE90\", \"id\": \"InputRequiredEvent\", \"label\": \"InputRequiredEvent\", \"shape\": \"ellipse\", \"title\": null}, {\"color\": \"#BEDAE4\", \"id\": \"external_step\", \"label\": \"external_step\", \"shape\": \"box\", \"title\": null}, {\"color\": \"#ADD8E6\", \"id\": \"generate_questions\", \"label\": \"generate_questions\", \"shape\": \"box\", \"title\": null}, {\"color\": \"#90EE90\", \"id\": \"GenerateQuestionsEvent\", \"label\": \"GenerateQuestionsEvent\", \"shape\": \"ellipse\", \"title\": null}, {\"color\": \"#90EE90\", \"id\": \"FeedbackEvent\", \"label\": \"FeedbackEvent\", \"shape\": \"ellipse\", \"title\": null}, {\"color\": \"#ADD8E6\", \"id\": \"get_feedback\", \"label\": \"get_feedback\", \"shape\": \"box\", \"title\": null}, {\"color\": \"#90EE90\", \"id\": \"HumanResponseEvent\", \"label\": \"HumanResponseEvent\", \"shape\": \"ellipse\", \"title\": null}, {\"color\": \"#ADD8E6\", \"id\": \"parse_form\", \"label\": \"parse_form\", \"shape\": \"box\", \"title\": null}, {\"color\": \"#90EE90\", \"id\": \"ParseFormEvent\", \"label\": \"ParseFormEvent\", \"shape\": \"ellipse\", \"title\": null}, {\"color\": \"#ADD8E6\", \"id\": \"set_up\", \"label\": \"set_up\", \"shape\": \"box\", \"title\": null}, {\"color\": \"#E27AFF\", \"id\": \"StartEvent\", \"label\": \"StartEvent\", \"shape\": \"ellipse\", \"title\": null}]);\n",
       "                  edges = new vis.DataSet([{\"arrows\": \"to\", \"from\": \"StopEvent\", \"to\": \"_done\"}, {\"arrows\": \"to\", \"from\": \"ask_question\", \"to\": \"ResponseEvent\"}, {\"arrows\": \"to\", \"from\": \"QueryEvent\", \"to\": \"ask_question\"}, {\"arrows\": \"to\", \"from\": \"fill_in_application\", \"to\": \"InputRequiredEvent\"}, {\"arrows\": \"to\", \"from\": \"InputRequiredEvent\", \"to\": \"external_step\"}, {\"arrows\": \"to\", \"from\": \"ResponseEvent\", \"to\": \"fill_in_application\"}, {\"arrows\": \"to\", \"from\": \"generate_questions\", \"to\": \"QueryEvent\"}, {\"arrows\": \"to\", \"from\": \"GenerateQuestionsEvent\", \"to\": \"generate_questions\"}, {\"arrows\": \"to\", \"from\": \"FeedbackEvent\", \"to\": \"generate_questions\"}, {\"arrows\": \"to\", \"from\": \"get_feedback\", \"to\": \"FeedbackEvent\"}, {\"arrows\": \"to\", \"from\": \"get_feedback\", \"to\": \"StopEvent\"}, {\"arrows\": \"to\", \"from\": \"HumanResponseEvent\", \"to\": \"get_feedback\"}, {\"arrows\": \"to\", \"from\": \"external_step\", \"to\": \"HumanResponseEvent\"}, {\"arrows\": \"to\", \"from\": \"parse_form\", \"to\": \"GenerateQuestionsEvent\"}, {\"arrows\": \"to\", \"from\": \"ParseFormEvent\", \"to\": \"parse_form\"}, {\"arrows\": \"to\", \"from\": \"set_up\", \"to\": \"ParseFormEvent\"}, {\"arrows\": \"to\", \"from\": \"StartEvent\", \"to\": \"set_up\"}]);\n",
       "\n",
       "                  nodeColors = {};\n",
       "                  allNodes = nodes.get({ returnType: \"Object\" });\n",
       "                  for (nodeId in allNodes) {\n",
       "                    nodeColors[nodeId] = allNodes[nodeId].color;\n",
       "                  }\n",
       "                  allEdges = edges.get({ returnType: \"Object\" });\n",
       "                  // adding nodes and edges to the graph\n",
       "                  data = {nodes: nodes, edges: edges};\n",
       "\n",
       "                  var options = {\n",
       "    \"configure\": {\n",
       "        \"enabled\": false\n",
       "    },\n",
       "    \"edges\": {\n",
       "        \"color\": {\n",
       "            \"inherit\": true\n",
       "        },\n",
       "        \"smooth\": {\n",
       "            \"enabled\": true,\n",
       "            \"type\": \"dynamic\"\n",
       "        }\n",
       "    },\n",
       "    \"interaction\": {\n",
       "        \"dragNodes\": true,\n",
       "        \"hideEdgesOnDrag\": false,\n",
       "        \"hideNodesOnDrag\": false\n",
       "    },\n",
       "    \"physics\": {\n",
       "        \"enabled\": true,\n",
       "        \"stabilization\": {\n",
       "            \"enabled\": true,\n",
       "            \"fit\": true,\n",
       "            \"iterations\": 1000,\n",
       "            \"onlyDynamicEdges\": false,\n",
       "            \"updateInterval\": 50\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "                  \n",
       "\n",
       "\n",
       "                  \n",
       "\n",
       "                  network = new vis.Network(container, data, options);\n",
       "\n",
       "                  \n",
       "\n",
       "                  \n",
       "\n",
       "                  \n",
       "\n",
       "\n",
       "                  \n",
       "\n",
       "                  return network;\n",
       "\n",
       "              }\n",
       "              drawGraph();\n",
       "        </script>\n",
       "    </body>\n",
       "</html> </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "isolated": true
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML, DisplayHandle\n",
    "from helper import extract_html_content\n",
    "\n",
    "html_content = extract_html_content(WORKFLOW_FILE)\n",
    "display(HTML(html_content), metadata=dict(isolated=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d55ed9-88d0-44ac-b4a3-eb605bcb0638",
   "metadata": {},
   "source": [
    "Cool! You can see the path all the way to the end and the feedback loop is clear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1147987",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "<p> 💻 &nbsp; <b>To access <code>fake_application_form.pdf</code>, <code>fake_resume.pdf</code>, <code>requirements.txt</code> and <code>helper.py</code> files:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em>. The form and resume are inside the data folder.\n",
    "\n",
    "<p> ⬇ &nbsp; <b>Download Notebooks:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Download as\"</em> and select <em>\"Notebook (.ipynb)\"</em>.</p>\n",
    "\n",
    "<p> 📒 &nbsp; For more help, please see the <em>\"Appendix – Tips and Help\"</em> Lesson.</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3a258f",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#f7fff8; padding:15px; border-width:3px; border-color:#e0f0e0; border-style:solid; border-radius:6px\"> 🚨\n",
    "&nbsp; <b>Different Run Results:</b> The output generated by AI chat models can vary with each execution due to their dynamic, probabilistic nature. Don't be surprised if your results differ from those shown in the video.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c82425-bdda-4f93-9226-fc4e4834d8ef",
   "metadata": {},
   "source": [
    "## Getting voice feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fad645-47db-436b-84e2-914acc89dee3",
   "metadata": {},
   "source": [
    "Now, just for fun, you'll do one more thing: change the feedback from text feedback to actual words spoken out loud. To do this we'll use a different model from OpenAI called Whisper. LlamaIndex has a built-in way to transcribe audio files into text using Whisper.\n",
    "\n",
    "Here's a function that takes a file and uses Whisper to return just the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53149fea-7383-4c39-a58c-5836857f69b7",
   "metadata": {
    "height": 183
   },
   "outputs": [],
   "source": [
    "def transcribe_speech(filepath):\n",
    "    if filepath is None:\n",
    "        gr.Warning(\"No audio found, please retry.\")\n",
    "    audio_file= open(filepath, \"rb\")\n",
    "    reader = WhisperReader(\n",
    "        model=\"whisper-1\",\n",
    "        api_key=openai_api_key,\n",
    "    )\n",
    "    documents = reader.load_data(filepath)\n",
    "    return documents[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b67c70a-48a6-4fcd-bf18-2c390cce5855",
   "metadata": {},
   "source": [
    "But before we can use it, you need to capture some audio from your microphone. That involves some extra steps!\n",
    "\n",
    "First, create a callback function that saves data to a global variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d53efc82-cbd2-448d-bc6f-96d6bc1486f7",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "def store_transcription(output):\n",
    "    global transcription_value\n",
    "    transcription_value = output\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389e3292-2d56-450c-bcb1-65b510a994ee",
   "metadata": {},
   "source": [
    "Now use Gradio, which has special widgets that can render inside a notebook, to create an interface for capturing audio from a microphone. When the audio is captured, it calls `transcribe_speech` on the recorded data, and calls `store_transcription` on that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06e38ac6-1e88-46dd-ace4-77241aff9d42",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "mic_transcribe = gr.Interface(\n",
    "    fn=lambda x: store_transcription(transcribe_speech(x)),\n",
    "    inputs=gr.Audio(sources=\"microphone\",\n",
    "                    type=\"filepath\"),\n",
    "    outputs=gr.Textbox(label=\"Transcription\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e04512-d9ab-450d-850f-072ae67bc451",
   "metadata": {},
   "source": [
    "In Gradio, you further define a visual interface containing this microphone input and output, and then launch it:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189076f4",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff1d7; padding:15px;\"> <b> Note</b>: Make sure to wait for the gradio interface to load. A popup window will appear and ask you to allow the use of your microphone. To record audio, make sure to click on record -> stop -> submit. Make sure the audio is captured before clicking on 'submit'.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bc89e72-76e0-4cfd-904b-0d3dd058532b",
   "metadata": {
    "height": 302
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_interface = gr.Blocks()\n",
    "with test_interface:\n",
    "    gr.TabbedInterface(\n",
    "        [mic_transcribe],\n",
    "        [\"Transcribe Microphone\"]\n",
    "    )\n",
    "\n",
    "\"\"\"\n",
    "test_interface.launch(\n",
    "    share=False, \n",
    "    server_port=8000, \n",
    "    prevent_thread_lock=True\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# best for notebooks—no clashes\n",
    "test_interface.launch(prevent_thread_lock=True)  # remove server_port arg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac30d95b-47bb-45db-9d42-5835120d92ae",
   "metadata": {},
   "source": [
    "You can now print out the transcription, which is stored in that global variable you created earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5de79c4-dbda-4103-baa1-5b315af6c1e1",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello. How are you today? Fine. I'm doing fine. Thank you.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(transcription_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8ee4ba-f744-4b7c-906f-b26151700d27",
   "metadata": {},
   "source": [
    "You're going to want to run Gradio again, so it's a good idea to shut down the Gradio interface you were using. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "436f51ba-760d-4af6-8da1-8088e7c8ebcd",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "source": [
    "test_interface.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce0f309",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff1d7; padding:15px;\"> <b> Note</b>: Make sure to run the previous cell to close the Gradio interface before running the next cell.</div>                                                                                          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b05ec0-495f-4376-a167-43efc1db04cd",
   "metadata": {},
   "source": [
    "Now you're going to create an entirely new class, a Transcription Handler. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8f30a2e-2c39-411a-917c-b78549e5eef1",
   "metadata": {
    "height": 863
   },
   "outputs": [],
   "source": [
    "# New! Transcription handler.\n",
    "class TranscriptionHandler:\n",
    "\n",
    "    # we create a queue to hold transcription values\n",
    "    def __init__(self):\n",
    "        self.transcription_queue = Queue()\n",
    "        self.interface = None\n",
    "\n",
    "    # every time we record something we put it in the queue\n",
    "    def store_transcription(self, output):\n",
    "        self.transcription_queue.put(output)\n",
    "        return output\n",
    "\n",
    "    # This is the same interface and transcription logic as before\n",
    "    # except it stores the result in a queue instead of a global\n",
    "    def create_interface(self):\n",
    "        mic_transcribe = gr.Interface(\n",
    "            fn=lambda x: self.store_transcription(transcribe_speech(x)),\n",
    "            inputs=gr.Audio(sources=\"microphone\", type=\"filepath\"),\n",
    "            outputs=gr.Textbox(label=\"Transcription\")\n",
    "        )\n",
    "        self.interface = gr.Blocks()\n",
    "        with self.interface:\n",
    "            gr.TabbedInterface(\n",
    "                [mic_transcribe],\n",
    "                [\"Transcribe Microphone\"]\n",
    "            )\n",
    "        return self.interface\n",
    "\n",
    "    # we launch the transcription interface\n",
    "    async def get_transcription(self):\n",
    "        self.interface = self.create_interface()\n",
    "        self.interface.launch(\n",
    "            share=False,\n",
    "            #server_port=8000, \n",
    "            prevent_thread_lock=True\n",
    "        )\n",
    "\n",
    "## best for notebooks—no clashes\n",
    "#test_interface.launch(prevent_thread_lock=True)  # remove server_port arg\n",
    "        \n",
    "        # we poll every 1.5 seconds waiting for something to end up in the queue\n",
    "        while True:\n",
    "            if not self.transcription_queue.empty():\n",
    "                result = self.transcription_queue.get()\n",
    "                if self.interface is not None:\n",
    "                    self.interface.close()\n",
    "                return result\n",
    "            await asyncio.sleep(1.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07e0042-5feb-4c25-8668-33debef828a7",
   "metadata": {},
   "source": [
    "Now you have a transcription handler, you can use it instead of the keyboard input interface when you're getting human input when you run your workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "905709d6-ad52-4514-a75e-2bae2cfbb802",
   "metadata": {
    "height": 387
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: content_guideline_instruction is deprecated and may be remove in a future release. Use system_prompt, system_prompt_append or user_prompt instead.\n",
      "Started parsing the file under job_id 12808279-53aa-46af-9937-68a3bc481457\n",
      "WARNING: content_guideline_instruction is deprecated and may be remove in a future release. Use system_prompt, system_prompt_append or user_prompt instead.\n",
      "WARNING: formatting_instruction is deprecated and may be remove in a future release. Use system_prompt, system_prompt_append or user_prompt instead.\n",
      "Started parsing the file under job_id cb5f5e5b-8f65-4dbd-9eab-0f796718a8f5\n",
      "Asking question: How would you answer this question about the candidate? <field>First Name</field>\n",
      "Answer was: Sarah\n",
      "Asking question: How would you answer this question about the candidate? <field>Last Name</field>\n",
      "Answer was: Chen\n",
      "Asking question: How would you answer this question about the candidate? <field>Email</field>\n",
      "Answer was: sarah.chen@email.com\n",
      "Asking question: How would you answer this question about the candidate? <field>Phone</field>\n",
      "Answer was: The candidate's phone number is not provided in the available information.\n",
      "Asking question: How would you answer this question about the candidate? <field>Linkedin</field>\n",
      "Answer was: The candidate's LinkedIn profile can be found at linkedin.com/in/sarahchen.\n",
      "Asking question: How would you answer this question about the candidate? <field>Project Portfolio</field>\n",
      "Answer was: The candidate has worked on notable projects including EcoTrack, a full-stack application for tracking carbon footprints that utilizes React, Node.js, and MongoDB, and features a machine learning algorithm for personalized sustainability recommendations. This project was recognized in TechCrunch's \"Top 10 Environmental Impact Apps of 2023.\" Additionally, they developed ChatFlow, a real-time chat application using the WebSocket protocol and React, which supports over 5000 monthly active users and includes end-to-end encryption and message persistence.\n",
      "Asking question: How would you answer this question about the candidate? <field>Degree</field>\n",
      "Answer was: The candidate holds a Bachelor of Science in Computer Science from the University of California, Berkeley.\n",
      "Asking question: How would you answer this question about the candidate? <field>Graduation Date</field>\n",
      "Answer was: The candidate graduated in 2017.\n",
      "Asking question: How would you answer this question about the candidate? <field>Current Job Title</field>\n",
      "Answer was: Senior Full Stack Developer\n",
      "Asking question: How would you answer this question about the candidate? <field>Current Employer</field>\n",
      "Answer was: The current employer of the candidate is TechFlow Solutions, located in San Francisco, CA.\n",
      "Asking question: How would you answer this question about the candidate? <field>Technical Skills</field>\n",
      "Answer was: The candidate possesses a diverse set of technical skills across both frontend and backend development. \n",
      "\n",
      "For frontend, they are proficient in:\n",
      "- React.js, Redux, Next.js, and TypeScript\n",
      "- Vue.js and Nuxt.js\n",
      "- HTML5, CSS3, and SASS/SCSS\n",
      "- Testing frameworks such as Jest and React Testing Library\n",
      "- Build tools like WebPack and Babel\n",
      "\n",
      "On the backend, their expertise includes:\n",
      "- Node.js and Express.js\n",
      "- Python and Django\n",
      "- API development using GraphQL and REST\n",
      "- Database management with PostgreSQL and MongoDB\n",
      "\n",
      "Additionally, they are familiar with tools and technologies such as Docker, Kubernetes, AWS services (EC2, S3, Lambda), Git, GitHub Actions, Jenkins, CircleCI, and Agile/Scrum methodologies, along with performance optimization techniques.\n",
      "Asking question: How would you answer this question about the candidate? <field>Describe why you’re a good fit for this position</field>\n",
      "Answer was: I am a strong fit for this position due to my extensive experience as a Full Stack Web Developer, with over 6 years in the field. My expertise in technologies such as React and Node.js, combined with my proven ability to lead technical teams and implement efficient CI/CD pipelines, aligns well with the requirements of this role. I have successfully architected scalable applications, including a microservices-based e-commerce platform that serves a large user base, demonstrating my capability to handle high-traffic environments.\n",
      "\n",
      "Additionally, my commitment to clean code and accessibility, along with my experience mentoring junior developers, showcases my dedication to fostering a collaborative and high-quality development environment. My technical skills, coupled with my certifications in cloud architecture, further enhance my qualifications for this position. Overall, my background and passion for web development make me an excellent candidate for this role.\n",
      "Asking question: How would you answer this question about the candidate? <field>Do you have 5 years of experience in React?</field>\n",
      "Answer was: Yes, the candidate has over 6 years of experience as a Full Stack Web Developer, with specific expertise in React.\n",
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n",
      "LLM says the verdict was FEEDBACK\n",
      "Asking question: How would you answer this question about the candidate? <field>First Name</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>The answer in PowerPoint L should be in URL.\n",
      "</feedback>\n",
      "                \n",
      "Answer was: Sarah\n",
      "Asking question: How would you answer this question about the candidate? <field>Last Name</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>The answer in PowerPoint L should be in URL.\n",
      "</feedback>\n",
      "                \n",
      "Answer was: Chen\n",
      "Asking question: How would you answer this question about the candidate? <field>Email</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>The answer in PowerPoint L should be in URL.\n",
      "</feedback>\n",
      "                \n",
      "Answer was: sarah.chen@email.com\n",
      "Asking question: How would you answer this question about the candidate? <field>Phone</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>The answer in PowerPoint L should be in URL.\n",
      "</feedback>\n",
      "                \n",
      "Answer was: The candidate's resume does not provide a phone number.\n",
      "Asking question: How would you answer this question about the candidate? <field>Linkedin</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>The answer in PowerPoint L should be in URL.\n",
      "</feedback>\n",
      "                \n",
      "Answer was: The LinkedIn profile of the candidate can be found at: [linkedin.com/in/sarahchen](https://linkedin.com/in/sarahchen)\n",
      "Asking question: How would you answer this question about the candidate? <field>Project Portfolio</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>The answer in PowerPoint L should be in URL.\n",
      "</feedback>\n",
      "                \n",
      "Answer was: The candidate's project portfolio includes the following notable projects:\n",
      "\n",
      "1. **EcoTrack**: A full-stack application for tracking carbon footprint, built using React, Node.js, and MongoDB. It features a machine learning algorithm for personalized sustainability recommendations and was recognized in TechCrunch's \"Top 10 Environmental Impact Apps of 2023.\"\n",
      "\n",
      "2. **ChatFlow**: A real-time chat application developed with the WebSocket protocol and React. It includes end-to-end encryption and message persistence, serving over 5000 monthly active users.\n",
      "\n",
      "For more details, you can visit the candidate's GitHub at [github.com/sarahcodes](https://github.com/sarahcodes) or their portfolio at [sarahchen.dev](https://sarahchen.dev).\n",
      "Asking question: How would you answer this question about the candidate? <field>Degree</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>The answer in PowerPoint L should be in URL.\n",
      "</feedback>\n",
      "                \n",
      "Answer was: The candidate holds a Bachelor of Science in Computer Science from the University of California, Berkeley.\n",
      "Asking question: How would you answer this question about the candidate? <field>Graduation Date</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>The answer in PowerPoint L should be in URL.\n",
      "</feedback>\n",
      "                \n",
      "Answer was: The graduation date for the candidate is May 2017.\n",
      "Asking question: How would you answer this question about the candidate? <field>Current Job Title</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>The answer in PowerPoint L should be in URL.\n",
      "</feedback>\n",
      "                \n",
      "Answer was: The current job title of the candidate is Senior Full Stack Developer.\n",
      "Asking question: How would you answer this question about the candidate? <field>Current Employer</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>The answer in PowerPoint L should be in URL.\n",
      "</feedback>\n",
      "                \n",
      "Answer was: The current employer of the candidate is TechFlow Solutions.\n",
      "Asking question: How would you answer this question about the candidate? <field>Technical Skills</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>The answer in PowerPoint L should be in URL.\n",
      "</feedback>\n",
      "                \n",
      "Answer was: The candidate's technical skills include:\n",
      "\n",
      "**Frontend:**\n",
      "- React.js, Redux, Next.js, TypeScript\n",
      "- Vue.js, Nuxt.js\n",
      "- HTML5, CSS3, SASS/SCSS\n",
      "- Jest, React Testing Library\n",
      "- WebPack, Babel\n",
      "\n",
      "**Backend:**\n",
      "- Node.js, Express.js\n",
      "- Python, Django\n",
      "- GraphQL, REST APIs\n",
      "- PostgreSQL, MongoDB\n",
      "\n",
      "**Tools & Others:**\n",
      "- Docker, Kubernetes\n",
      "- AWS (EC2, S3, Lambda)\n",
      "- Git, GitHub Actions\n",
      "- Jenkins, CircleCI\n",
      "- Agile/Scrum methodology\n",
      "- Performance optimization\n",
      "Asking question: How would you answer this question about the candidate? <field>Describe why you’re a good fit for this position</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>The answer in PowerPoint L should be in URL.\n",
      "</feedback>\n",
      "                \n",
      "Answer was: The candidate is a strong fit for the position due to their extensive experience as a Full Stack Web Developer, with over 6 years in the field. They have successfully led technical teams and implemented significant improvements in deployment processes and code quality. Their expertise in modern technologies such as React, Node.js, and cloud architecture aligns well with the requirements of the role. Additionally, their commitment to clean code, accessibility, and mentoring junior developers demonstrates their leadership qualities and dedication to team growth. The candidate's proven track record of developing scalable applications and optimizing performance further supports their suitability for the position.\n",
      "Asking question: How would you answer this question about the candidate? <field>Do you have 5 years of experience in React?</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>The answer in PowerPoint L should be in URL.\n",
      "</feedback>\n",
      "                \n",
      "Answer was: Yes, the candidate has over 6 years of experience in web development, including extensive work with React.\n",
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n",
      "LLM says the verdict was FEEDBACK\n",
      "Asking question: How would you answer this question about the candidate? <field>First Name</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>Portfolio insertion should be in URL\n",
      "</feedback>\n",
      "                \n",
      "Answer was: Sarah\n",
      "Asking question: How would you answer this question about the candidate? <field>Last Name</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>Portfolio insertion should be in URL\n",
      "</feedback>\n",
      "                \n",
      "Answer was: Chen\n",
      "Asking question: How would you answer this question about the candidate? <field>Email</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>Portfolio insertion should be in URL\n",
      "</feedback>\n",
      "                \n",
      "Answer was: sarah.chen@email.com\n",
      "Asking question: How would you answer this question about the candidate? <field>Phone</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>Portfolio insertion should be in URL\n",
      "</feedback>\n",
      "                \n",
      "Answer was: The candidate's resume does not include a phone number.\n",
      "Asking question: How would you answer this question about the candidate? <field>Linkedin</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>Portfolio insertion should be in URL\n",
      "</feedback>\n",
      "                \n",
      "Answer was: The candidate's LinkedIn profile can be found at: [linkedin.com/in/sarahchen](https://linkedin.com/in/sarahchen).\n",
      "Asking question: How would you answer this question about the candidate? <field>Project Portfolio</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>Portfolio insertion should be in URL\n",
      "</feedback>\n",
      "                \n",
      "Answer was: The candidate's project portfolio can be found at the following URL: [sarahchen.dev](http://sarahchen.dev).\n",
      "Asking question: How would you answer this question about the candidate? <field>Degree</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>Portfolio insertion should be in URL\n",
      "</feedback>\n",
      "                \n",
      "Answer was: The candidate holds a Bachelor of Science in Computer Science from the University of California, Berkeley.\n",
      "Asking question: How would you answer this question about the candidate? <field>Graduation Date</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>Portfolio insertion should be in URL\n",
      "</feedback>\n",
      "                \n",
      "Answer was: The graduation date for the candidate is May 2017.\n",
      "Asking question: How would you answer this question about the candidate? <field>Current Job Title</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>Portfolio insertion should be in URL\n",
      "</feedback>\n",
      "                \n",
      "Answer was: The current job title of the candidate is Senior Full Stack Developer.\n",
      "Asking question: How would you answer this question about the candidate? <field>Current Employer</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>Portfolio insertion should be in URL\n",
      "</feedback>\n",
      "                \n",
      "Answer was: The current employer of the candidate is TechFlow Solutions, located in San Francisco, CA.\n",
      "Asking question: How would you answer this question about the candidate? <field>Technical Skills</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>Portfolio insertion should be in URL\n",
      "</feedback>\n",
      "                \n",
      "Answer was: The candidate possesses a diverse set of technical skills across both frontend and backend development. \n",
      "\n",
      "**Frontend Skills:**\n",
      "- Proficient in React.js, Redux, Next.js, and TypeScript.\n",
      "- Experienced with Vue.js and Nuxt.js.\n",
      "- Skilled in HTML5, CSS3, and SASS/SCSS.\n",
      "- Familiar with testing frameworks such as Jest and React Testing Library.\n",
      "- Knowledgeable in build tools like WebPack and Babel.\n",
      "\n",
      "**Backend Skills:**\n",
      "- Expertise in Node.js and Express.js.\n",
      "- Proficient in Python and Django.\n",
      "- Experienced with GraphQL and REST APIs.\n",
      "- Knowledgeable in database management with PostgreSQL and MongoDB.\n",
      "\n",
      "Additionally, the candidate is well-versed in tools and technologies such as Docker, Kubernetes, and AWS services, along with CI/CD practices and Agile methodologies.\n",
      "Asking question: How would you answer this question about the candidate? <field>Describe why you’re a good fit for this position</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>Portfolio insertion should be in URL\n",
      "</feedback>\n",
      "                \n",
      "Answer was: The candidate is a strong fit for the position due to their extensive experience as a Full Stack Web Developer, with over 6 years in the field. They have a proven track record of successfully leading technical teams and implementing scalable web applications, particularly using React and Node.js. Their recent role involved architecting a microservices-based e-commerce platform that serves over 100,000 daily users, showcasing their ability to handle high-traffic applications.\n",
      "\n",
      "Additionally, the candidate has demonstrated a commitment to code quality and team development, having established coding standards that improved code quality significantly and mentored junior developers who advanced in their careers. Their technical skills span both frontend and backend technologies, including expertise in modern frameworks and cloud architecture, which aligns well with the demands of the position.\n",
      "\n",
      "Furthermore, their passion for clean code, accessibility, and mentoring, combined with their certifications in cloud solutions and development, make them a well-rounded candidate who can contribute effectively to the team. For more details on their work, you can view their portfolio at [sarahchen.dev](http://sarahchen.dev).\n",
      "Asking question: How would you answer this question about the candidate? <field>Do you have 5 years of experience in React?</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>Portfolio insertion should be in URL\n",
      "</feedback>\n",
      "                \n",
      "Answer was: Yes, the candidate has over 6 years of experience as a Full Stack Web Developer, with specific expertise in React.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-206' coro=<_delete_state() running at /Users/ytchen/Documents/experimental/AgenticDocumentWorkflow/.venv/lib/python3.11/site-packages/gradio/route_utils.py:979> wait_for=<Future pending cb=[Task.__wakeup()]>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, InputRequiredEvent):\n\u001b[32m     10\u001b[39m       \u001b[38;5;66;03m# Get transcription\u001b[39;00m\n\u001b[32m     11\u001b[39m       transcription_handler = TranscriptionHandler()\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m       response = \u001b[38;5;28;01mawait\u001b[39;00m transcription_handler.get_transcription()\n\u001b[32m     14\u001b[39m       handler.ctx.send_event(\n\u001b[32m     15\u001b[39m           HumanResponseEvent(\n\u001b[32m     16\u001b[39m               response=response\n\u001b[32m     17\u001b[39m           )\n\u001b[32m     18\u001b[39m       )\n\u001b[32m     20\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m handler\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 49\u001b[39m, in \u001b[36mTranscriptionHandler.get_transcription\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     47\u001b[39m         \u001b[38;5;28mself\u001b[39m.interface.close()\n\u001b[32m     48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio.sleep(\u001b[32m1.5\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.13/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/tasks.py:649\u001b[39m, in \u001b[36msleep\u001b[39m\u001b[34m(delay, result)\u001b[39m\n\u001b[32m    645\u001b[39m h = loop.call_later(delay,\n\u001b[32m    646\u001b[39m                     futures._set_result_unless_cancelled,\n\u001b[32m    647\u001b[39m                     future, result)\n\u001b[32m    648\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m649\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m future\n\u001b[32m    650\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    651\u001b[39m     h.cancel()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.13/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/futures.py:287\u001b[39m, in \u001b[36mFuture.__await__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done():\n\u001b[32m    286\u001b[39m     \u001b[38;5;28mself\u001b[39m._asyncio_future_blocking = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m  \u001b[38;5;66;03m# This tells Task to wait for completion.\u001b[39;00m\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done():\n\u001b[32m    289\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mawait wasn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt used with future\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.13/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/tasks.py:349\u001b[39m, in \u001b[36mTask.__wakeup\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[32m    348\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m349\u001b[39m         \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    350\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    351\u001b[39m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[32m    352\u001b[39m         \u001b[38;5;28mself\u001b[39m.__step(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.13/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/futures.py:198\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    196\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == _CANCELLED:\n\u001b[32m    197\u001b[39m     exc = \u001b[38;5;28mself\u001b[39m._make_cancelled_error()\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state != _FINISHED:\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.InvalidStateError(\u001b[33m'\u001b[39m\u001b[33mResult is not ready.\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mCancelledError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "w = RAGWorkflow(timeout=600, verbose=False)\n",
    "\n",
    "handler = w.run(\n",
    "    resume_file=\"./data/fake_resume.pdf\",\n",
    "    application_form=\"./data/fake_application_form.pdf\"\n",
    ")\n",
    "\n",
    "async for event in handler.stream_events():\n",
    "  if isinstance(event, InputRequiredEvent):\n",
    "      # Get transcription\n",
    "      transcription_handler = TranscriptionHandler()\n",
    "      response = await transcription_handler.get_transcription()\n",
    "\n",
    "      handler.ctx.send_event(\n",
    "          HumanResponseEvent(\n",
    "              response=response\n",
    "          )\n",
    "      )\n",
    "\n",
    "response = await handler\n",
    "print(\"Agent complete! Here's your final result:\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610fff23-cad0-4690-b166-2cc399f3e0c3",
   "metadata": {},
   "source": [
    "## Congratulations!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb621327-73da-4946-a546-cd80732a03ae",
   "metadata": {},
   "source": [
    "You've successfully created an AI agent that responds to spoken feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562cecca",
   "metadata": {},
   "source": [
    "## Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce98a735",
   "metadata": {},
   "source": [
    "To learn more about agentic document workflows, you check this [article](https://www.llamaindex.ai/blog/introducing-agentic-document-workflows) and theses [example implementations](https://github.com/run-llama/llamacloud-demo/tree/main/examples/document_workflows)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ADW)",
   "language": "python",
   "name": "adw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
