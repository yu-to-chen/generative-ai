{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435c8bc3-427f-4ec6-85ac-088505a29023",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ./my_acp_project/test_crew_server.py\n",
    "\n",
    "# Wrapping the RAG Agent into an ACP Server\n",
    "# Somehow, we have to run in the \"my_acp_project\" directory environment\n",
    "# It complains not finding acp_sdk\n",
    "\n",
    "# Make sure jupyter notebook and python shell using the same python version\n",
    "# pip install ipykernel\n",
    "# python -m ipykernel install --user --name=env13 --display-name \"Python (env13)\"\n",
    "# acp_sdk installing for python >= 3.11, here we use python 3.13.5\n",
    "\n",
    "from collections.abc import AsyncGenerator\n",
    "from acp_sdk.models import Message, MessagePart\n",
    "from acp_sdk.server import RunYield, RunYieldResume, Server\n",
    "\n",
    "from crewai import Crew, Task, Agent, LLM\n",
    "from crewai_tools import RagTool\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "server = Server()\n",
    "llm = LLM(model=\"ollama_chat/qwen2.5:14b\", base_url=\"http://localhost:11434\", max_tokens=8192)\n",
    "\n",
    "config = {\n",
    "    \"llm\": {\n",
    "        \"provider\": \"ollama\",\n",
    "        \"config\": {\n",
    "            \"model\": \"qwen2.5:14b\",\n",
    "        }\n",
    "    },\n",
    "    \"embedding_model\": {\n",
    "        \"provider\": \"openai\",\n",
    "        \"config\": {\n",
    "            \"model\": \"text-embedding-3-small\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "rag_tool = RagTool(config=config,  \n",
    "                   chunk_size=1200,       \n",
    "                   chunk_overlap=200,     \n",
    "                  )\n",
    "rag_tool.add(\"../data/王梓蓉_論文改稿_v2.pdf\", data_type=\"pdf_file\")\n",
    "\n",
    "\n",
    "@server.agent()\n",
    "async def research_agent(input: list[Message]) -> AsyncGenerator[RunYield, RunYieldResume]:\n",
    "    \"This is an agent for questions around a research thesis, it uses a RAG pattern to find answers based on the thesis. Use it to help answer questions on the thesis and its research.\"\n",
    "\n",
    "    thesis_agent = Agent(\n",
    "        role=\"Senior thesis qa Assistant\", \n",
    "        goal=\"Understand the content of a thesis\",\n",
    "        backstory=\"You are an expert qa agent designed to assist with research queries for a particular thesis\",\n",
    "        verbose=True,\n",
    "        allow_delegation=False,\n",
    "        llm=llm,\n",
    "        tools=[rag_tool], \n",
    "        max_retry_limit=5\n",
    "    )\n",
    "    \n",
    "    task1 = Task(\n",
    "        description=\"What is the contribution of the thesis?\",\n",
    "        expected_output = \"A comprehensive response as to the users question\",\n",
    "        agent=thesis_agent\n",
    "    )\n",
    "    crew = Crew(agents=[thesis_agent], tasks=[task1], verbose=True)\n",
    "    \n",
    "    task_output = await crew.kickoff_async()\n",
    "    yield Message(parts=[MessagePart(content=str(task_output))])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    server.run(port=8001)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
