{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "958c961c-02fd-47de-ad89-ec4d757bcffb",
   "metadata": {},
   "source": [
    "# L2: DSPy Programming - Signatures and Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b78a748-1059-4643-a44a-f3a8eae034b7",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#fff6e4; padding:15px; border-width:3px; border-color:#f5ecda; border-style:solid; border-radius:6px\"> ‚è≥ <b>Note <code>(Kernel Starting)</code>:</b> This notebook takes about 30 seconds to be ready to use. You may start and watch the video while you wait.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14d44d51-79dd-4655-92c0-53226cf80b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: litellm in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (1.61.13)\n",
      "Collecting litellm\n",
      "  Downloading litellm-1.72.1-py3-none-any.whl.metadata (39 kB)\n",
      "Requirement already satisfied: aiohttp in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from litellm) (3.11.11)\n",
      "Requirement already satisfied: click in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from litellm) (8.1.7)\n",
      "Requirement already satisfied: httpx>=0.23.0 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from litellm) (0.27.2)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from litellm) (8.5.0)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from litellm) (3.1.4)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from litellm) (4.23.0)\n",
      "Requirement already satisfied: openai>=1.68.2 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from litellm) (1.76.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from litellm) (2.11.4)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from litellm) (1.0.1)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from litellm) (0.7.0)\n",
      "Requirement already satisfied: tokenizers in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from litellm) (0.20.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from jinja2<4.0.0,>=3.1.2->litellm) (2.1.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (0.20.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0.0->litellm) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0.0->litellm) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0.0->litellm) (4.13.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0.0->litellm) (0.4.0)\n",
      "Requirement already satisfied: anyio in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from httpx>=0.23.0->litellm) (4.9.0)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from httpx>=0.23.0->litellm) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from httpx>=0.23.0->litellm) (1.0.5)\n",
      "Requirement already satisfied: idna in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from httpx>=0.23.0->litellm) (3.10)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from httpx>=0.23.0->litellm) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.23.0->litellm) (0.14.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from importlib-metadata>=6.8.0->litellm) (3.21.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from openai>=1.68.2->litellm) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from openai>=1.68.2->litellm) (0.8.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from openai>=1.68.2->litellm) (4.66.5)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from tiktoken>=0.7.0->litellm) (2024.9.11)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from tiktoken>=0.7.0->litellm) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm) (2.2.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from aiohttp->litellm) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from aiohttp->litellm) (1.3.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from aiohttp->litellm) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from aiohttp->litellm) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from aiohttp->litellm) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from aiohttp->litellm) (1.18.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from tokenizers->litellm) (0.25.2)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (6.0.2)\n",
      "Downloading litellm-1.72.1-py3-none-any.whl (8.0 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: litellm\n",
      "  Attempting uninstall: litellm\n",
      "    Found existing installation: litellm 1.61.13\n",
      "    Uninstalling litellm-1.61.13:\n",
      "      Successfully uninstalled litellm-1.61.13\n",
      "Successfully installed litellm-1.72.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install --upgrade litellm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "471fa7d9-21f6-460f-a7ef-846a17967dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: litellm\n",
      "Version: 1.72.1\n",
      "Summary: Library to easily interface with LLM API providers\n",
      "Home-page: https://litellm.ai\n",
      "Author: BerriAI\n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages\n",
      "Requires: aiohttp, click, httpx, importlib-metadata, jinja2, jsonschema, openai, pydantic, python-dotenv, tiktoken, tokenizers\n",
      "Required-by: crewai, dspy\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show litellm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8751b1c3",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "from helper import get_openai_api_key\n",
    "openai_api_key = get_openai_api_key()\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"]  = get_openai_api_key()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e035d9-152b-4f5b-9b89-487e556618de",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "<p> üíª &nbsp; <b>Access <code>requirements.txt</code> and <code>helper.py</code> files:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em>.</p>\n",
    "\n",
    "<p> ‚¨á &nbsp; <b>Download Notebooks:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Download as\"</em> and select <em>\"Notebook (.ipynb)\"</em>.</p>\n",
    "\n",
    "<p> üìí &nbsp; For more help, please see the <em>\"Appendix ‚Äì Tips, Help, and Download\"</em> Lesson.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72705217-455a-485d-a12f-4b4f60c0fd6b",
   "metadata": {},
   "source": [
    "### Set up API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "102d2afa-874a-4396-8273-f5a4896bd906",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "from helper import get_openai_api_key\n",
    "openai_api_key = get_openai_api_key()\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = get_openai_api_key()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514ebd71-0dbd-42b8-84fd-975610e4d253",
   "metadata": {},
   "source": [
    "### Configure the LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a48bd6ed-0d8f-4348-a09c-ab860b63e40c",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "import dspy\n",
    "dspy.settings.configure(lm=dspy.LM(\"openai/gpt-4o-mini\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0e0fcc-4539-46e0-af97-a4c765acab8f",
   "metadata": {},
   "source": [
    "## Use DSPy built-in Module to Build a Sentiment Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "346f5302-0903-4595-97f7-818c637f11aa",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "class SentimentClassifier(dspy.Signature):\n",
    "    \"\"\"Classify the sentiment of a text.\"\"\"\n",
    "\n",
    "    text: str = dspy.InputField(desc=\"input text to classify sentiment\")\n",
    "    sentiment: int = dspy.OutputField(\n",
    "        desc=\"sentiment, the higher the more positive\", ge=0, le=10\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "558d3e54-cbb8-4229-8d1c-7f9b37283048",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "str_signature = dspy.make_signature(\"text -> sentiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4c1e4f-b241-4c26-ac91-c2fc2b54c6c6",
   "metadata": {},
   "source": [
    "### Create a Module to Interact with the LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cbcc28ff-181f-4a92-b7e8-370d39128904",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "predict = dspy.Predict(SentimentClassifier) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68ac1acd-6bc3-43be-829f-df4bbe30ddb3",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(\n",
      "    sentiment=8\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "output = predict(text=\"I am feeling pretty happy!\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58a7eda0-ad5f-4cd5-a9e4-9e13934ed9d2",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment is: 8\n",
      "The sentiment is: 8\n"
     ]
    }
   ],
   "source": [
    "print(f\"The sentiment is: {output.sentiment}\")\n",
    "print(f\"The sentiment is: {output['sentiment']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be5d025e-4c94-48af-b99c-62815ee1b84c",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(\n",
      "    sentiment=4\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "dspy.configure(lm=dspy.LM(\"openai/gpt-4o\"))\n",
    "print(predict(text=\"I am feeling pretty happy!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "85f2ee29-15b4-4a89-b09c-ec2b6b99b16b",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "dspy.configure(lm=dspy.LM(\"openai/gpt-4o-mini\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2b9084-2b06-4c22-9683-0a2e4c0a45b0",
   "metadata": {},
   "source": [
    "### Wait, Where is My Prompt? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a70885d-6cb0-4d90-bbf0-f5da296d5420",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-06-05T12:40:50.180584]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `text` (str): input text to classify sentiment\n",
      "\n",
      "Your output fields are:\n",
      "1. `sentiment` (int): sentiment, the higher the more positive\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "Inputs will have the following structure:\n",
      "\n",
      "[[ ## text ## ]]\n",
      "{text}\n",
      "\n",
      "Outputs will be a JSON object with the following fields.\n",
      "\n",
      "{\n",
      "  \"sentiment\": \"{sentiment}        # note: the value you produce must be a single int value\"\n",
      "}\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        Classify the sentiment of a text.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## text ## ]]\n",
      "I am feeling pretty happy!\n",
      "\n",
      "Respond with a JSON object in the following order of fields: `sentiment` (must be formatted as a valid Python int).\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m{\"sentiment\":4}\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dspy.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e36f97e-5414-4749-939f-0bd1f20e3ab0",
   "metadata": {},
   "source": [
    "### Try a Different Built-in Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e86d738-468c-4269-bb51-8ecfc2b6ccfc",
   "metadata": {
    "height": 81
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(\n",
      "    reasoning=\"Reasoning: Let's think step by step in order to analyze the text. The phrase 'I am feeling pretty happy!' expresses a positive emotion. The use of the word 'happy' indicates a strong positive sentiment. Therefore, the overall sentiment of the text is positive.\",\n",
      "    sentiment=8\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cot = dspy.ChainOfThought(SentimentClassifier)\n",
    "\n",
    "output = cot(text=\"I am feeling pretty happy!\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad92d6d2-554a-4d8a-b647-2f7c4ba97b08",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-06-05T12:40:55.439895]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `text` (str): input text to classify sentiment\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `sentiment` (int): sentiment, the higher the more positive\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "Inputs will have the following structure:\n",
      "\n",
      "[[ ## text ## ]]\n",
      "{text}\n",
      "\n",
      "Outputs will be a JSON object with the following fields.\n",
      "\n",
      "{\n",
      "  \"reasoning\": \"{reasoning}\",\n",
      "  \"sentiment\": \"{sentiment}        # note: the value you produce must be a single int value\"\n",
      "}\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        Classify the sentiment of a text.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## text ## ]]\n",
      "I am feeling pretty happy!\n",
      "\n",
      "Respond with a JSON object in the following order of fields: `reasoning`, then `sentiment` (must be formatted as a valid Python int).\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m{\"reasoning\":\"Reasoning: Let's think step by step in order to analyze the text. The phrase 'I am feeling pretty happy!' expresses a positive emotion. The use of the word 'happy' indicates a strong positive sentiment. Therefore, the overall sentiment of the text is positive.\",\"sentiment\":8}\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dspy.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71f2d32-2336-4a54-9c2c-ef41109125c1",
   "metadata": {},
   "source": [
    "### Use a Different Adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "baa8ca69-13e8-47cc-9965-b0e280a383ce",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "dspy.configure(adapter=dspy.JSONAdapter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "984fa475-0220-4ab8-995f-492afa09385a",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(\n",
      "    reasoning=\"Reasoning: Let's think step by step in order to analyze the text. The phrase 'I am feeling pretty happy!' expresses a positive emotion. The use of the word 'happy' indicates a strong positive sentiment. Therefore, the overall sentiment of the text is positive.\",\n",
      "    sentiment=8\n",
      ")\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-06-05T12:41:00.645861]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `text` (str): input text to classify sentiment\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `sentiment` (int): sentiment, the higher the more positive\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "Inputs will have the following structure:\n",
      "\n",
      "[[ ## text ## ]]\n",
      "{text}\n",
      "\n",
      "Outputs will be a JSON object with the following fields.\n",
      "\n",
      "{\n",
      "  \"reasoning\": \"{reasoning}\",\n",
      "  \"sentiment\": \"{sentiment}        # note: the value you produce must be a single int value\"\n",
      "}\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        Classify the sentiment of a text.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## text ## ]]\n",
      "I am feeling pretty happy!\n",
      "\n",
      "Respond with a JSON object in the following order of fields: `reasoning`, then `sentiment` (must be formatted as a valid Python int).\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m{\"reasoning\":\"Reasoning: Let's think step by step in order to analyze the text. The phrase 'I am feeling pretty happy!' expresses a positive emotion. The use of the word 'happy' indicates a strong positive sentiment. Therefore, the overall sentiment of the text is positive.\",\"sentiment\":8}\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cot(text=\"I am feeling pretty happy!\"))\n",
    "dspy.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22921dc6-d6ff-4306-82b7-60cc2ef09bff",
   "metadata": {},
   "source": [
    "## Build a Program with Custom Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "757973e3-0716-4e6b-99ed-010ffb3e8390",
   "metadata": {
    "height": 1169
   },
   "outputs": [],
   "source": [
    "class QuestionGenerator(dspy.Signature):\n",
    "    \"\"\"Generate a yes or no question in order to guess the celebrity name in users' mind. You can ask in general or directly guess the name if you think the signal is enough. You should never ask the same question in the past_questions.\"\"\"\n",
    "    past_questions: list[str] = dspy.InputField(desc=\"past questions asked\")\n",
    "    past_answers: list[bool] = dspy.InputField(desc=\"past answers\")\n",
    "    new_question: str = dspy.OutputField(desc=\"new question that can help narrow down the celebrity name\")\n",
    "    guess_made: bool = dspy.OutputField(desc=\"If the new_question is the celebrity name guess, set to True, if it is still a general question set to False\")\n",
    "\n",
    "\n",
    "class Reflection(dspy.Signature):\n",
    "    \"\"\"Provide reflection on the guessing process\"\"\"\n",
    "    correct_celebrity_name: str = dspy.InputField(desc=\"the celebrity name in user's mind\")\n",
    "    final_guessor_question: str = dspy.InputField(desc=\"the final guess or question LM made\")\n",
    "    past_questions: list[str] = dspy.InputField(desc=\"past questions asked\")\n",
    "    past_answers: list[bool] = dspy.InputField(desc=\"past answers\")\n",
    "\n",
    "    reflection: str = dspy.OutputField(\n",
    "        desc=\"reflection on the guessing process, including what was done well and what can be improved\"\n",
    "    )\n",
    "\n",
    "def ask(prompt, valid_responses=(\"y\", \"n\")):\n",
    "    while True:\n",
    "        response = input(f\"{prompt} ({'/'.join(valid_responses)}): \").strip().lower()\n",
    "        if response in valid_responses:\n",
    "            return response\n",
    "        print(f\"Please enter one of: {', '.join(valid_responses)}\")\n",
    "\n",
    "class CelebrityGuess(dspy.Module):\n",
    "    def __init__(self, max_tries=10):\n",
    "        super().__init__()\n",
    "\n",
    "        self.question_generator = dspy.ChainOfThought(QuestionGenerator)\n",
    "        self.reflection = dspy.ChainOfThought(Reflection)\n",
    "\n",
    "        self.max_tries = 20\n",
    "\n",
    "    def forward(self):\n",
    "        celebrity_name = input(\"Please think of a celebrity name, once you are ready, type the name and press enter...\")\n",
    "        past_questions = []\n",
    "        past_answers = []\n",
    "\n",
    "        correct_guess = False\n",
    "\n",
    "        for i in range(self.max_tries):\n",
    "            question = self.question_generator(\n",
    "                past_questions=past_questions,\n",
    "                past_answers=past_answers,\n",
    "            )\n",
    "            answer = ask(f\"{question.new_question}\").lower() == \"y\"\n",
    "            past_questions.append(question.new_question)\n",
    "            past_answers.append(answer)\n",
    "\n",
    "            if question.guess_made and answer:\n",
    "                correct_guess = True\n",
    "                break\n",
    "\n",
    "        if correct_guess:\n",
    "            print(\"Yay! I got it right!\")\n",
    "        else:\n",
    "            print(\"Oops, I couldn't guess it right.\")\n",
    "\n",
    "        reflection = self.reflection(\n",
    "            correct_celebrity_name=celebrity_name,\n",
    "            final_guessor_question=question.new_question,\n",
    "            past_questions=past_questions,\n",
    "            past_answers=past_answers,\n",
    "        )\n",
    "        print(reflection.reflection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "74e7da57-2b07-404b-87ad-633dc751511b",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "celebrity_guess = CelebrityGuess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cabb8dd3-cdcd-4d93-b04d-cd6915981cb5",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please think of a celebrity name, once you are ready, type the name and press enter... Donald Trump\n",
      "New Question: Is the celebrity you are thinking of male? (y/n):  y\n",
      "New Question: Is the celebrity you are thinking of known for acting? (y/n):  n\n",
      "New Question: Is the celebrity you are thinking of known for music? (y/n):  n\n",
      "New Question: Is the celebrity you are thinking of known for sports? (y/n):  n\n",
      "New Question: Is the celebrity you are thinking of known for their work in politics? (y/n):  y\n",
      "New Question: Is the celebrity you are thinking of currently active in politics? (y/n):  y\n",
      "New Question: Is the celebrity you are thinking of a current or former president? (y/n):  y\n",
      "New Question: Is the celebrity you are thinking of still alive? (y/n):  y\n",
      "New Question: Is the celebrity you are thinking of a Democrat? (y/n):  n\n",
      "New Question: Is the celebrity you are thinking of known for a significant political event or action during their presidency? (y/n):  y\n",
      "New Question: Did the celebrity you are thinking of serve as president in the 21st century? (y/n):  y\n",
      "New Question: Is the celebrity you are thinking of Barack Obama? (y/n):  n\n",
      "Is the celebrity you are thinking of Joe Biden? (y/n):  n\n",
      "New Question: Is the celebrity you are thinking of a former president from the 20th century? (y/n):  n\n",
      "Is the celebrity you are thinking of Ronald Reagan? (y/n):  n\n",
      "Is the celebrity you are thinking of Bill Clinton? (y/n):  n\n",
      "Is the celebrity you are thinking of George W. Bush? (y/n):  n\n",
      "Is the celebrity you are thinking of Jimmy Carter? (y/n):  n\n",
      "Is the celebrity you are thinking of Joe Biden? (y/n):  n\n",
      "New Question: Is the celebrity you are thinking of the current president of the United States? (y/n):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oops, I couldn't guess it right.\n",
      "Reflection: The guessing process was quite thorough, as it effectively narrowed down the options through a series of targeted questions. The questions about political affiliation and significant events during the presidency were particularly useful. However, the final question could have been framed differently to avoid confusion, as it directly asked about the current president, which led to a false conclusion. In future iterations, it might be beneficial to clarify the time frame of the presidency in the questions to avoid such pitfalls.\n"
     ]
    }
   ],
   "source": [
    "celebrity_guess()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c17054-4872-4ed7-a8a3-13162c0dad70",
   "metadata": {},
   "source": [
    "## Save and Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "21ae42d9-f703-4432-9910-82c4fbdae0e6",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "celebrity_guess.save(\"dspy_program/celebrity.json\", save_program=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bf744c20-9b74-4c1e-9fac-a56d54db47ff",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "celebrity_guess.load(\"dspy_program/celebrity.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "785bbeae-fc9a-48b8-ad73-f280e04dada6",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "celebrity_guess.save(\"dspy_program/celebrity/\", save_program=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eb548d44-b176-4629-8fe3-57d0573181ac",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "loaded = dspy.load(\"dspy_program/celebrity/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d93f8c-e8d1-4408-9941-331cf68faae8",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "loaded()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9fdf73-27a5-4925-bfb7-343c6ac6c58e",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d226b779-6b8e-4ff9-a0a2-86df42c9499d",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747385d3-6611-484f-b7c7-78564be67b0d",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0aa5186-bc89-4b64-9639-5e51a53ec4e6",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc92dddb-7808-4b51-9443-4ef903dfa39f",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb15b565-92b8-4637-bac9-5e53736873ba",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93e3c41-ec8e-4624-a188-a90886158769",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e302ec73-a9f4-4ab7-b548-b321688a35a8",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce60cd9-d5a5-42f9-a375-b3ead2137e99",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1347cbdb-b9ce-4029-90ad-c7cf38043df2",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4e3c7b-1fb4-478c-9ad4-bbf187a49b53",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e988337-bc5c-4f26-a6cb-a74cd694b746",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dcce24-0aa3-44df-bbae-c49a9801522f",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca43556c",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80a8d0a",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
