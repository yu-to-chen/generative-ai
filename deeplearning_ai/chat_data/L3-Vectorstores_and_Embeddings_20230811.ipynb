{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02a0e38d",
   "metadata": {},
   "source": [
    "# Vectorstores and Embeddings\n",
    "Recall the overall workflow for retrieval augmented generation (RAG):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "170c7895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chromadb\n",
      "  Obtaining dependency information for chromadb from https://files.pythonhosted.org/packages/5f/86/599e1482723dea206ad269aece4e4907f4a981840fcb6c731d39f79098ed/chromadb-0.4.5-py3-none-any.whl.metadata\n",
      "  Downloading chromadb-0.4.5-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: requests>=2.28 in ./env3/lib/python3.11/site-packages (from chromadb) (2.31.0)\n",
      "Requirement already satisfied: pydantic<2.0,>=1.9 in ./env3/lib/python3.11/site-packages (from chromadb) (1.10.12)\n",
      "Collecting chroma-hnswlib==0.7.2 (from chromadb)\n",
      "  Using cached chroma-hnswlib-0.7.2.tar.gz (31 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting fastapi<0.100.0,>=0.95.2 (from chromadb)\n",
      "  Obtaining dependency information for fastapi<0.100.0,>=0.95.2 from https://files.pythonhosted.org/packages/73/eb/03b691afa0b5ffa1e93ed34f97ec1e7855c758efbdcfb16c209af0b0506b/fastapi-0.99.1-py3-none-any.whl.metadata\n",
      "  Downloading fastapi-0.99.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting uvicorn[standard]>=0.18.3 (from chromadb)\n",
      "  Obtaining dependency information for uvicorn[standard]>=0.18.3 from https://files.pythonhosted.org/packages/79/96/b0882a1c3f7ef3dd86879e041212ae5b62b4bd352320889231cc735a8e8f/uvicorn-0.23.2-py3-none-any.whl.metadata\n",
      "  Downloading uvicorn-0.23.2-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: numpy>=1.21.6 in ./env3/lib/python3.11/site-packages (from chromadb) (1.25.2)\n",
      "Collecting posthog>=2.4.0 (from chromadb)\n",
      "  Using cached posthog-3.0.1-py2.py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./env3/lib/python3.11/site-packages (from chromadb) (4.7.1)\n",
      "Collecting pulsar-client>=3.1.0 (from chromadb)\n",
      "  Obtaining dependency information for pulsar-client>=3.1.0 from https://files.pythonhosted.org/packages/bf/a6/ae8f5ffea04e58b155612f5236ca05aa2f7c2490407bc8c64b60c0d8c7a6/pulsar_client-3.2.0-cp311-cp311-macosx_10_15_universal2.whl.metadata\n",
      "  Downloading pulsar_client-3.2.0-cp311-cp311-macosx_10_15_universal2.whl.metadata (1.0 kB)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Obtaining dependency information for onnxruntime>=1.14.1 from https://files.pythonhosted.org/packages/17/2f/83f6ef69403624e74bc068f8674af34d3af44314a808adac267b2e379171/onnxruntime-1.15.1-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading onnxruntime-1.15.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
      "Collecting tokenizers>=0.13.2 (from chromadb)\n",
      "  Downloading tokenizers-0.13.3-cp311-cp311-macosx_12_0_arm64.whl (3.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pypika>=0.48.9 (from chromadb)\n",
      "  Using cached PyPika-0.48.9.tar.gz (67 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.65.0 in ./env3/lib/python3.11/site-packages (from chromadb) (4.66.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in ./env3/lib/python3.11/site-packages (from chromadb) (7.4.0)\n",
      "Collecting importlib-resources (from chromadb)\n",
      "  Obtaining dependency information for importlib-resources from https://files.pythonhosted.org/packages/25/d4/592f53ce2f8dde8be5720851bd0ab71cc2e76c55978e4163ef1ab7e389bb/importlib_resources-6.0.1-py3-none-any.whl.metadata\n",
      "  Downloading importlib_resources-6.0.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting starlette<0.28.0,>=0.27.0 (from fastapi<0.100.0,>=0.95.2->chromadb)\n",
      "  Obtaining dependency information for starlette<0.28.0,>=0.27.0 from https://files.pythonhosted.org/packages/58/f8/e2cca22387965584a409795913b774235752be4176d276714e15e1a58884/starlette-0.27.0-py3-none-any.whl.metadata\n",
      "  Downloading starlette-0.27.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
      "  Obtaining dependency information for flatbuffers from https://files.pythonhosted.org/packages/6f/12/d5c79ee252793ffe845d58a913197bfa02ae9a0b5c9bc3dc4b58d477b9e7/flatbuffers-23.5.26-py2.py3-none-any.whl.metadata\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Requirement already satisfied: packaging in ./env3/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (23.1)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Obtaining dependency information for protobuf from https://files.pythonhosted.org/packages/01/f5/4d4465795340d288de56ecae61fac7d3a646eb26dc6face8578d31fcafff/protobuf-4.24.0-cp37-abi3-macosx_10_9_universal2.whl.metadata\n",
      "  Downloading protobuf-4.24.0-cp37-abi3-macosx_10_9_universal2.whl.metadata (540 bytes)\n",
      "Collecting sympy (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Requirement already satisfied: six>=1.5 in ./env3/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb) (1.16.0)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
      "  Using cached monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: python-dateutil>2.1 in ./env3/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb) (2.8.2)\n",
      "Requirement already satisfied: certifi in ./env3/lib/python3.11/site-packages (from pulsar-client>=3.1.0->chromadb) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./env3/lib/python3.11/site-packages (from requests>=2.28->chromadb) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./env3/lib/python3.11/site-packages (from requests>=2.28->chromadb) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./env3/lib/python3.11/site-packages (from requests>=2.28->chromadb) (2.0.4)\n",
      "Collecting click>=7.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Obtaining dependency information for click>=7.0 from https://files.pythonhosted.org/packages/1a/70/e63223f8116931d365993d4a6b7ef653a4d920b41d03de7c59499962821f/click-8.1.6-py3-none-any.whl.metadata\n",
      "  Downloading click-8.1.6-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting h11>=0.8 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Obtaining dependency information for httptools>=0.5.0 from https://files.pythonhosted.org/packages/85/df/63720eadbadca00b7f91bc724972ca3a946670598354bef1de779c7c62e2/httptools-0.6.0-cp311-cp311-macosx_10_9_universal2.whl.metadata\n",
      "  Downloading httptools-0.6.0-cp311-cp311-macosx_10_9_universal2.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in ./env3/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./env3/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (6.0.1)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvloop-0.17.0-cp311-cp311-macosx_10_9_universal2.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached watchfiles-0.19.0-cp37-abi3-macosx_11_0_arm64.whl (388 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading websockets-11.0.3-cp311-cp311-macosx_11_0_arm64.whl (121 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.0/121.0 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: anyio<5,>=3.4.0 in ./env3/lib/python3.11/site-packages (from starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb) (3.7.1)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Collecting mpmath>=0.19 (from sympy->onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./env3/lib/python3.11/site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi<0.100.0,>=0.95.2->chromadb) (1.3.0)\n",
      "Downloading chromadb-0.4.5-py3-none-any.whl (402 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.8/402.8 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fastapi-0.99.1-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading onnxruntime-1.15.1-cp311-cp311-macosx_11_0_arm64.whl (6.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pulsar_client-3.2.0-cp311-cp311-macosx_10_15_universal2.whl (10.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading importlib_resources-6.0.1-py3-none-any.whl (34 kB)\n",
      "Downloading click-8.1.6-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httptools-0.6.0-cp311-cp311-macosx_10_9_universal2.whl (233 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.2/233.2 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached starlette-0.27.0-py3-none-any.whl (66 kB)\n",
      "Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Downloading protobuf-4.24.0-cp37-abi3-macosx_10_9_universal2.whl (409 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.6/409.6 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvicorn-0.23.2-py3-none-any.whl (59 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: chroma-hnswlib, pypika\n",
      "  Building wheel for chroma-hnswlib (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for chroma-hnswlib: filename=chroma_hnswlib-0.7.2-cp311-cp311-macosx_13_0_arm64.whl size=195661 sha256=a12432a63614dbe5ec21dc5bea29feadf8a1fddf3390ca77a9f949c6bfabed33\n",
      "  Stored in directory: /Users/ytchen/Library/Caches/pip/wheels/1e/fb/8d/3c2f10bfe53319fa5d6dc00886919aec106ffb442e1d3379fb\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53723 sha256=98121633e8f075acf04879189068de1d8f88e5bec3c7066040a5a68cd9960766\n",
      "  Stored in directory: /Users/ytchen/Library/Caches/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
      "Successfully built chroma-hnswlib pypika\n",
      "Installing collected packages: tokenizers, pypika, mpmath, monotonic, flatbuffers, websockets, uvloop, sympy, pulsar-client, protobuf, importlib-resources, humanfriendly, httptools, h11, click, chroma-hnswlib, backoff, watchfiles, uvicorn, starlette, posthog, coloredlogs, onnxruntime, fastapi, chromadb\n",
      "Successfully installed backoff-2.2.1 chroma-hnswlib-0.7.2 chromadb-0.4.5 click-8.1.6 coloredlogs-15.0.1 fastapi-0.99.1 flatbuffers-23.5.26 h11-0.14.0 httptools-0.6.0 humanfriendly-10.0 importlib-resources-6.0.1 monotonic-1.6 mpmath-1.3.0 onnxruntime-1.15.1 posthog-3.0.1 protobuf-4.24.0 pulsar-client-3.2.0 pypika-0.48.9 starlette-0.27.0 sympy-1.12 tokenizers-0.13.3 uvicorn-0.23.2 uvloop-0.17.0 watchfiles-0.19.0 websockets-11.0.3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade chromadb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f07dae27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028d8db7",
   "metadata": {},
   "source": [
    "We just discussed Document Loading and Splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8595586",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# Load PDF\n",
    "loaders = [\n",
    "    # Duplicate documents on purpose - messy data\n",
    "    PyPDFLoader(\"docs/cs229_lectures/MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(\"docs/cs229_lectures/MachineLearning-Lecture01.pdf\"),\n",
    "    PyPDFLoader(\"docs/cs229_lectures/MachineLearning-Lecture02.pdf\"),\n",
    "    PyPDFLoader(\"docs/cs229_lectures/MachineLearning-Lecture03.pdf\")\n",
    "]\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38c47949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 150\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bffb67f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = text_splitter.split_documents(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c471804f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa38802",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "Let's take our splits and embed them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9baa8eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "embedding = OpenAIEmbeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01324ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \"i like dogs\"\n",
    "sentence2 = \"i like canines\"\n",
    "sentence3 = \"the weather is ugly outside\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95d87cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding1 = embedding.embed_query(sentence1)\n",
    "embedding2 = embedding.embed_query(sentence2)\n",
    "embedding3 = embedding.embed_query(sentence3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7cbe5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "824e41dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9631908238968823"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(embedding1, embedding2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df2bbd39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7711177746511548"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(embedding1, embedding3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "379dc355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7596334095818107"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(embedding2, embedding3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e60563",
   "metadata": {},
   "source": [
    "## Vectorstores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d8f8b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc5943fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79d84ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = 'docs/chroma/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95c9d3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./docs/chroma  # remove old database files if any\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67243b60",
   "metadata": {},
   "source": [
    "## Cannot upgrade sqlite to 3.35.0???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86b1746a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0145579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209\n"
     ]
    }
   ],
   "source": [
    "print(vectordb._collection.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba605ca",
   "metadata": {},
   "source": [
    "## Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2fc85706",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"is there an email i can ask for help\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15a4de34",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(question,k=3) # k is number of documents \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e8be2a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3329787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"cs229-qa@cs.stanford.edu. This goes to an acc ount that's read by all the TAs and me. So \\nrather than sending us email individually, if you send email to this account, it will \\nactually let us get back to you maximally quickly with answers to your questions.  \\nIf you're asking questions about homework probl ems, please say in the subject line which \\nassignment and which question the email refers to, since that will also help us to route \\nyour question to the appropriate TA or to me  appropriately and get the response back to \\nyou quickly.  \\nLet's see. Skipping ahead — let's see — for homework, one midterm, one open and term \\nproject. Notice on the honor code. So one thi ng that I think will help you to succeed and \\ndo well in this class and even help you to enjoy this cla ss more is if you form a study \\ngroup.  \\nSo start looking around where you' re sitting now or at the end of class today, mingle a \\nlittle bit and get to know your classmates. I strongly encourage you to form study groups \\nand sort of have a group of people to study with and have a group of your fellow students \\nto talk over these concepts with. You can also  post on the class news group if you want to \\nuse that to try to form a study group.  \\nBut some of the problems sets in this cla ss are reasonably difficult.  People that have \\ntaken the class before may tell you they were very difficult. And just I bet it would be \\nmore fun for you, and you'd probably have a be tter learning experience if you form a\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed8c256a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb.persist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9da949f",
   "metadata": {},
   "source": [
    "## Failure modes\n",
    "This seems great, and basic similarity search will get you 80% of the way there very easily.\n",
    "\n",
    "But there are some failure modes that can creep up.\n",
    "\n",
    "Here are some edge cases that can arise - we'll fix them in the next class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd63fa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about matlab?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f303aa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(question,k=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c86465",
   "metadata": {},
   "source": [
    "Notice that we're getting duplicate chunks (because of the duplicate MachineLearning-Lecture01.pdf in the index).\n",
    "\n",
    "Semantic search fetches all similar documents, but does not enforce diversity.\n",
    "\n",
    "docs[0] and docs[1] are indentical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6badb8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='those homeworks will be done in either MATLA B or in Octave, which is sort of — I \\nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn\\'t.  \\nSo I guess for those of you that haven\\'t s een MATLAB before, and I know most of you \\nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \\nplot data. And it\\'s sort of an extremely easy to  learn tool to use for implementing a lot of \\nlearning algorithms.  \\nAnd in case some of you want to work on your  own home computer or something if you \\ndon\\'t have a MATLAB license, for the purposes of  this class, there\\'s also — [inaudible] \\nwrite that down [inaudible] MATLAB — there\\' s also a software package called Octave \\nthat you can download for free off the Internet. And it has somewhat fewer features than MATLAB, but it\\'s free, and for the purposes of  this class, it will work for just about \\neverything.  \\nSo actually I, well, so yeah, just a side comment for those of you that haven\\'t seen \\nMATLAB before I guess, once a colleague of mine at a different university, not at \\nStanford, actually teaches another machine l earning course. He\\'s taught it for many years. \\nSo one day, he was in his office, and an old student of his from, lik e, ten years ago came \\ninto his office and he said, \"Oh, professo r, professor, thank you so much for your', metadata={'page': 8, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3fbdc99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='those homeworks will be done in either MATLA B or in Octave, which is sort of — I \\nknow some people call it a free ve rsion of MATLAB, which it sort  of is, sort of isn\\'t.  \\nSo I guess for those of you that haven\\'t s een MATLAB before, and I know most of you \\nhave, MATLAB is I guess part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to \\nplot data. And it\\'s sort of an extremely easy to  learn tool to use for implementing a lot of \\nlearning algorithms.  \\nAnd in case some of you want to work on your  own home computer or something if you \\ndon\\'t have a MATLAB license, for the purposes of  this class, there\\'s also — [inaudible] \\nwrite that down [inaudible] MATLAB — there\\' s also a software package called Octave \\nthat you can download for free off the Internet. And it has somewhat fewer features than MATLAB, but it\\'s free, and for the purposes of  this class, it will work for just about \\neverything.  \\nSo actually I, well, so yeah, just a side comment for those of you that haven\\'t seen \\nMATLAB before I guess, once a colleague of mine at a different university, not at \\nStanford, actually teaches another machine l earning course. He\\'s taught it for many years. \\nSo one day, he was in his office, and an old student of his from, lik e, ten years ago came \\ninto his office and he said, \"Oh, professo r, professor, thank you so much for your', metadata={'page': 8, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfb77aa",
   "metadata": {},
   "source": [
    "We can see a new failure mode.\n",
    "\n",
    "The question below asks a question about the third lecture, but includes results from other lectures as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "692d7269",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about regression in the third lecture?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "83b85399",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(question,k=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "19344ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 0, 'source': 'docs/cs229_lectures/MachineLearning-Lecture03.pdf'}\n",
      "{'page': 14, 'source': 'docs/cs229_lectures/MachineLearning-Lecture03.pdf'}\n",
      "{'page': 6, 'source': 'docs/cs229_lectures/MachineLearning-Lecture03.pdf'}\n",
      "{'page': 8, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n",
      "{'page': 8, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    print(doc.metadata)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8259e486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "into his office and he said, \"Oh, professo r, professor, thank you so much for your \n",
      "machine learning class. I learned so much from it. There's this stuff that I learned in your \n",
      "class, and I now use every day. And it's help ed me make lots of money, and here's a \n",
      "picture of my big house.\"  \n",
      "So my friend was very excited. He said, \"W ow. That's great. I'm glad to hear this \n",
      "machine learning stuff was actually useful. So what was it that you learned? Was it \n",
      "logistic regression? Was it the PCA? Was it the data ne tworks? What was it that you \n",
      "learned that was so helpful?\" And the student said, \"Oh, it was the MATLAB.\"  \n",
      "So for those of you that don't know MATLAB yet, I hope you do learn it. It's not hard, \n",
      "and we'll actually have a short MATLAB tutori al in one of the discussion sections for \n",
      "those of you that don't know it.  \n",
      "Okay. The very last piece of logistical th ing is the discussion s ections. So discussion \n",
      "sections will be taught by the TAs, and atte ndance at discussion sections is optional, \n",
      "although they'll also be recorded and televi sed. And we'll use the discussion sections \n",
      "mainly for two things. For the next two or th ree weeks, we'll use the discussion sections \n",
      "to go over the prerequisites to this class or if some of you haven't seen probability or \n",
      "statistics for a while or maybe algebra, we'll go over those in the discussion sections as a \n",
      "refresher for those of you that want one.\n"
     ]
    }
   ],
   "source": [
    "print(docs[4].page_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b433da8e",
   "metadata": {},
   "source": [
    "Approaches discussed in the next lecture can be used to address both!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88940169",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
