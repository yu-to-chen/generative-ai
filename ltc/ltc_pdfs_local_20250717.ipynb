{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d65762c7-085b-41e1-b35b-b9444ead0732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d014a695-4d14-4362-b5ac-f261111911fb",
   "metadata": {},
   "source": [
    "### CrewAI + Ollama + qwen2.5:14b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f29969b-8e60-4193-8ee9-d8b6deb4e337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Bellman equation is a key concept in decision-making processes, particularly in fields like economics, artificial intelligence, and operations research. It's used to solve complex problems by breaking them down into simpler sub-problems.\n",
      "\n",
      "Imagine you're playing a video game where at each level, you have choices that affect your score for that level and the options available in future levels. The Bellman equation helps you make decisions not just based on what gives you immediate rewards but also considers long-term benefits from those choices.\n",
      "\n",
      "In simple terms, it represents an optimal decision rule telling you how to act now given some information about what might happen later if you follow certain strategies or policies. It takes into account the current state (like your score and level in a game), possible actions you can take, immediate rewards for those actions, and potential future benefits.\n",
      "\n",
      "The equation looks like this: V(s) = max_a [R(s,a) + γ * ∑_s' P(s'|s,a)V(s')]\n",
      "\n",
      "Where:\n",
      "- V(s) is the value of being in state s.\n",
      "- a represents an action you can take in that state.\n",
      "- R(s, a) is the reward for taking action a in state s.\n",
      "- γ (gamma) is a discount factor between 0 and 1 that determines how much we care about future rewards compared to immediate ones.\n",
      "- P(s'|s,a) is the probability of moving to the next state s' from current state s by taking action a.\n",
      "- V(s') is the value of being in the next state.\n",
      "\n",
      "So, this equation helps you make decisions considering both immediate and long-term consequences. It's widely used in reinforcement learning algorithms where agents learn to take actions that maximize rewards over time.\n"
     ]
    }
   ],
   "source": [
    "from crewai import Agent, Crew, Task\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "def chat_with_llm(prompt, model=\"ollama_chat/qwen2.5:14b\", base_url=\"http://localhost:11434\", max_tokens=8192):\n",
    "    llm = OllamaLLM(\n",
    "        model=model,\n",
    "        base_url=base_url,\n",
    "        temperature=0.7,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "\n",
    "    agent = Agent(\n",
    "        role=\"Helpful assistant\",\n",
    "        goal=\"Respond accurately to user prompts\",\n",
    "        backstory=\"You are a concise and knowledgeable assistant.\",\n",
    "        verbose=False,\n",
    "        llm=llm\n",
    "    )\n",
    "\n",
    "    task = Task(\n",
    "        description=prompt,\n",
    "        expected_output=\"A helpful and accurate response to the user's prompt.\",\n",
    "        agent=agent\n",
    "    )\n",
    "\n",
    "    crew = Crew(\n",
    "        agents=[agent],\n",
    "        tasks=[task],\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    return crew.kickoff()\n",
    "\n",
    "## Example usage\n",
    "#if __name__ == \"__main__\":\n",
    "#    reply = chat_with_llm(\"Explain the Bellman equation in simple terms.\")\n",
    "#    print(reply)\n",
    "\n",
    "print(chat_with_llm(\"Explain the Bellman equation in simple terms.\", max_tokens=1000))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9991b334-09ad-466f-bfae-21920c35e1e3",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6695062c-054f-43ad-92c1-ef66d6ee4ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "from utils import llama4, llama4_together\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_id = \"meta-llama/Llama-4-Scout-17B-16E-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc99c94-5af1-445f-9ac6-092b067e4c8b",
   "metadata": {},
   "source": [
    "### Multiple document summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e21b9e1d-6d57-42bd-8e9c-61ae628eb999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing paper 1 - 長照專業服務操作指引-觀念篇_公告.pdf, 36408 characters\n",
      "\n",
      "Total papers processed: 1.0, 875\n"
     ]
    }
   ],
   "source": [
    "from utils import pdf2text\n",
    "\n",
    "papers = [\n",
    "\"長照專業服務操作指引-觀念篇_公告.pdf\",\n",
    "]\n",
    "#\"長照專業服務操作指引-操作篇-共通操作指引_公告.pdf\",\n",
    "#\"長照專業服務操作指引-操作篇-居家護理指導與諮詢操作指引_公告.pdf\"\n",
    "\n",
    "paper_texts = []\n",
    "for n, paper in enumerate(papers):\n",
    "    text = pdf2text(f\"data/pdfs/{paper}\")\n",
    "    paper_texts.append(f\"Processing paper {n+1} - {paper}, {len(text)} characters\\n\")\n",
    "    print(f\"Processing paper {n+1} - {paper}, {len(text)} characters\")\n",
    "\n",
    "    summary = chat_with_llm(f\"\"\"give me a summary of less than 140 words for the article below {text}\"\"\", \n",
    "                            max_tokens=600)\n",
    "    paper_texts.append(f\"{summary}\\n\\n\")\n",
    "\n",
    "total_text = \"\\n\\n\".join(paper_texts)\n",
    "print(f\"\\nTotal papers processed: {len(paper_texts)/2}, {len(total_text)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da964f55-425a-48e9-826b-9d327de051ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing paper 1 - 長照專業服務操作指引-觀念篇_公告.pdf, 36408 characters\n",
      "\n",
      "\n",
      "根據提供的文獻和內容，以下是促進跨專業合作以實現成功復能（Reablement）服務的具體措施：\n",
      "\n",
      "1. **教育培訓**：\n",
      "   - 進行專業服務相關之繼續教育課程，使個管人員對於復能概念與專業服務內涵有正確的理解。\n",
      "   - 提供新進個案管理員和個別化照顧管理員（A 個管）實地見習機會，讓他們與 B 單位的專業人員共同訪視個案，以了解專業服務的實際執行情況。\n",
      "   - 新進專業人員需通過考核後方予以聘用，確保其具備提供高品質專業服務的能力。\n",
      "\n",
      "2. **建立合作溝通機制**：\n",
      "   - 每個個案都有專屬記事本，有助於促進各專業與服務人員之間的溝通。\n",
      "   - 建立跨專業群組（如 Line 群組），使所有相關專業和人員能夠共同討論個案狀況、指導措施及表現等信息。\n",
      "   - 記事本中包含每次訪視的日期、個案問題、執行內容、指導措施等，並建議下次訪視時需注意的事項或提供建議。\n",
      "\n",
      "3. **聯合訪視**：\n",
      "   - 專業服務指導人員與居服員共同訪視個案，確保在每次家訪中都能提供適宜的練習機會。\n",
      "   - 透過跨專業合作模式（如圖6所示），追蹤和評估個案自選活動的訓練進展。\n",
      "\n",
      "4. **見習/實習制度**：\n",
      "   - 設立典範實習單位，使新單位能夠了解績優單位的運作模式。\n",
      "   - 新進專業人員需完成見習實習方案並通過考核，以確保其具備提供高品質專業服務的能力。\n",
      "\n",
      "5. **每日密集性訓練原則**：\n",
      "   - 確保居服員在每次訪視時都能針對個案自選活動提供適宜的練習機會，強調「每日密集性訓練」的重要性。\n",
      "   \n",
      "6. **影像和文件管理**：\n",
      "   - 需取得個案家屬同意並告知其照片或影片可觀看範圍，以確保個資安全。\n",
      "   - 將需要與團隊溝通的照片或影像上傳至專屬記事本，以追蹤訓練的正確性和進展。\n",
      "\n",
      "這些措施可以確保跨專業合作的成功進行，促進復能服務的有效執行，幫助老年人恢復和維持獨立生活的能力。\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(total_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a97df3-92d6-4482-bd86-e696574fb4ae",
   "metadata": {},
   "source": [
    "### Loop thru the whole directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "501e0d06-0867-4eef-937f-f4933e67ed5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 53 PDF files to process.\n",
      "\n",
      "Processing paper 1 - 2.獎勵布建住宿式長照機構資源計畫-114年度待獎勵區域(1140502).pdf, 3801 characters\n",
      "Processing paper 2 - 衛部顧字第1131962420號公告.pdf, 2 characters\n",
      "Processing paper 3 - 問答集1.pdf, 1293 characters\n",
      "Processing paper 4 - 長照專業服務操作指引-操作篇-共通操作指引_公告.pdf, 19399 characters\n",
      "Processing paper 5 - 問答集2.pdf, 938 characters\n",
      "Processing paper 6 - 照顧實務指導員訓練(公告).pdf, 1311 characters\n",
      "Processing paper 7 - 家庭照顧者支持服務據點專業人員工作手冊.pdf, 75805 characters\n",
      "Processing paper 8 - 院臺衛字第1131014413號.pdf, 695 characters\n",
      "Processing paper 9 - 問答集3.pdf, 557 characters\n",
      "Processing paper 10 - 112年居家失能個案家庭醫師照護方案(1120626).pdf, 13720 characters\n",
      "Processing paper 11 - 112年居家失能個案家庭醫師照護方案公告(1120626).pdf, 0 characters\n",
      "Processing paper 12 - 家庭照顧者支持服務原則(公告).pdf, 1804 characters\n",
      "Processing paper 13 - 附件1-申請流程圖（114.04.09修正版）.pdf, 906 characters\n",
      "Processing paper 14 - 各縣市失智症照顧及服務資訊.pdf, 1721 characters\n",
      "Processing paper 15 - 「住宿機構強化感染管制獎勵計畫」縣市計畫書格式.pdf, 2173 characters\n",
      "Processing paper 16 - 3.公告-獎勵布建住宿式長照機構資源計畫.pdf, 0 characters\n",
      "Processing paper 17 - 長照專業服務操作指引-附錄一-服務紀錄參考格式_公告.pdf, 4911 characters\n",
      "Processing paper 18 - 預立醫療照護諮商及預立醫療決定宣導單.pdf, 941 characters\n",
      "Processing paper 19 - 4.獎勵布建住宿式長照機構資源計畫申請作業需知(1131227修正公告).pdf, 11933 characters\n",
      "Processing paper 20 - 長期照顧整合課程(LevelⅢ).pdf, 628 characters\n",
      "Processing paper 21 - 「住宿機構強化感染管制獎勵計畫」成果報告格式.pdf, 872 characters\n",
      "Processing paper 22 - 住宿式長照機構之旱災、停水、水資源短缺緊急應變指引.pdf, 2052 characters\n",
      "Processing paper 23 - 1130628修訂本部「減少照護機構住民至醫療機構就醫方案」公告及計畫書.pdf, 9456 characters\n",
      "Processing paper 24 - 長期照顧專業課程(LevelⅡ)及整合課程(LevelⅢ)授課講師資格.pdf, 389 characters\n",
      "Processing paper 25 - 長照專業服務操作指引-附錄二-居家護理指導與諮詢服務的處置指引_公告.pdf, 64957 characters\n",
      "Processing paper 26 - 長照專業服務操作指引-附錄三-案例說明_公告.pdf, 64157 characters\n",
      "Processing paper 27 - 長照專業服務操作指引-觀念篇_公告.pdf, 36408 characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 12 0 (offset 0)\n",
      "Ignoring wrong pointing object 14 0 (offset 0)\n",
      "Ignoring wrong pointing object 16 0 (offset 0)\n",
      "Ignoring wrong pointing object 24 0 (offset 0)\n",
      "Ignoring wrong pointing object 26 0 (offset 0)\n",
      "Ignoring wrong pointing object 28 0 (offset 0)\n",
      "Ignoring wrong pointing object 43 0 (offset 0)\n",
      "Ignoring wrong pointing object 48 0 (offset 0)\n",
      "Ignoring wrong pointing object 54 0 (offset 0)\n",
      "Ignoring wrong pointing object 227 0 (offset 0)\n",
      "Ignoring wrong pointing object 232 0 (offset 0)\n",
      "Ignoring wrong pointing object 234 0 (offset 0)\n",
      "Ignoring wrong pointing object 236 0 (offset 0)\n",
      "Ignoring wrong pointing object 238 0 (offset 0)\n",
      "Ignoring wrong pointing object 240 0 (offset 0)\n",
      "Ignoring wrong pointing object 242 0 (offset 0)\n",
      "Ignoring wrong pointing object 257 0 (offset 0)\n",
      "Ignoring wrong pointing object 752 0 (offset 0)\n",
      "Ignoring wrong pointing object 754 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing paper 28 - 附件3-長照機構暨長照人員相關管理資訊系統_品質提升管理_介接規格書v4.5.pdf, 73705 characters\n",
      "Processing paper 29 - 失智共同照護中心及社區服務據點參考手冊.pdf, 26055 characters\n",
      "Processing paper 30 - 113至116年住宿機構照顧品質獎勵計畫(公告核定版).pdf, 21152 characters\n",
      "Processing paper 31 - 附件2-住宿機構照顧品質獎勵計畫說明會議 v1.4R（114.6.13更新）.pdf, 5459 characters\n",
      "Processing paper 32 - 住宿式機構與醫院合作服務合約參考範本.pdf, 1047 characters\n",
      "Processing paper 33 - 長照高負荷家庭照顧者轉介及服務流程.pdf, 1255 characters\n",
      "Processing paper 34 - 院臺衛字第1131020942號函PDF.pdf, 619 characters\n",
      "Processing paper 35 - 1.公告-獎勵布建住宿式長照機構資源計畫-114年度待獎勵區域.pdf, 6 characters\n",
      "Processing paper 36 - 附件4、住宿機構照顧品質獎勵計畫-懶人包.pdf, 326 characters\n",
      "Processing paper 37 - 住宿機構照顧品質獎勵計畫問答集(113年11月28日版).pdf, 21100 characters\n",
      "Processing paper 38 - 長照專業服務操作指引-操作篇-居家護理指導與諮詢操作指引_公告.pdf, 4301 characters\n",
      "Processing paper 39 - 「住宿式機構強化感染管制獎勵計畫」衛生福利部權責司署計畫審查內容及評分原則.pdf, 807 characters\n",
      "Processing paper 40 - 高負荷家庭照顧者初篩指標.pdf, 1345 characters\n",
      "Processing paper 41 - L2+L3課程及師資公告函.pdf, 1318 characters\n",
      "Processing paper 42 - 長照專業服務手冊1120109(公告修正).pdf, 32 characters\n",
      "Processing paper 43 - 住宿式機構照顧服務員進階培訓獎勵計畫(修訂公告).pdf, 5586 characters\n",
      "Processing paper 44 - 失智症共同照護中心清冊.pdf, 6751 characters\n",
      "Processing paper 45 - 「住宿機構強化感染管制獎勵計畫」指標評核佐證資料建議範本.pdf, 31905 characters\n",
      "Processing paper 46 - 住宿式長照機構清冊-簡版名單(114年4月底).pdf, 7733 characters\n",
      "Processing paper 47 - 衛部顧字第1131961750號公告.pdf, 2 characters\n",
      "Processing paper 48 - 長照專業服務手冊-修正說明表(公告).pdf, 23243 characters\n",
      "Processing paper 49 - 「住宿機構強化感染管制獎勵計畫」機構申請表.pdf, 807 characters\n",
      "Processing paper 50 - 長照2.0視覺識別系統手冊.pdf, 66 characters\n",
      "Processing paper 51 - 衛生福利部112-114年度「出院準備銜接長照服務計畫」申請作業須知.pdf, 20326 characters\n",
      "Processing paper 52 - 長期照顧專業課程(LevelⅡ).pdf, 44903 characters\n",
      "Processing paper 53 - 113至116年度「住宿機構強化感染管制獎勵計畫」.pdf, 14775 characters\n",
      "\n",
      "Total papers processed: 53.0, 50128\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from utils import pdf2text\n",
    "\n",
    "# Set the directory containing PDFs\n",
    "pdf_dir = \"data/pdfs\"\n",
    "\n",
    "# Automatically find all PDF files in the directory\n",
    "papers = [f for f in os.listdir(pdf_dir) if f.endswith(\".pdf\")]\n",
    "\n",
    "print(f\"Found {len(papers)} PDF files to process.\\n\")\n",
    "\n",
    "paper_texts = []\n",
    "for n, paper in enumerate(papers):\n",
    "    text = pdf2text(os.path.join(pdf_dir, paper))\n",
    "    paper_texts.append(f\"Processing paper {n+1} - {paper}, {len(text)} characters\\n\")\n",
    "    print(f\"Processing paper {n+1} - {paper}, {len(text)} characters\")\n",
    "\n",
    "    summary = chat_with_llm(f\"\"\"give me a summary of less than 110 words for the article below {text}\"\"\", \n",
    "                            max_tokens=500)\n",
    "    paper_texts.append(f\"{summary}\\n\\n\")\n",
    "\n",
    "total_text = \"\\n\\n\".join(paper_texts)\n",
    "print(f\"\\nTotal papers processed: {len(paper_texts)/2}, {len(total_text)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ee70fb0-5dc7-4c48-a553-1dd5e87d2cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content successfully written to './total_text.txt'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def write_long_text_to_file(filename: str, content: str):\n",
    "    \"\"\"\n",
    "    Writes a given text string to a local file, overwriting if it exists.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(content)\n",
    "        print(f\"Content successfully written to '{filename}'.\")\n",
    "    except IOError as e:\n",
    "        print(f\"Error writing to file '{filename}': {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "'''\n",
    "if __name__ == \"__main__\":\n",
    "    # Example Usage\n",
    "    text_content = \"\"\"\n",
    "    This is a concise example of text to be written to a file.\n",
    "    It demonstrates writing multiple lines efficiently.\n",
    "    \"\"\"\n",
    "    output_file = \"concise_text_file.txt\"\n",
    "    write_long_text_to_file(output_file, text_content)\n",
    "\n",
    "    # Optional: Verify content\n",
    "    try:\n",
    "        with open(output_file, 'r', encoding='utf-8') as f:\n",
    "            read_back = f.read()\n",
    "            print(f\"Read back (first 50 chars): '{read_back[:50]}...'\")\n",
    "            if read_back == text_content:\n",
    "                print(\"Verification: Content matches.\")\n",
    "            else:\n",
    "                print(\"Verification: Content mismatch.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{output_file}' not found for verification.\")\n",
    "'''\n",
    "write_long_text_to_file(f\"./total_text.txt\", total_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e281c196-3fcb-4370-a147-3b427bea3e15",
   "metadata": {},
   "source": [
    "### Article Summary Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24eec633-7d4f-4bcb-a4fc-89902d499901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🧠 Step 1: Setup\n",
    "import re\n",
    "import openai\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")  # Or paste your key here\n",
    "\n",
    "# Use OpenAI's cost-efficient model\n",
    "MODEL = \"gpt-4o-mini\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6c96930-7d60-406c-84c4-2cc7a10ac85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 53 articles.\n",
      "ℹ️ Median summary length: 530 characters\n",
      "📉 Articles shorter than 132 characters will be grouped as 'Short Summaries'\n",
      "📂 1 short articles identified.\n"
     ]
    }
   ],
   "source": [
    "# 📄 Step 2: Preprocess article summaries\n",
    "\n",
    "raw_text = total_text\n",
    "pattern = r\"(Processing paper \\d+ - .+?\\.pdf, \\d+ characters)\"\n",
    "splits = re.split(pattern, raw_text)[1:]\n",
    "\n",
    "articles = []\n",
    "for i in range(0, len(splits), 2):\n",
    "    header = splits[i].strip()\n",
    "    summary = splits[i + 1].strip()\n",
    "    articles.append((header, summary))\n",
    "\n",
    "print(f\"✅ Loaded {len(articles)} articles.\")\n",
    "\n",
    "# 🔎 Filter short summaries\n",
    "summary_lengths = [len(summary) for _, summary in articles]\n",
    "median_length = sorted(summary_lengths)[len(summary_lengths) // 2]\n",
    "short_threshold = 0.25 * median_length\n",
    "\n",
    "print(f\"ℹ️ Median summary length: {median_length} characters\")\n",
    "print(f\"📉 Articles shorter than {short_threshold:.0f} characters will be grouped as 'Short Summaries'\")\n",
    "\n",
    "short_articles = []\n",
    "normal_articles = []\n",
    "for pair in articles:\n",
    "    if len(pair[1]) < short_threshold:\n",
    "        short_articles.append(pair)\n",
    "    else:\n",
    "        normal_articles.append(pair)\n",
    "\n",
    "print(f\"📂 {len(short_articles)} short articles identified.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9bc1fb2-1b9b-40d0-b0f4-19b9bd8c756f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Processing paper 34 - 院臺衛字第1131020942號函PDF.pdf, 619 characters', '行政院函件同意衛生福利部所報「住宿機構照顧品質獎勵計畫」草案，並指示正本送衛福部，副本送內政部、國家發展委員會及行政院主計總處。發文日期為113年8月19日，發文字號為院臺衛字第1131020942號。')]\n"
     ]
    }
   ],
   "source": [
    "print(short_articles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b0ec93a-7800-485f-b59a-ea83e5433dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 LLM Classification Result:\n",
      "\n",
      "Group 1: [Long-Term Care Policies and Programs]\n",
      "Articles: [1, 3, 6, 12, 13, 35]\n",
      "\n",
      "Group 2: [Professional Training and Development]\n",
      "Articles: [4, 8, 20, 24, 40]\n",
      "\n",
      "Group 3: [Technology in Caregiving]\n",
      "Articles: [5, 17, 22, 25]\n",
      "\n",
      "Group 4: [Family Caregiver Support]\n",
      "Articles: [7, 12, 39, 51]\n",
      "\n",
      "Group 5: [Assessment and Evaluation in Long-Term Care]\n",
      "Articles: [10, 17, 33, 37]\n",
      "\n",
      "Group 6: [Health and Safety Regulations]\n",
      "Articles: [14, 18, 32, 38]\n",
      "\n",
      "Group 7: [Remote Work and Workplace Dynamics]\n",
      "Articles: [2, 41]\n",
      "\n",
      "Group 8: [Environmental and Agricultural Issues]\n",
      "Articles: [16, 34]\n"
     ]
    }
   ],
   "source": [
    "# 🤖 Step 3: Classify normal articles using GPT-4o-mini\n",
    "def classify_articles(normal_articles):\n",
    "    from openai import OpenAI\n",
    "    client = OpenAI()\n",
    "\n",
    "    preview_text = \"\\n\\n\".join(\n",
    "        [f\"{i+1}. {summary[:500]}\" for i, (_, summary) in enumerate(normal_articles)]\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a helpful assistant. I have article summaries and want to group them thematically.\n",
    "Please classify them into **no more than 8 groups** based on content, and give each group a one-sentence label.\n",
    "\n",
    "Only classify the summaries below. Ignore missing or overly short ones.\n",
    "\n",
    "Respond exactly in this format:\n",
    "Group 1: [Label]\n",
    "Articles: [list of numbers]\n",
    "Group 2: ...\n",
    "\n",
    "Here are the summaries:\n",
    "{preview_text}\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.2\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "grouping_response = classify_articles(normal_articles)\n",
    "print(\"🧠 LLM Classification Result:\\n\")\n",
    "print(grouping_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a25b368-182f-4c53-bfd2-bae5ed609908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Total 9 groups including short articles.\n"
     ]
    }
   ],
   "source": [
    "# 📊 Step 4: Parse grouping and merge short summary group\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "# 📊 Step 4: Parse LLM grouping output correctly with bracket support\n",
    "grouped_articles = defaultdict(list)\n",
    "\n",
    "# Match group blocks robustly\n",
    "group_blocks = re.findall(r\"(Group \\d+:\\s*\\[.*?\\].*?)(?=Group \\d+:|\\Z)\", grouping_response, re.DOTALL)\n",
    "\n",
    "for block in group_blocks:\n",
    "    # Extract label inside brackets: [Label]\n",
    "    label_match = re.search(r\"Group \\d+:\\s*\\[(.+?)\\]\", block)\n",
    "    label = label_match.group(1).strip() if label_match else \"Unnamed Group\"\n",
    "\n",
    "    # Extract numbers inside Articles: [1, 2, ...]\n",
    "    article_match = re.search(r\"Articles:\\s*\\[([^\\]]+)\\]\", block)\n",
    "    if article_match:\n",
    "        number_str = article_match.group(1)\n",
    "        indices = [int(n.strip()) - 1 for n in number_str.split(\",\") if n.strip().isdigit()]\n",
    "        for idx in indices:\n",
    "            if 0 <= idx < len(normal_articles):\n",
    "                grouped_articles[label].append(normal_articles[idx])\n",
    "\n",
    "# Add short summary group if any\n",
    "if short_articles:\n",
    "    grouped_articles[\"Short Summaries or Incomplete Articles\"] = short_articles\n",
    "\n",
    "print(f\"📦 Total {len(grouped_articles)} groups including short articles.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7088256c-3d3b-4334-a410-7ea085c02bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved all groups to folder: classified_articles\n"
     ]
    }
   ],
   "source": [
    "# 📝 Step 5: Write results to text files\n",
    "output_dir = \"classified_articles\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for label, items in grouped_articles.items():\n",
    "    filename = re.sub(r'[\\\\/:\"*?<>|]+', \"_\", label[:60]) + \".txt\"\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        for header, summary in items:\n",
    "            f.write(header + \"\\n\")\n",
    "            f.write(summary + \"\\n\\n\")\n",
    "\n",
    "print(f\"✅ Saved all groups to folder: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d583358-d9b9-4280-a8f4-2872b0bbc3e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ltc)",
   "language": "python",
   "name": "ltc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
