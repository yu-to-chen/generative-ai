{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d65762c7-085b-41e1-b35b-b9444ead0732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d014a695-4d14-4362-b5ac-f261111911fb",
   "metadata": {},
   "source": [
    "### CrewAI + Ollama + qwen2.5:14b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f29969b-8e60-4193-8ee9-d8b6deb4e337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Bellman equation is a key concept in decision-making processes, particularly in fields like economics, artificial intelligence, and operations research. It's used to solve complex problems by breaking them down into simpler sub-problems.\n",
      "\n",
      "Imagine you're playing a video game where at each level, you have choices that affect your score for that level and the options available in future levels. The Bellman equation helps you make decisions not just based on what gives you immediate rewards but also considers long-term benefits from those choices.\n",
      "\n",
      "In simple terms, it represents an optimal decision rule telling you how to act now given some information about what might happen later if you follow certain strategies or policies. It takes into account the current state (like your score and level in a game), possible actions you can take, immediate rewards for those actions, and potential future benefits.\n",
      "\n",
      "The equation looks like this: V(s) = max_a [R(s,a) + Î³ * âˆ‘_s' P(s'|s,a)V(s')]\n",
      "\n",
      "Where:\n",
      "- V(s) is the value of being in state s.\n",
      "- a represents an action you can take in that state.\n",
      "- R(s, a) is the reward for taking action a in state s.\n",
      "- Î³ (gamma) is a discount factor between 0 and 1 that determines how much we care about future rewards compared to immediate ones.\n",
      "- P(s'|s,a) is the probability of moving to the next state s' from current state s by taking action a.\n",
      "- V(s') is the value of being in the next state.\n",
      "\n",
      "So, this equation helps you make decisions considering both immediate and long-term consequences. It's widely used in reinforcement learning algorithms where agents learn to take actions that maximize rewards over time.\n"
     ]
    }
   ],
   "source": [
    "from crewai import Agent, Crew, Task\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "def chat_with_llm(prompt, model=\"ollama_chat/qwen2.5:14b\", base_url=\"http://localhost:11434\", max_tokens=8192):\n",
    "    llm = OllamaLLM(\n",
    "        model=model,\n",
    "        base_url=base_url,\n",
    "        temperature=0.7,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "\n",
    "    agent = Agent(\n",
    "        role=\"Helpful assistant\",\n",
    "        goal=\"Respond accurately to user prompts\",\n",
    "        backstory=\"You are a concise and knowledgeable assistant.\",\n",
    "        verbose=False,\n",
    "        llm=llm\n",
    "    )\n",
    "\n",
    "    task = Task(\n",
    "        description=prompt,\n",
    "        expected_output=\"A helpful and accurate response to the user's prompt.\",\n",
    "        agent=agent\n",
    "    )\n",
    "\n",
    "    crew = Crew(\n",
    "        agents=[agent],\n",
    "        tasks=[task],\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    return crew.kickoff()\n",
    "\n",
    "## Example usage\n",
    "#if __name__ == \"__main__\":\n",
    "#    reply = chat_with_llm(\"Explain the Bellman equation in simple terms.\")\n",
    "#    print(reply)\n",
    "\n",
    "print(chat_with_llm(\"Explain the Bellman equation in simple terms.\", max_tokens=1000))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9991b334-09ad-466f-bfae-21920c35e1e3",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6695062c-054f-43ad-92c1-ef66d6ee4ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "from utils import llama4, llama4_together\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_id = \"meta-llama/Llama-4-Scout-17B-16E-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc99c94-5af1-445f-9ac6-092b067e4c8b",
   "metadata": {},
   "source": [
    "### Multiple document summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e21b9e1d-6d57-42bd-8e9c-61ae628eb999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing paper 1 - é•·ç…§å°ˆæ¥­æœå‹™æ“ä½œæŒ‡å¼•-è§€å¿µç¯‡_å…¬å‘Š.pdf, 36408 characters\n",
      "\n",
      "Total papers processed: 1.0, 875\n"
     ]
    }
   ],
   "source": [
    "from utils import pdf2text\n",
    "\n",
    "papers = [\n",
    "\"é•·ç…§å°ˆæ¥­æœå‹™æ“ä½œæŒ‡å¼•-è§€å¿µç¯‡_å…¬å‘Š.pdf\",\n",
    "]\n",
    "#\"é•·ç…§å°ˆæ¥­æœå‹™æ“ä½œæŒ‡å¼•-æ“ä½œç¯‡-å…±é€šæ“ä½œæŒ‡å¼•_å…¬å‘Š.pdf\",\n",
    "#\"é•·ç…§å°ˆæ¥­æœå‹™æ“ä½œæŒ‡å¼•-æ“ä½œç¯‡-å±…å®¶è­·ç†æŒ‡å°èˆ‡è«®è©¢æ“ä½œæŒ‡å¼•_å…¬å‘Š.pdf\"\n",
    "\n",
    "paper_texts = []\n",
    "for n, paper in enumerate(papers):\n",
    "    text = pdf2text(f\"data/pdfs/{paper}\")\n",
    "    paper_texts.append(f\"Processing paper {n+1} - {paper}, {len(text)} characters\\n\")\n",
    "    print(f\"Processing paper {n+1} - {paper}, {len(text)} characters\")\n",
    "\n",
    "    summary = chat_with_llm(f\"\"\"give me a summary of less than 140 words for the article below {text}\"\"\", \n",
    "                            max_tokens=600)\n",
    "    paper_texts.append(f\"{summary}\\n\\n\")\n",
    "\n",
    "total_text = \"\\n\\n\".join(paper_texts)\n",
    "print(f\"\\nTotal papers processed: {len(paper_texts)/2}, {len(total_text)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da964f55-425a-48e9-826b-9d327de051ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing paper 1 - é•·ç…§å°ˆæ¥­æœå‹™æ“ä½œæŒ‡å¼•-è§€å¿µç¯‡_å…¬å‘Š.pdf, 36408 characters\n",
      "\n",
      "\n",
      "æ ¹æ“šæä¾›çš„æ–‡ç»å’Œå…§å®¹ï¼Œä»¥ä¸‹æ˜¯ä¿ƒé€²è·¨å°ˆæ¥­åˆä½œä»¥å¯¦ç¾æˆåŠŸå¾©èƒ½ï¼ˆReablementï¼‰æœå‹™çš„å…·é«”æªæ–½ï¼š\n",
      "\n",
      "1. **æ•™è‚²åŸ¹è¨“**ï¼š\n",
      "   - é€²è¡Œå°ˆæ¥­æœå‹™ç›¸é—œä¹‹ç¹¼çºŒæ•™è‚²èª²ç¨‹ï¼Œä½¿å€‹ç®¡äººå“¡å°æ–¼å¾©èƒ½æ¦‚å¿µèˆ‡å°ˆæ¥­æœå‹™å…§æ¶µæœ‰æ­£ç¢ºçš„ç†è§£ã€‚\n",
      "   - æä¾›æ–°é€²å€‹æ¡ˆç®¡ç†å“¡å’Œå€‹åˆ¥åŒ–ç…§é¡§ç®¡ç†å“¡ï¼ˆA å€‹ç®¡ï¼‰å¯¦åœ°è¦‹ç¿’æ©Ÿæœƒï¼Œè®“ä»–å€‘èˆ‡ B å–®ä½çš„å°ˆæ¥­äººå“¡å…±åŒè¨ªè¦–å€‹æ¡ˆï¼Œä»¥äº†è§£å°ˆæ¥­æœå‹™çš„å¯¦éš›åŸ·è¡Œæƒ…æ³ã€‚\n",
      "   - æ–°é€²å°ˆæ¥­äººå“¡éœ€é€šéè€ƒæ ¸å¾Œæ–¹äºˆä»¥è˜ç”¨ï¼Œç¢ºä¿å…¶å…·å‚™æä¾›é«˜å“è³ªå°ˆæ¥­æœå‹™çš„èƒ½åŠ›ã€‚\n",
      "\n",
      "2. **å»ºç«‹åˆä½œæºé€šæ©Ÿåˆ¶**ï¼š\n",
      "   - æ¯å€‹å€‹æ¡ˆéƒ½æœ‰å°ˆå±¬è¨˜äº‹æœ¬ï¼Œæœ‰åŠ©æ–¼ä¿ƒé€²å„å°ˆæ¥­èˆ‡æœå‹™äººå“¡ä¹‹é–“çš„æºé€šã€‚\n",
      "   - å»ºç«‹è·¨å°ˆæ¥­ç¾¤çµ„ï¼ˆå¦‚ Line ç¾¤çµ„ï¼‰ï¼Œä½¿æ‰€æœ‰ç›¸é—œå°ˆæ¥­å’Œäººå“¡èƒ½å¤ å…±åŒè¨è«–å€‹æ¡ˆç‹€æ³ã€æŒ‡å°æªæ–½åŠè¡¨ç¾ç­‰ä¿¡æ¯ã€‚\n",
      "   - è¨˜äº‹æœ¬ä¸­åŒ…å«æ¯æ¬¡è¨ªè¦–çš„æ—¥æœŸã€å€‹æ¡ˆå•é¡Œã€åŸ·è¡Œå…§å®¹ã€æŒ‡å°æªæ–½ç­‰ï¼Œä¸¦å»ºè­°ä¸‹æ¬¡è¨ªè¦–æ™‚éœ€æ³¨æ„çš„äº‹é …æˆ–æä¾›å»ºè­°ã€‚\n",
      "\n",
      "3. **è¯åˆè¨ªè¦–**ï¼š\n",
      "   - å°ˆæ¥­æœå‹™æŒ‡å°äººå“¡èˆ‡å±…æœå“¡å…±åŒè¨ªè¦–å€‹æ¡ˆï¼Œç¢ºä¿åœ¨æ¯æ¬¡å®¶è¨ªä¸­éƒ½èƒ½æä¾›é©å®œçš„ç·´ç¿’æ©Ÿæœƒã€‚\n",
      "   - é€éè·¨å°ˆæ¥­åˆä½œæ¨¡å¼ï¼ˆå¦‚åœ–6æ‰€ç¤ºï¼‰ï¼Œè¿½è¹¤å’Œè©•ä¼°å€‹æ¡ˆè‡ªé¸æ´»å‹•çš„è¨“ç·´é€²å±•ã€‚\n",
      "\n",
      "4. **è¦‹ç¿’/å¯¦ç¿’åˆ¶åº¦**ï¼š\n",
      "   - è¨­ç«‹å…¸ç¯„å¯¦ç¿’å–®ä½ï¼Œä½¿æ–°å–®ä½èƒ½å¤ äº†è§£ç¸¾å„ªå–®ä½çš„é‹ä½œæ¨¡å¼ã€‚\n",
      "   - æ–°é€²å°ˆæ¥­äººå“¡éœ€å®Œæˆè¦‹ç¿’å¯¦ç¿’æ–¹æ¡ˆä¸¦é€šéè€ƒæ ¸ï¼Œä»¥ç¢ºä¿å…¶å…·å‚™æä¾›é«˜å“è³ªå°ˆæ¥­æœå‹™çš„èƒ½åŠ›ã€‚\n",
      "\n",
      "5. **æ¯æ—¥å¯†é›†æ€§è¨“ç·´åŸå‰‡**ï¼š\n",
      "   - ç¢ºä¿å±…æœå“¡åœ¨æ¯æ¬¡è¨ªè¦–æ™‚éƒ½èƒ½é‡å°å€‹æ¡ˆè‡ªé¸æ´»å‹•æä¾›é©å®œçš„ç·´ç¿’æ©Ÿæœƒï¼Œå¼·èª¿ã€Œæ¯æ—¥å¯†é›†æ€§è¨“ç·´ã€çš„é‡è¦æ€§ã€‚\n",
      "   \n",
      "6. **å½±åƒå’Œæ–‡ä»¶ç®¡ç†**ï¼š\n",
      "   - éœ€å–å¾—å€‹æ¡ˆå®¶å±¬åŒæ„ä¸¦å‘ŠçŸ¥å…¶ç…§ç‰‡æˆ–å½±ç‰‡å¯è§€çœ‹ç¯„åœï¼Œä»¥ç¢ºä¿å€‹è³‡å®‰å…¨ã€‚\n",
      "   - å°‡éœ€è¦èˆ‡åœ˜éšŠæºé€šçš„ç…§ç‰‡æˆ–å½±åƒä¸Šå‚³è‡³å°ˆå±¬è¨˜äº‹æœ¬ï¼Œä»¥è¿½è¹¤è¨“ç·´çš„æ­£ç¢ºæ€§å’Œé€²å±•ã€‚\n",
      "\n",
      "é€™äº›æªæ–½å¯ä»¥ç¢ºä¿è·¨å°ˆæ¥­åˆä½œçš„æˆåŠŸé€²è¡Œï¼Œä¿ƒé€²å¾©èƒ½æœå‹™çš„æœ‰æ•ˆåŸ·è¡Œï¼Œå¹«åŠ©è€å¹´äººæ¢å¾©å’Œç¶­æŒç¨ç«‹ç”Ÿæ´»çš„èƒ½åŠ›ã€‚\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(total_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a97df3-92d6-4482-bd86-e696574fb4ae",
   "metadata": {},
   "source": [
    "### Loop thru the whole directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "501e0d06-0867-4eef-937f-f4933e67ed5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 53 PDF files to process.\n",
      "\n",
      "Processing paper 1 - 2.çå‹µå¸ƒå»ºä½å®¿å¼é•·ç…§æ©Ÿæ§‹è³‡æºè¨ˆç•«-114å¹´åº¦å¾…çå‹µå€åŸŸ(1140502).pdf, 3801 characters\n",
      "Processing paper 2 - è¡›éƒ¨é¡§å­—ç¬¬1131962420è™Ÿå…¬å‘Š.pdf, 2 characters\n",
      "Processing paper 3 - å•ç­”é›†1.pdf, 1293 characters\n",
      "Processing paper 4 - é•·ç…§å°ˆæ¥­æœå‹™æ“ä½œæŒ‡å¼•-æ“ä½œç¯‡-å…±é€šæ“ä½œæŒ‡å¼•_å…¬å‘Š.pdf, 19399 characters\n",
      "Processing paper 5 - å•ç­”é›†2.pdf, 938 characters\n",
      "Processing paper 6 - ç…§é¡§å¯¦å‹™æŒ‡å°å“¡è¨“ç·´(å…¬å‘Š).pdf, 1311 characters\n",
      "Processing paper 7 - å®¶åº­ç…§é¡§è€…æ”¯æŒæœå‹™æ“šé»å°ˆæ¥­äººå“¡å·¥ä½œæ‰‹å†Š.pdf, 75805 characters\n",
      "Processing paper 8 - é™¢è‡ºè¡›å­—ç¬¬1131014413è™Ÿ.pdf, 695 characters\n",
      "Processing paper 9 - å•ç­”é›†3.pdf, 557 characters\n",
      "Processing paper 10 - 112å¹´å±…å®¶å¤±èƒ½å€‹æ¡ˆå®¶åº­é†«å¸«ç…§è­·æ–¹æ¡ˆ(1120626).pdf, 13720 characters\n",
      "Processing paper 11 - 112å¹´å±…å®¶å¤±èƒ½å€‹æ¡ˆå®¶åº­é†«å¸«ç…§è­·æ–¹æ¡ˆå…¬å‘Š(1120626).pdf, 0 characters\n",
      "Processing paper 12 - å®¶åº­ç…§é¡§è€…æ”¯æŒæœå‹™åŸå‰‡(å…¬å‘Š).pdf, 1804 characters\n",
      "Processing paper 13 - é™„ä»¶1-ç”³è«‹æµç¨‹åœ–ï¼ˆ114.04.09ä¿®æ­£ç‰ˆï¼‰.pdf, 906 characters\n",
      "Processing paper 14 - å„ç¸£å¸‚å¤±æ™ºç—‡ç…§é¡§åŠæœå‹™è³‡è¨Š.pdf, 1721 characters\n",
      "Processing paper 15 - ã€Œä½å®¿æ©Ÿæ§‹å¼·åŒ–æ„ŸæŸ“ç®¡åˆ¶çå‹µè¨ˆç•«ã€ç¸£å¸‚è¨ˆç•«æ›¸æ ¼å¼.pdf, 2173 characters\n",
      "Processing paper 16 - 3.å…¬å‘Š-çå‹µå¸ƒå»ºä½å®¿å¼é•·ç…§æ©Ÿæ§‹è³‡æºè¨ˆç•«.pdf, 0 characters\n",
      "Processing paper 17 - é•·ç…§å°ˆæ¥­æœå‹™æ“ä½œæŒ‡å¼•-é™„éŒ„ä¸€-æœå‹™ç´€éŒ„åƒè€ƒæ ¼å¼_å…¬å‘Š.pdf, 4911 characters\n",
      "Processing paper 18 - é ç«‹é†«ç™‚ç…§è­·è«®å•†åŠé ç«‹é†«ç™‚æ±ºå®šå®£å°å–®.pdf, 941 characters\n",
      "Processing paper 19 - 4.çå‹µå¸ƒå»ºä½å®¿å¼é•·ç…§æ©Ÿæ§‹è³‡æºè¨ˆç•«ç”³è«‹ä½œæ¥­éœ€çŸ¥(1131227ä¿®æ­£å…¬å‘Š).pdf, 11933 characters\n",
      "Processing paper 20 - é•·æœŸç…§é¡§æ•´åˆèª²ç¨‹(Levelâ…¢).pdf, 628 characters\n",
      "Processing paper 21 - ã€Œä½å®¿æ©Ÿæ§‹å¼·åŒ–æ„ŸæŸ“ç®¡åˆ¶çå‹µè¨ˆç•«ã€æˆæœå ±å‘Šæ ¼å¼.pdf, 872 characters\n",
      "Processing paper 22 - ä½å®¿å¼é•·ç…§æ©Ÿæ§‹ä¹‹æ—±ç½ã€åœæ°´ã€æ°´è³‡æºçŸ­ç¼ºç·Šæ€¥æ‡‰è®ŠæŒ‡å¼•.pdf, 2052 characters\n",
      "Processing paper 23 - 1130628ä¿®è¨‚æœ¬éƒ¨ã€Œæ¸›å°‘ç…§è­·æ©Ÿæ§‹ä½æ°‘è‡³é†«ç™‚æ©Ÿæ§‹å°±é†«æ–¹æ¡ˆã€å…¬å‘ŠåŠè¨ˆç•«æ›¸.pdf, 9456 characters\n",
      "Processing paper 24 - é•·æœŸç…§é¡§å°ˆæ¥­èª²ç¨‹(Levelâ…¡)åŠæ•´åˆèª²ç¨‹(Levelâ…¢)æˆèª²è¬›å¸«è³‡æ ¼.pdf, 389 characters\n",
      "Processing paper 25 - é•·ç…§å°ˆæ¥­æœå‹™æ“ä½œæŒ‡å¼•-é™„éŒ„äºŒ-å±…å®¶è­·ç†æŒ‡å°èˆ‡è«®è©¢æœå‹™çš„è™•ç½®æŒ‡å¼•_å…¬å‘Š.pdf, 64957 characters\n",
      "Processing paper 26 - é•·ç…§å°ˆæ¥­æœå‹™æ“ä½œæŒ‡å¼•-é™„éŒ„ä¸‰-æ¡ˆä¾‹èªªæ˜_å…¬å‘Š.pdf, 64157 characters\n",
      "Processing paper 27 - é•·ç…§å°ˆæ¥­æœå‹™æ“ä½œæŒ‡å¼•-è§€å¿µç¯‡_å…¬å‘Š.pdf, 36408 characters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 12 0 (offset 0)\n",
      "Ignoring wrong pointing object 14 0 (offset 0)\n",
      "Ignoring wrong pointing object 16 0 (offset 0)\n",
      "Ignoring wrong pointing object 24 0 (offset 0)\n",
      "Ignoring wrong pointing object 26 0 (offset 0)\n",
      "Ignoring wrong pointing object 28 0 (offset 0)\n",
      "Ignoring wrong pointing object 43 0 (offset 0)\n",
      "Ignoring wrong pointing object 48 0 (offset 0)\n",
      "Ignoring wrong pointing object 54 0 (offset 0)\n",
      "Ignoring wrong pointing object 227 0 (offset 0)\n",
      "Ignoring wrong pointing object 232 0 (offset 0)\n",
      "Ignoring wrong pointing object 234 0 (offset 0)\n",
      "Ignoring wrong pointing object 236 0 (offset 0)\n",
      "Ignoring wrong pointing object 238 0 (offset 0)\n",
      "Ignoring wrong pointing object 240 0 (offset 0)\n",
      "Ignoring wrong pointing object 242 0 (offset 0)\n",
      "Ignoring wrong pointing object 257 0 (offset 0)\n",
      "Ignoring wrong pointing object 752 0 (offset 0)\n",
      "Ignoring wrong pointing object 754 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing paper 28 - é™„ä»¶3-é•·ç…§æ©Ÿæ§‹æš¨é•·ç…§äººå“¡ç›¸é—œç®¡ç†è³‡è¨Šç³»çµ±_å“è³ªæå‡ç®¡ç†_ä»‹æ¥è¦æ ¼æ›¸v4.5.pdf, 73705 characters\n",
      "Processing paper 29 - å¤±æ™ºå…±åŒç…§è­·ä¸­å¿ƒåŠç¤¾å€æœå‹™æ“šé»åƒè€ƒæ‰‹å†Š.pdf, 26055 characters\n",
      "Processing paper 30 - 113è‡³116å¹´ä½å®¿æ©Ÿæ§‹ç…§é¡§å“è³ªçå‹µè¨ˆç•«(å…¬å‘Šæ ¸å®šç‰ˆ).pdf, 21152 characters\n",
      "Processing paper 31 - é™„ä»¶2-ä½å®¿æ©Ÿæ§‹ç…§é¡§å“è³ªçå‹µè¨ˆç•«èªªæ˜æœƒè­° v1.4Rï¼ˆ114.6.13æ›´æ–°ï¼‰.pdf, 5459 characters\n",
      "Processing paper 32 - ä½å®¿å¼æ©Ÿæ§‹èˆ‡é†«é™¢åˆä½œæœå‹™åˆç´„åƒè€ƒç¯„æœ¬.pdf, 1047 characters\n",
      "Processing paper 33 - é•·ç…§é«˜è² è·å®¶åº­ç…§é¡§è€…è½‰ä»‹åŠæœå‹™æµç¨‹.pdf, 1255 characters\n",
      "Processing paper 34 - é™¢è‡ºè¡›å­—ç¬¬1131020942è™Ÿå‡½PDF.pdf, 619 characters\n",
      "Processing paper 35 - 1.å…¬å‘Š-çå‹µå¸ƒå»ºä½å®¿å¼é•·ç…§æ©Ÿæ§‹è³‡æºè¨ˆç•«-114å¹´åº¦å¾…çå‹µå€åŸŸ.pdf, 6 characters\n",
      "Processing paper 36 - é™„ä»¶4ã€ä½å®¿æ©Ÿæ§‹ç…§é¡§å“è³ªçå‹µè¨ˆç•«-æ‡¶äººåŒ….pdf, 326 characters\n",
      "Processing paper 37 - ä½å®¿æ©Ÿæ§‹ç…§é¡§å“è³ªçå‹µè¨ˆç•«å•ç­”é›†(113å¹´11æœˆ28æ—¥ç‰ˆ).pdf, 21100 characters\n",
      "Processing paper 38 - é•·ç…§å°ˆæ¥­æœå‹™æ“ä½œæŒ‡å¼•-æ“ä½œç¯‡-å±…å®¶è­·ç†æŒ‡å°èˆ‡è«®è©¢æ“ä½œæŒ‡å¼•_å…¬å‘Š.pdf, 4301 characters\n",
      "Processing paper 39 - ã€Œä½å®¿å¼æ©Ÿæ§‹å¼·åŒ–æ„ŸæŸ“ç®¡åˆ¶çå‹µè¨ˆç•«ã€è¡›ç”Ÿç¦åˆ©éƒ¨æ¬Šè²¬å¸ç½²è¨ˆç•«å¯©æŸ¥å…§å®¹åŠè©•åˆ†åŸå‰‡.pdf, 807 characters\n",
      "Processing paper 40 - é«˜è² è·å®¶åº­ç…§é¡§è€…åˆç¯©æŒ‡æ¨™.pdf, 1345 characters\n",
      "Processing paper 41 - L2+L3èª²ç¨‹åŠå¸«è³‡å…¬å‘Šå‡½.pdf, 1318 characters\n",
      "Processing paper 42 - é•·ç…§å°ˆæ¥­æœå‹™æ‰‹å†Š1120109(å…¬å‘Šä¿®æ­£).pdf, 32 characters\n",
      "Processing paper 43 - ä½å®¿å¼æ©Ÿæ§‹ç…§é¡§æœå‹™å“¡é€²éšåŸ¹è¨“çå‹µè¨ˆç•«(ä¿®è¨‚å…¬å‘Š).pdf, 5586 characters\n",
      "Processing paper 44 - å¤±æ™ºç—‡å…±åŒç…§è­·ä¸­å¿ƒæ¸…å†Š.pdf, 6751 characters\n",
      "Processing paper 45 - ã€Œä½å®¿æ©Ÿæ§‹å¼·åŒ–æ„ŸæŸ“ç®¡åˆ¶çå‹µè¨ˆç•«ã€æŒ‡æ¨™è©•æ ¸ä½è­‰è³‡æ–™å»ºè­°ç¯„æœ¬.pdf, 31905 characters\n",
      "Processing paper 46 - ä½å®¿å¼é•·ç…§æ©Ÿæ§‹æ¸…å†Š-ç°¡ç‰ˆåå–®(114å¹´4æœˆåº•).pdf, 7733 characters\n",
      "Processing paper 47 - è¡›éƒ¨é¡§å­—ç¬¬1131961750è™Ÿå…¬å‘Š.pdf, 2 characters\n",
      "Processing paper 48 - é•·ç…§å°ˆæ¥­æœå‹™æ‰‹å†Š-ä¿®æ­£èªªæ˜è¡¨(å…¬å‘Š).pdf, 23243 characters\n",
      "Processing paper 49 - ã€Œä½å®¿æ©Ÿæ§‹å¼·åŒ–æ„ŸæŸ“ç®¡åˆ¶çå‹µè¨ˆç•«ã€æ©Ÿæ§‹ç”³è«‹è¡¨.pdf, 807 characters\n",
      "Processing paper 50 - é•·ç…§2.0è¦–è¦ºè­˜åˆ¥ç³»çµ±æ‰‹å†Š.pdf, 66 characters\n",
      "Processing paper 51 - è¡›ç”Ÿç¦åˆ©éƒ¨112-114å¹´åº¦ã€Œå‡ºé™¢æº–å‚™éŠœæ¥é•·ç…§æœå‹™è¨ˆç•«ã€ç”³è«‹ä½œæ¥­é ˆçŸ¥.pdf, 20326 characters\n",
      "Processing paper 52 - é•·æœŸç…§é¡§å°ˆæ¥­èª²ç¨‹(Levelâ…¡).pdf, 44903 characters\n",
      "Processing paper 53 - 113è‡³116å¹´åº¦ã€Œä½å®¿æ©Ÿæ§‹å¼·åŒ–æ„ŸæŸ“ç®¡åˆ¶çå‹µè¨ˆç•«ã€.pdf, 14775 characters\n",
      "\n",
      "Total papers processed: 53.0, 50128\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from utils import pdf2text\n",
    "\n",
    "# Set the directory containing PDFs\n",
    "pdf_dir = \"data/pdfs\"\n",
    "\n",
    "# Automatically find all PDF files in the directory\n",
    "papers = [f for f in os.listdir(pdf_dir) if f.endswith(\".pdf\")]\n",
    "\n",
    "print(f\"Found {len(papers)} PDF files to process.\\n\")\n",
    "\n",
    "paper_texts = []\n",
    "for n, paper in enumerate(papers):\n",
    "    text = pdf2text(os.path.join(pdf_dir, paper))\n",
    "    paper_texts.append(f\"Processing paper {n+1} - {paper}, {len(text)} characters\\n\")\n",
    "    print(f\"Processing paper {n+1} - {paper}, {len(text)} characters\")\n",
    "\n",
    "    summary = chat_with_llm(f\"\"\"give me a summary of less than 110 words for the article below {text}\"\"\", \n",
    "                            max_tokens=500)\n",
    "    paper_texts.append(f\"{summary}\\n\\n\")\n",
    "\n",
    "total_text = \"\\n\\n\".join(paper_texts)\n",
    "print(f\"\\nTotal papers processed: {len(paper_texts)/2}, {len(total_text)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ee70fb0-5dc7-4c48-a553-1dd5e87d2cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content successfully written to './total_text.txt'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def write_long_text_to_file(filename: str, content: str):\n",
    "    \"\"\"\n",
    "    Writes a given text string to a local file, overwriting if it exists.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(content)\n",
    "        print(f\"Content successfully written to '{filename}'.\")\n",
    "    except IOError as e:\n",
    "        print(f\"Error writing to file '{filename}': {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "'''\n",
    "if __name__ == \"__main__\":\n",
    "    # Example Usage\n",
    "    text_content = \"\"\"\n",
    "    This is a concise example of text to be written to a file.\n",
    "    It demonstrates writing multiple lines efficiently.\n",
    "    \"\"\"\n",
    "    output_file = \"concise_text_file.txt\"\n",
    "    write_long_text_to_file(output_file, text_content)\n",
    "\n",
    "    # Optional: Verify content\n",
    "    try:\n",
    "        with open(output_file, 'r', encoding='utf-8') as f:\n",
    "            read_back = f.read()\n",
    "            print(f\"Read back (first 50 chars): '{read_back[:50]}...'\")\n",
    "            if read_back == text_content:\n",
    "                print(\"Verification: Content matches.\")\n",
    "            else:\n",
    "                print(\"Verification: Content mismatch.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{output_file}' not found for verification.\")\n",
    "'''\n",
    "write_long_text_to_file(f\"./total_text.txt\", total_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e281c196-3fcb-4370-a147-3b427bea3e15",
   "metadata": {},
   "source": [
    "### Article Summary Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24eec633-7d4f-4bcb-a4fc-89902d499901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§  Step 1: Setup\n",
    "import re\n",
    "import openai\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")  # Or paste your key here\n",
    "\n",
    "# Use OpenAI's cost-efficient model\n",
    "MODEL = \"gpt-4o-mini\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6c96930-7d60-406c-84c4-2cc7a10ac85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 53 articles.\n",
      "â„¹ï¸ Median summary length: 530 characters\n",
      "ğŸ“‰ Articles shorter than 132 characters will be grouped as 'Short Summaries'\n",
      "ğŸ“‚ 1 short articles identified.\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“„ Step 2: Preprocess article summaries\n",
    "\n",
    "raw_text = total_text\n",
    "pattern = r\"(Processing paper \\d+ - .+?\\.pdf, \\d+ characters)\"\n",
    "splits = re.split(pattern, raw_text)[1:]\n",
    "\n",
    "articles = []\n",
    "for i in range(0, len(splits), 2):\n",
    "    header = splits[i].strip()\n",
    "    summary = splits[i + 1].strip()\n",
    "    articles.append((header, summary))\n",
    "\n",
    "print(f\"âœ… Loaded {len(articles)} articles.\")\n",
    "\n",
    "# ğŸ” Filter short summaries\n",
    "summary_lengths = [len(summary) for _, summary in articles]\n",
    "median_length = sorted(summary_lengths)[len(summary_lengths) // 2]\n",
    "short_threshold = 0.25 * median_length\n",
    "\n",
    "print(f\"â„¹ï¸ Median summary length: {median_length} characters\")\n",
    "print(f\"ğŸ“‰ Articles shorter than {short_threshold:.0f} characters will be grouped as 'Short Summaries'\")\n",
    "\n",
    "short_articles = []\n",
    "normal_articles = []\n",
    "for pair in articles:\n",
    "    if len(pair[1]) < short_threshold:\n",
    "        short_articles.append(pair)\n",
    "    else:\n",
    "        normal_articles.append(pair)\n",
    "\n",
    "print(f\"ğŸ“‚ {len(short_articles)} short articles identified.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9bc1fb2-1b9b-40d0-b0f4-19b9bd8c756f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Processing paper 34 - é™¢è‡ºè¡›å­—ç¬¬1131020942è™Ÿå‡½PDF.pdf, 619 characters', 'è¡Œæ”¿é™¢å‡½ä»¶åŒæ„è¡›ç”Ÿç¦åˆ©éƒ¨æ‰€å ±ã€Œä½å®¿æ©Ÿæ§‹ç…§é¡§å“è³ªçå‹µè¨ˆç•«ã€è‰æ¡ˆï¼Œä¸¦æŒ‡ç¤ºæ­£æœ¬é€è¡›ç¦éƒ¨ï¼Œå‰¯æœ¬é€å…§æ”¿éƒ¨ã€åœ‹å®¶ç™¼å±•å§”å“¡æœƒåŠè¡Œæ”¿é™¢ä¸»è¨ˆç¸½è™•ã€‚ç™¼æ–‡æ—¥æœŸç‚º113å¹´8æœˆ19æ—¥ï¼Œç™¼æ–‡å­—è™Ÿç‚ºé™¢è‡ºè¡›å­—ç¬¬1131020942è™Ÿã€‚')]\n"
     ]
    }
   ],
   "source": [
    "print(short_articles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b0ec93a-7800-485f-b59a-ea83e5433dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§  LLM Classification Result:\n",
      "\n",
      "Group 1: [Long-Term Care Policies and Programs]\n",
      "Articles: [1, 3, 6, 12, 13, 35]\n",
      "\n",
      "Group 2: [Professional Training and Development]\n",
      "Articles: [4, 8, 20, 24, 40]\n",
      "\n",
      "Group 3: [Technology in Caregiving]\n",
      "Articles: [5, 17, 22, 25]\n",
      "\n",
      "Group 4: [Family Caregiver Support]\n",
      "Articles: [7, 12, 39, 51]\n",
      "\n",
      "Group 5: [Assessment and Evaluation in Long-Term Care]\n",
      "Articles: [10, 17, 33, 37]\n",
      "\n",
      "Group 6: [Health and Safety Regulations]\n",
      "Articles: [14, 18, 32, 38]\n",
      "\n",
      "Group 7: [Remote Work and Workplace Dynamics]\n",
      "Articles: [2, 41]\n",
      "\n",
      "Group 8: [Environmental and Agricultural Issues]\n",
      "Articles: [16, 34]\n"
     ]
    }
   ],
   "source": [
    "# ğŸ¤– Step 3: Classify normal articles using GPT-4o-mini\n",
    "def classify_articles(normal_articles):\n",
    "    from openai import OpenAI\n",
    "    client = OpenAI()\n",
    "\n",
    "    preview_text = \"\\n\\n\".join(\n",
    "        [f\"{i+1}. {summary[:500]}\" for i, (_, summary) in enumerate(normal_articles)]\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a helpful assistant. I have article summaries and want to group them thematically.\n",
    "Please classify them into **no more than 8 groups** based on content, and give each group a one-sentence label.\n",
    "\n",
    "Only classify the summaries below. Ignore missing or overly short ones.\n",
    "\n",
    "Respond exactly in this format:\n",
    "Group 1: [Label]\n",
    "Articles: [list of numbers]\n",
    "Group 2: ...\n",
    "\n",
    "Here are the summaries:\n",
    "{preview_text}\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.2\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "grouping_response = classify_articles(normal_articles)\n",
    "print(\"ğŸ§  LLM Classification Result:\\n\")\n",
    "print(grouping_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a25b368-182f-4c53-bfd2-bae5ed609908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ Total 9 groups including short articles.\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“Š Step 4: Parse grouping and merge short summary group\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "# ğŸ“Š Step 4: Parse LLM grouping output correctly with bracket support\n",
    "grouped_articles = defaultdict(list)\n",
    "\n",
    "# Match group blocks robustly\n",
    "group_blocks = re.findall(r\"(Group \\d+:\\s*\\[.*?\\].*?)(?=Group \\d+:|\\Z)\", grouping_response, re.DOTALL)\n",
    "\n",
    "for block in group_blocks:\n",
    "    # Extract label inside brackets: [Label]\n",
    "    label_match = re.search(r\"Group \\d+:\\s*\\[(.+?)\\]\", block)\n",
    "    label = label_match.group(1).strip() if label_match else \"Unnamed Group\"\n",
    "\n",
    "    # Extract numbers inside Articles: [1, 2, ...]\n",
    "    article_match = re.search(r\"Articles:\\s*\\[([^\\]]+)\\]\", block)\n",
    "    if article_match:\n",
    "        number_str = article_match.group(1)\n",
    "        indices = [int(n.strip()) - 1 for n in number_str.split(\",\") if n.strip().isdigit()]\n",
    "        for idx in indices:\n",
    "            if 0 <= idx < len(normal_articles):\n",
    "                grouped_articles[label].append(normal_articles[idx])\n",
    "\n",
    "# Add short summary group if any\n",
    "if short_articles:\n",
    "    grouped_articles[\"Short Summaries or Incomplete Articles\"] = short_articles\n",
    "\n",
    "print(f\"ğŸ“¦ Total {len(grouped_articles)} groups including short articles.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7088256c-3d3b-4334-a410-7ea085c02bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved all groups to folder: classified_articles\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“ Step 5: Write results to text files\n",
    "output_dir = \"classified_articles\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for label, items in grouped_articles.items():\n",
    "    filename = re.sub(r'[\\\\/:\"*?<>|]+', \"_\", label[:60]) + \".txt\"\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        for header, summary in items:\n",
    "            f.write(header + \"\\n\")\n",
    "            f.write(summary + \"\\n\\n\")\n",
    "\n",
    "print(f\"âœ… Saved all groups to folder: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d583358-d9b9-4280-a8f4-2872b0bbc3e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ltc)",
   "language": "python",
   "name": "ltc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
