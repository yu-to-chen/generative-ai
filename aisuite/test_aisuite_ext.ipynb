{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c5db75d8-8fb3-4d93-a389-bb56c4205476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (1.57.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from openai) (0.8.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.8)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/opt/certifi/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/bin/python -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: aisuite[all] in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (0.1.6)\n",
      "Requirement already satisfied: anthropic<0.31.0,>=0.30.1 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from aisuite[all]) (0.30.1)\n",
      "Requirement already satisfied: groq<0.10.0,>=0.9.0 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from aisuite[all]) (0.9.0)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.35.8 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from aisuite[all]) (1.57.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from anthropic<0.31.0,>=0.30.1->aisuite[all]) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from anthropic<0.31.0,>=0.30.1->aisuite[all]) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from anthropic<0.31.0,>=0.30.1->aisuite[all]) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from anthropic<0.31.0,>=0.30.1->aisuite[all]) (0.8.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from anthropic<0.31.0,>=0.30.1->aisuite[all]) (2.9.2)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from anthropic<0.31.0,>=0.30.1->aisuite[all]) (1.3.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.0 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from anthropic<0.31.0,>=0.30.1->aisuite[all]) (0.20.3)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from anthropic<0.31.0,>=0.30.1->aisuite[all]) (4.12.2)\n",
      "Requirement already satisfied: tqdm>4 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from openai<2.0.0,>=1.35.8->aisuite[all]) (4.66.5)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from anyio<5,>=3.5.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (3.8)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/opt/certifi/lib/python3.12/site-packages (from httpx<1,>=0.23.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from httpx<1,>=0.23.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (2.23.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from tokenizers>=0.13.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (0.25.2)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/lib/python3.12/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (2.2.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/opt/homebrew/Cellar/jupyterlab/4.2.5_1/libexec/bin/python -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install openai\n",
    "!{sys.executable} -m pip install \"aisuite[all]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3e2d1427-f592-4d81-b019-3474747ec9aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv  \n",
    "import numpy as np\n",
    "import os\n",
    "from pprint import pprint as pp\n",
    "\n",
    "# Load variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f652bfdf-f514-4796-80e9-4f2913391826",
   "metadata": {},
   "source": [
    "# OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39cc565b-0912-43b3-a75c-89c0858cde5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0edce44b-0168-4070-ae84-9475dee1f163",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aisuite as ai\n",
    "client = ai.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68bdea77-a513-4c70-b293-f2eec9cc499d",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Talk using Pirate English.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell a joke in 1 line.\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd6c8568-1c99-4876-89cb-adbc14142e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why couldn't the pirate play cards? Because he was standing on the deck! Arrr!\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(model=\"openai:gpt-3.5-turbo\", messages=messages, \n",
    "                                          temperature=0.75)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83ba360-f472-4a5b-9d03-be6ed106241f",
   "metadata": {},
   "source": [
    "# Anthropic\n",
    "- Need to set up billing plan, skip for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6d747e5-3a36-496c-ad14-a60a15600214",
   "metadata": {},
   "outputs": [],
   "source": [
    "anthropic_api_key = os.getenv(\"ANTHROPIC_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "036e3208-ef4f-42e3-94d6-1a2c8b728262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nresponse = client.chat.completions.create(model=\"anthropic:claude-3-5-sonnet-20241022\", \\n                                          messages=messages, temperature=0.75)\\nprint(response.choices[0].message.content)\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "response = client.chat.completions.create(model=\"anthropic:claude-3-5-sonnet-20241022\", \n",
    "                                          messages=messages, temperature=0.75)\n",
    "print(response.choices[0].message.content)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4804cf4a-837c-4faa-91a7-ae43c85438c3",
   "metadata": {},
   "source": [
    "# OpenAI 4o mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88331a4e-e7ed-4a6c-a83f-0d76c0acf45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Below is a tabular comparison of RAG (Retrieval-Augmented Generation) and Agentic RAG, highlighting their definitions, key features, applications, and distinctions.\n",
      "\n",
      "| Feature                  | RAG (Retrieval-Augmented Generation)                | Agentic RAG                                       |\n",
      "|-------------------------|-----------------------------------------------------|--------------------------------------------------|\n",
      "| **Definition**          | A model that combines retrieval of external data with generative capabilities for enhanced outputs. | An enhanced version of RAG that incorporates agentic behavior, allowing for more autonomous decision-making. |\n",
      "| **Core Components**     | Retrieval mechanism, generative model               | Retrieval mechanism, generative model, agentic behaviors (like making decisions based on context) |\n",
      "| **Functionality**       | Generates responses using context from retrieved documents or data. | Generates responses while also acting upon received inputs and making decisions dynamically. |\n",
      "| **Interactivity**       | Primarily reactive, responding to user inputs and context. | Can actively seek information and adjust responses based on ongoing interactions. |\n",
      "| **Use Cases**           | Information retrieval, chatbots, summarization, question answering. | Concierge services, personal assistants, decision support systems, interactive storytelling. |\n",
      "| **User Engagement**     | Engages users through informative responses based on external sources. | Engages users more dynamically, adapting and evolving responses based on user interaction. |\n",
      "| **Adaptability**        | Limited adaptability, relies on pre-defined retrieval processes. | High adaptability, can alter goals and approaches based on context and user needs. |\n",
      "| **Complexity**          | Generally simpler to implement, focusing on merging retrieval and generation. | More complex, requiring advanced understanding of user intent and proactive interaction. |\n",
      "| **Potential Risks**     | May produce irrelevant information if retrieval fails; relies on quality of sources. | Risk of misinterpretation or unwanted actions due to autonomous decision-making capabilities. |\n",
      "\n",
      "This table provides a concise overview of the differences and similarities between traditional RAG and the more advanced Agentic RAG approach. If you have any specific aspects you'd like to explore further, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "provider = \"openai\"\n",
    "model_id = \"gpt-4o-mini\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Give me a tabular comparison of RAG and AGENTIC RAG\"},\n",
    "]\n",
    "response = client.chat.completions.create(\n",
    "    model=f\"{provider}:{model_id}\",\n",
    "    messages=messages,\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b115a9f-7ae1-4f95-be93-0b5d31bce037",
   "metadata": {},
   "source": [
    "# Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b927970-ff08-4d81-ae8d-c37e936809d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f43527-f2cd-47ca-99a0-dbe64c8ef3d5",
   "metadata": {},
   "source": [
    "- Function to Send Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13367ad5-2bae-4c2d-895b-fa5d4aac02fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! It's great to assist you. The capital of Japan is Tokyo. If you have any other questions, feel free to ask!\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ask(message, sys_message=\"You are a helpful agent.\",\n",
    "        model=\"groq:mixtral-8x7b-32768\"):\n",
    "    client = ai.Client()\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": sys_message},\n",
    "        {\"role\": \"user\", \"content\": message}\n",
    "    ]\n",
    "    response = client.chat.completions.create(model=model, messages=messages)\n",
    "    return response.choices[0].message.content\n",
    "ask(\"Hi. what is capital of Japan?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc729c3-bda9-4fab-af19-ed8d20ccf3d3",
   "metadata": {},
   "source": [
    "# Using Multiple APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5232087-5ca5-4338-917d-bb2938efab09",
   "metadata": {},
   "outputs": [],
   "source": [
    "mistral_api_key = os.getenv(\"MISTRAL_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3192747d-c017-40fa-b19a-35f314c834e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I was created by Mistral AI, a leading AI company based in Paris, France. Mistral AI's mission is to create artificial general intelligence that can understand, learn, and adapt to a wide range of tasks. I am just one of the many helpful tools developed by Mistral AI to make people's lives easier and more efficient.\n",
      "I was created by the Mistral AI team, a cutting-edge AI company from France.\n",
      "----------\n",
      "I was created by Meta AI that utilizes various AI technologies such as natural language processing (NLP) and machine learning to generate human-like text responses. My primary function is to assist users with information and tasks, providing helpful and accurate responses based on the input provided. I am constantly learning and improving my abilities through ongoing training and updates.\n"
     ]
    }
   ],
   "source": [
    "print(ask(\"Who is your creator?\"))\n",
    "print(ask('Who is your creator?', model='mistral:mistral-small-latest'))\n",
    "print(\"----------\")\n",
    "print(ask('Who is your creator?', model='ollama:llama3:8b'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b70b0d5-4834-4be5-99a4-c057c4debfee",
   "metadata": {},
   "source": [
    "# Querying Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "106b3802-2223-43e6-bfd2-615fe9ec6657",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models = [\n",
    "    'llama3-8b-8192',\n",
    "    'mixtral-8x7b-32768',\n",
    "]\n",
    "ret = []\n",
    "for x in models:\n",
    "    ret.append(ask('Write a short one sentence explanation of the origins of AI?', \n",
    "                   model=f'groq:{x}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "59695e6a-d9cd-4e30-9faf-e645d7b782cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('llama3-8b-8192: \\n'\n",
      " ' Artificial Intelligence (AI) has its origins in the 1950s, when computer '\n",
      " 'scientists like Alan Turing, Marvin Minsky, and John McCarthy first proposed '\n",
      " 'the idea of creating machines that could simulate human intelligence through '\n",
      " 'the development of algorithms and software that could learn, reason, and '\n",
      " 'interact with humans. ')\n",
      "('mixtral-8x7b-32768: \\n'\n",
      " ' AI, or Artificial Intelligence, has its roots in the mid-20th century, when '\n",
      " 'scientists began to seriously study the possibility of creating machines '\n",
      " 'that could mimic human thought and decision-making processes. ')\n"
     ]
    }
   ],
   "source": [
    "for idx, x in enumerate(ret):\n",
    "    pp(models[idx] + ': \\n ' + x + ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19225261-595e-4bed-9b2e-284157af2943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c296e312-66a9-4fa3-8214-198415517bf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
